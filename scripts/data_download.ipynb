{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c33f8a5-7262-4268-a3cd-66a6431c7a15",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Note:\n",
    "- Download of ERA5 data below will require around 80 GB of storage (plus another 330 GB if global analysis is desired), and may take several days due to queueing in the ECMWF Climate Data Store (CDS)\n",
    "- Download of GLASS data will require around 30 GB of storage\n",
    "- So a total of around 110 GB of storage will be required (plus another 330 GB if global analysis is desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2f851-e9fd-4c7d-a07f-4774bdf282e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import cdsapi\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45348c69-c048-4ad1-8e82-3b6404409a97",
   "metadata": {},
   "source": [
    "# Download ERA5 data\n",
    "\n",
    "If haven't already, first set up ECMWF CDS API using instructions from here: https://confluence.ecmwf.int/display/CKB/How+to+download+ERA5#HowtodownloadERA5-4-DownloadERA5familydatathroughtheCDSAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c88fbb-2824-41fd-bc52-6c52c5b13b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open CDS API client for ERA5 downloads\n",
    "c = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1cb6ab-18af-4f3e-90aa-9281ada92bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Areas for each region in NWSE format to retrieve data for\n",
    "area = {\n",
    "    \"ca\": [17, -91, 7, -81],\n",
    "    \"sa\": [0, -65, -15, -30],\n",
    "    \"wa\": [-26, 114, -36, 124],\n",
    "    \"global\": [90, -180, -90, 180]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d6a4d-1240-4ee1-9b06-41390f26f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months to retrieve data for\n",
    "months = [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "]\n",
    "\n",
    "# Days to retrieve data for\n",
    "days = [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "            '13', '14', '15',\n",
    "            '16', '17', '18',\n",
    "            '19', '20', '21',\n",
    "            '22', '23', '24',\n",
    "            '25', '26', '27',\n",
    "            '28', '29', '30',\n",
    "            '31',\n",
    "]\n",
    "\n",
    "# Times to retrieve data for\n",
    "times = [\n",
    "            '00:00', '01:00', '02:00',\n",
    "            '03:00', '04:00', '05:00',\n",
    "            '06:00', '07:00', '08:00',\n",
    "            '09:00', '10:00', '11:00',\n",
    "            '12:00', '13:00', '14:00',\n",
    "            '15:00', '16:00', '17:00',\n",
    "            '18:00', '19:00', '20:00',\n",
    "            '21:00', '22:00', '23:00',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b67b3d-dca8-41aa-ba2e-a7aaadd7af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable names in ECMWF CDS, available here:\n",
    "# https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation\n",
    "\n",
    "vars_era5_static = [\n",
    "            'angle_of_sub_gridscale_orography', 'anisotropy_of_sub_gridscale_orography', 'geopotential',\n",
    "            'high_vegetation_cover', 'lake_cover', 'lake_depth',\n",
    "            'land_sea_mask', 'low_vegetation_cover', 'slope_of_sub_gridscale_orography',\n",
    "            'soil_type', 'standard_deviation_of_filtered_subgrid_orography', 'standard_deviation_of_orography',\n",
    "            'type_of_high_vegetation', 'type_of_low_vegetation',\n",
    "]\n",
    "\n",
    "vars_era5 = {\n",
    "    \"sfc\": [\n",
    "            '100m_u_component_of_wind', '100m_v_component_of_wind', '10m_u_component_of_wind',\n",
    "            '10m_v_component_of_wind', '2m_temperature', 'mean_sea_level_pressure',\n",
    "            'surface_latent_heat_flux', 'surface_sensible_heat_flux',\n",
    "    ],\n",
    "    \"atm\": [\n",
    "            'evaporation', 'total_column_cloud_liquid_water', 'total_column_water_vapour',\n",
    "            'vertical_integral_of_divergence_of_moisture_flux', 'vertical_integral_of_energy_conversion', \n",
    "            'vertical_integral_of_kinetic_energy', 'vertical_integral_of_potential_internal_and_latent_energy',\n",
    "    ],\n",
    "    \"cld\": [\n",
    "            'boundary_layer_height', 'cloud_base_height', 'convective_available_potential_energy',\n",
    "            'convective_inhibition', 'forecast_albedo', 'total_cloud_cover',\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8163630c-875d-486e-b444-6caa5ddf6ae3",
   "metadata": {},
   "source": [
    "## Static data (global)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a77e0-f860-4c12-9aaf-a0687ff93710",
   "metadata": {},
   "source": [
    "### Request all static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097551ba-aa1c-408d-a9aa-1c4f9836a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_era5_slv_static_all():\n",
    "    # Create global_era5-slv_static folder to download data into (if it doesn't already exist)\n",
    "    Path(\"../data_raw/global_era5-slv_static\").mkdir(parents=True, exist_ok=True)\n",
    "    file_name = \"../data_raw/global_era5-slv_static/global_era5-slv_static_all.nc\"\n",
    "    if Path(file_name).exists():\n",
    "        print(file_name, \"already exists\")\n",
    "    else:\n",
    "        try:\n",
    "            c.retrieve(\n",
    "                'reanalysis-era5-single-levels-monthly-means',\n",
    "                {\n",
    "                    'product_type': 'monthly_averaged_reanalysis',\n",
    "                    'variable': vars_era5_static,\n",
    "                    'year': '2022',\n",
    "                    'month': '01',\n",
    "                    'time': '00:00',\n",
    "                    'format': 'netcdf',\n",
    "                },\n",
    "                file_name)\n",
    "            print(\"Retrieved\", file_name)\n",
    "        except:\n",
    "            print(\"Failed to retrieve \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc74c5-947f-4669-b15e-b90ac7a3586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all static data\n",
    "retrieve_era5_slv_static_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0d7fe-d615-4a5c-a731-69416bff35e0",
   "metadata": {},
   "source": [
    "## Monthly averaged reanalysis by hour of day, on single levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc561f-a9f3-4689-b4cb-456ed79b399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define request to retrieve monthly reanalysis (to be used with retrieve function)\n",
    "def request_era5_slv_month_hour(region, year, vars_type):\n",
    "    file_name = '../data_raw/{region}_era5-slv-{vars_type}_month-hour/{region}_era5-slv-{vars_type}_month-hour_{year}.nc'.format(\n",
    "        region=region, vars_type=vars_type, year=year)\n",
    "    if Path(file_name).exists():\n",
    "        print(file_name + \" already exists\")\n",
    "    else:\n",
    "        try:\n",
    "            c.retrieve(\n",
    "                'reanalysis-era5-single-levels-monthly-means',\n",
    "                {\n",
    "                    'product_type': 'monthly_averaged_reanalysis_by_hour_of_day',\n",
    "                    'variable': vars_era5[vars_type],\n",
    "                    'year': year,\n",
    "                    'month': months,\n",
    "                    'time': times,\n",
    "                    'format': 'netcdf',\n",
    "                    'area': area[region],\n",
    "                },\n",
    "                file_name)\n",
    "            print(\"Retrieved \" + file_name)\n",
    "        except:\n",
    "            print(\"Failed to retrieve \" + file_name)\n",
    "        \n",
    "# Define function to retrieve monthly reanalysis    \n",
    "def retrieve_era5_slv_month_hour(region, vars_type, year_start, year_end):\n",
    "    # Assert region and vars_type is valid so we don't unneccessarily create a folder in the next part\n",
    "    # And so we don't unnecessarily trigger the exception message\n",
    "    assert region in area.keys(), f\"region not one of: {*[*area],}\"\n",
    "    assert vars_type in [*vars_era5], f\"vars_type not one of {[*vars_era5]}\"\n",
    "    # Create {region}_era5-slv-{vars_type}_month-hour folder to download data into\n",
    "    # (if it doesn't already exist)\n",
    "    Path(\"../data_raw/{region}_era5-slv-{vars_type}_month-hour\".format(region=region, vars_type=vars_type)).mkdir(parents=True, exist_ok=True)\n",
    "    # Run up to 10 parallel retrieve requests (ECMWF CDS only allows 1 year per request for hourly data)\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        for year in range(year_start, year_end+1):\n",
    "            executor.submit(request_era5_slv_month_hour, region, year, vars_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c91dde-0123-4bb1-8298-cd403903cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for surface analysis in Western Australia\n",
    "retrieve_era5_slv_month_hour(\"wa\", \"sfc\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e22f5f-86bd-42b4-a614-83eebddc8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for atmospheric analysis in Western Australia\n",
    "retrieve_era5_slv_month_hour(\"wa\", \"atm\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831cce6c-60bd-44fe-91ca-76edf6eb01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for cloud analysis in Western Australia\n",
    "retrieve_era5_slv_month_hour(\"wa\", \"cld\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b163f-0b95-4083-a089-1a758938d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for surface analysis in Central America\n",
    "retrieve_era5_slv_month_hour(\"ca\", \"sfc\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9909dc1-7a2d-4d0c-b213-743e44927b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for atmospheric analysis in Central America\n",
    "retrieve_era5_slv_month_hour(\"ca\", \"atm\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9aa0c-0f54-4dcb-943e-bf00db529f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for cloud analysis in Central America\n",
    "retrieve_era5_slv_month_hour(\"ca\", \"cld\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f27829-6366-4e9c-994d-737cb716e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for surface analysis in South America\n",
    "retrieve_era5_slv_month_hour(\"sa\", \"sfc\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88f046-5834-4e61-9509-ffc7a13eb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for atmospheric analysis in South America\n",
    "retrieve_era5_slv_month_hour(\"sa\", \"atm\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375d592-60cc-4642-86f0-2f92ccde5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for cloud analysis in South America\n",
    "retrieve_era5_slv_month_hour(\"sa\", \"cld\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa95ea-9a7e-4449-94ac-4a45037b674e",
   "metadata": {},
   "source": [
    "## Hourly reanalysis, on single levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341419dc-664e-48d6-a1d6-097f6a2ada83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define request to retrieve hourly reanalysis (to be used with retrieve function)\n",
    "def request_era5_slv_hour(region, year, vars_type):\n",
    "    file_name = '../data_raw/{region}_era5-slv-{vars_type}_hour/{region}_era5-slv-{vars_type}_hour_{year}.nc'.format(\n",
    "        region=region, vars_type=vars_type, year=year)\n",
    "    if Path(file_name).exists():\n",
    "        print(file_name + \" already exists\")\n",
    "    else:\n",
    "        try:\n",
    "            c.retrieve(\n",
    "            'reanalysis-era5-single-levels',\n",
    "            {\n",
    "                'product_type': 'reanalysis',\n",
    "                'variable': vars_era5[vars_type],\n",
    "                'year': year,\n",
    "                'month': months,\n",
    "                'day': days,\n",
    "                'time': times,\n",
    "                'area': area[region],\n",
    "                'format': 'netcdf',\n",
    "            },\n",
    "            file_name)\n",
    "            print(\"Retrieved \" + file_name)\n",
    "        except:\n",
    "            print(\"Failed to retrieve \" + file_name)\n",
    "\n",
    "# Define function to retrieve hourly reanalysis    \n",
    "def retrieve_era5_slv_hour(region, vars_type, year_start, year_end):\n",
    "    # Assert region and vars_type is valid so we don't unneccessarily create a folder in the next part\n",
    "    # And so we don't unnecessarily trigger the exception message\n",
    "    assert region in area.keys(), f\"region not one of: {*[*area],}\"\n",
    "    assert vars_type in [*vars_era5], f\"vars_type not one of {[*vars_era5]}\"\n",
    "    # Create {region}_era5-slv-{vars_type}_hour folder to download data into\n",
    "    # (if it doesn't already exist)\n",
    "    Path(\"../data_raw/{region}_era5-slv-{vars_type}_hour\".format(region=region, vars_type=vars_type)).mkdir(parents=True, exist_ok=True)\n",
    "    # Run up to 10 parallel retrieve requests (ECMWF CDS only allows 1 year per request for hourly data)\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        for year in range(year_start, year_end+1):\n",
    "            executor.submit(request_era5_slv_hour, region, year, vars_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d36474-719d-4e5a-9303-be583057f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve hourly reanalysis data for surface analysis in Central America\n",
    "retrieve_era5_slv_hour(\"ca\", \"sfc\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd02aeff-e99f-4dcd-9655-d105b19ec999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve hourly reanalysis data for surface analysis in South America\n",
    "retrieve_era5_slv_hour(\"sa\", \"sfc\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6e71d-fbc5-4f16-a56b-e305d6b88c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve hourly reanalysis data for surface analysis in Western Australia\n",
    "retrieve_era5_slv_hour(\"wa\", \"sfc\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3cedb-edc9-4306-bf18-005654aeebfe",
   "metadata": {},
   "source": [
    "# Download GLASS data\n",
    "\n",
    "First check that the naming conventions for the file urls are still up to date here: http://www.glass.umd.edu/Overview.html\n",
    "\n",
    "Of the different components in the naming convention, the product_version and production_date is most likely to change so check these by browsing the downloads page here: http://www.glass.umd.edu/Download.html\n",
    "\n",
    "Take care in that the production_date may vary for different years within the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabed11-8c80-45ba-89ab-194880fad4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve GLASS data\n",
    "# Check on server that the url components are up to date (especially product_version)\n",
    "def retrieve_glass_8_day(variable, data_source, year_start, year_end, production_date):\n",
    "    # Define dictionaries according to GLASS dataset names (user may need to update these)\n",
    "    variable_number = {\"lai\": \"01\", \"fapar\": \"09\"}\n",
    "    data_source_number = {\"modis\": \"01\", \"avhrr\": \"02\"}\n",
    "    product_version = {\"modis\": \"V60\", \"avhrr\": \"V40\"}\n",
    "    dl_dir_path = {\"modis\": \"MODIS/0.05D\", \"avhrr\": \"AVHRR\"}\n",
    "    # Assert arguments are valid so we don't unneccessarily create a folder in the next part\n",
    "    # And so we don't unnecessarily trigger the exception message\n",
    "    assert variable in variable_number.keys(), f\"variable not one of: {*[*variable_number],}\"\n",
    "    assert data_source in data_source_number.keys(), f\"data_source not one of: {*[*data_source_number],}\"\n",
    "    # Create global_glass-{variable}-{data_source}_8-day folder to download data into\n",
    "    # (if it doesn't already exist)\n",
    "    file_path = \"../data_raw/global_glass-{variable}-{data_source}_8-day\".format(\n",
    "        variable=variable, data_source=data_source)\n",
    "    Path(file_path).mkdir(parents=True, exist_ok=True)\n",
    "    # Download data from the correct url, and to the correct file name\n",
    "    for year in range(year_start, year_end+1):\n",
    "        for day in range(1, 361+1, 8):\n",
    "            file_name = file_path + \"/global_glass-{variable}-{data_source}_8-day_{year}-{day:03}.hdf\".format(\n",
    "                variable=variable, data_source=data_source, year=year, day=day)\n",
    "            dl_url = (\"http://www.glass.umd.edu/{variable}/{dl_dir_path}/{year}/GLASS{variable_number}\" + \n",
    "                      \"B{data_source_number}.{product_version}.A{year}{day:03}.{production_date}.hdf\").format(\n",
    "                variable=variable.upper(), dl_dir_path=dl_dir_path[data_source], year=year, day=day,\n",
    "                variable_number=variable_number[variable], data_source_number = data_source_number[data_source],\n",
    "                product_version=product_version[data_source], production_date=production_date)\n",
    "            if Path(file_name).exists():\n",
    "                print(file_name + \" already exists\")\n",
    "            else:\n",
    "                try:\n",
    "                    wget.download(dl_url, file_name)\n",
    "                    print(\"Retrieved \" + file_name)\n",
    "                except:\n",
    "                    print(\"Failed to retrieve \" + file_name + \"; check on server if there is missing data \" +\n",
    "                          \"for the given date, and/or if the product_version and production_date for that \" +\n",
    "                          \"file is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39524d-935f-429a-82e5-3a6893ccfb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve LAI data derived from MODIS\n",
    "# Check on server for the correct production_date to enter for each year\n",
    "retrieve_glass_8_day(\"lai\", \"modis\", 2000, 2019, \"2022010\")\n",
    "retrieve_glass_8_day(\"lai\", \"modis\", 2020, 2021, \"2022138\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42224f-ca61-4b42-b2b2-55f1f8e80c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve LAI data derived from AVHRR\n",
    "# Check on server for the correct production_date to enter for each year\n",
    "retrieve_glass_8_day(\"lai\", \"avhrr\", 1981, 2017, \"2019353\")\n",
    "retrieve_glass_8_day(\"lai\", \"avhrr\", 2018, 2018, \"2019358\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5943b6-c383-4938-981c-2b548a3e5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve FAPAR data derived from MODIS\n",
    "# Check on server for the correct production_date to enter for each year\n",
    "retrieve_glass_8_day(\"fapar\", \"modis\", 2000, 2020, \"2022092\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50f3f1-bd55-4a49-81fc-1bdfc3bd1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve FAPAR data derived from AVHRR\n",
    "# Check on server for the correct production_date to enter for each year\n",
    "retrieve_glass_8_day(\"fapar\", \"avhrr\", 1982, 2015, \"2019353\")\n",
    "retrieve_glass_8_day(\"fapar\", \"avhrr\", 2016, 2018, \"2019358\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4993a-4b27-4afd-8ab1-842ecf81f0f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Download other data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04a912-9292-4625-80f2-b57d60201634",
   "metadata": {},
   "source": [
    "## Definition for the State Barrier Fence of Western Australia\n",
    "\n",
    "- Download from https://data-downloads.slip.wa.gov.au/ExtractDownload/DownloadFile/187882\n",
    "- Information on dataset available here: https://catalogue.data.wa.gov.au/dataset/state-barrier-fence-dafwa-030/resource/2b867d37-26d3-4be0-9cbd-6969dc30df4d?inner_span=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0bfcc3-39b5-4093-a5df-0a2394db233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wa_sbf_static folder to download data into\n",
    "# (if it doesn't already exist)\n",
    "Path(\"../data_raw/wa_sbfwa_static\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09abb25-9029-4cdf-a3ea-b466e543a67e",
   "metadata": {},
   "source": [
    "## NOAA Climate Indices\n",
    "\n",
    "Catalog of indices available here: https://psl.noaa.gov/data/climateindices/list/\n",
    "\n",
    "Indices used in this analysis are:\n",
    "- AMO: NOAA/PSL AMO Index (AMOI)\n",
    "- PDO: NOAA/PSL PDO Index (PDOI)\n",
    "- ENSO: NOAA/CPC Oceanic Nino Index (ONI)\n",
    "- IOD: NOAA/PSL Dipole Mode Index (DMI)\n",
    "- AAO/SAM: NOAA/CPC AAO Index (AAOI)\n",
    "- AO/NAM: NOAA/CPC AO Index (AOI)\n",
    "- NAO: NOAA/CPC NAO Index (NAOI)\n",
    "- EPO: NOAA/CPC EPO Index (EPOI)\n",
    "\n",
    "Abbreviations:\n",
    "- NOAA: National Oceanic and Atmospheric Administration\n",
    "- PSL: Physical Sciences Laboratory\n",
    "- CPC: Climate Prediction Center\n",
    "- AMO: Atlantic Multidecadal Oscillation\n",
    "- PDO: Pacific Decadal Oscillation\n",
    "- ENSO: El Nino-Southern Oscillation\n",
    "- IOD: Indian Ocean Dipole\n",
    "- AAO/SAM: Antarctic Oscillation/Southern Annular Mode\n",
    "- AO/NAM: Arctic Oscillation/Northern Annular Mode\n",
    "- NAO: North Atlantic Oscillation\n",
    "- EPO: Eastern Pacific Oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4b778-0ed8-4f74-9cd6-0157566cfd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {\n",
    "    \"amoi\": {\"output\": \"noaa-psl_amoi\", \"url\": \"https://psl.noaa.gov/data/correlation/amon.us.data\"},\n",
    "    \"pdoi\": {\"output\": \"noaa-psl_pdoi\", \"url\": \"https://psl.noaa.gov/data/correlation/pdo.data\"},\n",
    "    \"oni\": {\"output\": \"noaa-cpc_oni\", \"url\": \"https://psl.noaa.gov/data/correlation/oni.data\"},\n",
    "    \"dmi\": {\"output\": \"noaa-psl_dmi\", \"url\": \"https://psl.noaa.gov/gcos_wgsp/Timeseries/Data/dmi.had.long.data\"},\n",
    "    \"aaoi\": {\"output\": \"noaa-cpc_aaoi\", \"url\": \"https://psl.noaa.gov/data/correlation/aao.data\"},\n",
    "    \"aoi\": {\"output\": \"noaa-cpc_aoi\", \"url\": \"https://psl.noaa.gov/data/correlation/ao.data\"},\n",
    "    \"naoi\": {\"output\": \"noaa-cpc_naoi\", \"url\": \"https://psl.noaa.gov/data/correlation/nao.data\"},\n",
    "    \"epoi\": {\"output\": \"noaa-cpc_epoi\", \"url\": \"https://psl.noaa.gov/data/correlation/epo.data\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0628f10-1c24-4301-9fa1-b6196ddcc73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"../data_raw/global_noaa-climate-indices\").mkdir(parents=True, exist_ok=True)\n",
    "for index in [*indices]:\n",
    "    file_name = \"../data_raw/global_noaa-climate-indices/\" + indices[index][\"output\"]\n",
    "    if Path(file_name).exists():\n",
    "        print(file_name + \" already exists\")\n",
    "    else:\n",
    "        try:\n",
    "            wget.download(indices[index][\"url\"], file_name)\n",
    "            print(\"Retrieved \" + file_name)\n",
    "        except:\n",
    "            print(\"Failed to retrieve \" + file_name + \"; check on catalog if url has changed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73d932-d1a6-49b0-9ec1-53f9377208c6",
   "metadata": {},
   "source": [
    "# (Deprecated)\n",
    "\n",
    "Data downloads which were executed but were not used within the thesis project due to time constraints, change of scope, or finding that it was unnecessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6327a4af-a375-4e55-83cf-1bf98fe35c65",
   "metadata": {},
   "source": [
    "## (Deprecated) Global monthly averaged reanalysis by hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183dff3-58f6-4bb6-bbf9-c0d4a859975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global surface analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"sfc\", 1981, 1985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a46206-29f6-408a-a2ec-ca6ab5cfd5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global surface analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"sfc\", 1992, 1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d077b6-24f2-4a12-af97-e0b45a3fbaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global surface analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"sfc\", 2007, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418975fc-762c-4586-adcc-71989c52a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global surface analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"sfc\", 2017, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36313f0-42d3-4169-bfa9-4648401416aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global atmospheric analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"atm\", 1981, 1985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bce31e-72d6-41d7-ad04-025388d2c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global atmospheric analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"atm\", 1992, 1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30e859-8529-446f-97b1-cb4b92292339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global atmospheric analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"atm\", 2007, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9864e-5a73-4306-9ada-565ad3e506b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global atmospheric analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"atm\", 2017, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd25a06-2123-4a3f-8a01-70e24ab3b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global cloud analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"cld\", 1981, 1985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad9c80-0333-47c1-b5ef-9c5f7e41d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global cloud analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"cld\", 1992, 1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e8a39-eb78-4823-9578-146c4d782fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global cloud analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"cld\", 2007, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ce14e-7ac2-419d-b001-15578ffdb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve monthly averaged by hour reanalysis data for global cloud analysis\n",
    "# retrieve_era5_slv_month_hour(\"global\", \"cld\", 2017, 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91152b82-cab5-4a53-9721-a947af6cbc2d",
   "metadata": {},
   "source": [
    "## (Deprecated) BoM hourly observation data\n",
    "\n",
    "Request from http://www.bom.gov.au/catalogue/data-feeds.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667814af-0f0f-4dc4-b4b1-7538f90a581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create wa_bom_hour folder to download data into\n",
    "# # (if it doesn't already exist)\n",
    "# Path(\"../data_raw/wa_bom_hour\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c504d001-da1a-454d-a0bb-144fff9be156",
   "metadata": {},
   "source": [
    "## (Deprecated) BoM minutely observation data\n",
    "\n",
    "Request from http://www.bom.gov.au/catalogue/data-feeds.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671795ab-9b46-4bd2-b53a-39e16de862bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create wa_bom_minute folder to download data into\n",
    "# # (if it doesn't already exist)\n",
    "# Path(\"../data_raw/wa_bom_minute\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefcf2cf-a6c9-419e-823e-0235cae59907",
   "metadata": {},
   "source": [
    "## (Deprecated) Bunny Fence Experiment (2005-2007) data\n",
    "\n",
    "Request from https://www.eol.ucar.edu/field_projects/bufex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec968c1e-6b9d-4c83-bf29-10bee19bb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create wa_bufex folder to download data into\n",
    "# # (if it doesn't already exist)\n",
    "# Path(\"../data_raw/wa_bufex\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee24a04-3745-4320-9a7f-deaeacb826d1",
   "metadata": {},
   "source": [
    "## (Deprecated) Original set of ERA5 variables which were retrieved\n",
    "\n",
    "In the original set of data retrievals, the atmospheric variables included 'vertical_integral_of_divergence_of_cloud_frozen_water_flux' and 'vertical_integral_of_divergence_of_cloud_liquid_water_flux'. This is because it was thought that the vertical integral of divergence of *water vapour* flux needed to be derived by subtracting these two variables from 'vertical_integral_of_divergence_of_moisture_flux'. But correspondence with ECMWF specialist support confirmed that 'vertical_integral_of_divergence_of_moisture_flux' includes the divergence for water vapour only (i.e. does not include cloud liquid or frozen water fluxes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21c2a3-c72c-4cd0-894c-b6a2cb69bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Variable names in ECMWF CDS, available here:\n",
    "# # https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation\n",
    "\n",
    "# vars_era5_static = [\n",
    "#             'angle_of_sub_gridscale_orography', 'anisotropy_of_sub_gridscale_orography', 'geopotential',\n",
    "#             'high_vegetation_cover', 'lake_cover', 'lake_depth',\n",
    "#             'land_sea_mask', 'low_vegetation_cover', 'slope_of_sub_gridscale_orography',\n",
    "#             'soil_type', 'standard_deviation_of_filtered_subgrid_orography', 'standard_deviation_of_orography',\n",
    "#             'type_of_high_vegetation', 'type_of_low_vegetation',\n",
    "# ]\n",
    "\n",
    "# vars_era5 = {\n",
    "#     \"sfc\": [\n",
    "#             '100m_u_component_of_wind', '100m_v_component_of_wind', '10m_u_component_of_wind',\n",
    "#             '10m_v_component_of_wind', '2m_temperature', 'mean_sea_level_pressure',\n",
    "#             'surface_latent_heat_flux', 'surface_sensible_heat_flux',\n",
    "#     ],\n",
    "#     \"atm\": [\n",
    "#             'evaporation', 'total_column_cloud_liquid_water', 'total_column_water_vapour',\n",
    "#             'vertical_integral_of_divergence_of_cloud_frozen_water_flux', 'vertical_integral_of_divergence_of_cloud_liquid_water_flux', 'vertical_integral_of_divergence_of_moisture_flux',\n",
    "#             'vertical_integral_of_energy_conversion', 'vertical_integral_of_kinetic_energy', 'vertical_integral_of_potential_internal_and_latent_energy',\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afeebfc-c426-4a66-8a6c-00307aa91d96",
   "metadata": {},
   "source": [
    "## (Deprecated) Request one static ERA5 variable at a time\n",
    "\n",
    "Abandoned in favour of retrieving all static variables simultaneously (since these don't take up much storage anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e474e5-9bb3-44ed-a70e-ead21f80b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define request to retrieve static data (to be used with retrieve function)\n",
    "# def request_era5_slv_static(variable):\n",
    "#     file_name = \"../data_raw/global_era5-slv_static/global_era5-slv_static_{output_name}.nc\".format(\n",
    "#         output_name=variable.replace(\"_\", \"-\"))\n",
    "#     if Path(file_name).exists():\n",
    "#         print(file_name, \"already exists\")\n",
    "#     else:\n",
    "#         try:\n",
    "#             c.retrieve(\n",
    "#                 'reanalysis-era5-single-levels-monthly-means',\n",
    "#                 {\n",
    "#                     'product_type': 'monthly_averaged_reanalysis',\n",
    "#                     'variable': variable,\n",
    "#                     'year': '2022',\n",
    "#                     'month': '01',\n",
    "#                     'time': '00:00',\n",
    "#                     'format': 'netcdf',\n",
    "#                 },\n",
    "#                 file_name)\n",
    "#             print(\"Retrieved\", file_name)\n",
    "#         except:\n",
    "#             print(\"Failed to retrieve \" + file_name)\n",
    "            \n",
    "# # Define function to retrieve static data \n",
    "# def retrieve_era5_slv_static(variables):\n",
    "#     # Assert variables are valid so we don't unneccessarily create folders in the next part\n",
    "#     # And so we don't unnecessarily trigger the exception message\n",
    "#     assert all(variable in vars_era5_static for variable in variables), \\\n",
    "#         \"variables not subset of: {}\".format(vars_era5[\"static\"])\n",
    "#     # Create global_era5-slv_static folder to download data into\n",
    "#     # (if it doesn't already exist)\n",
    "#     Path(\"../data_raw/global_era5-slv_static\").mkdir(parents=True, exist_ok=True)\n",
    "#     # Run up to 10 parallel retrieve requests (to queue and download data for all variables simultaneously)\n",
    "#     with ThreadPoolExecutor(max_workers=min(len(variables), 10)) as executor:\n",
    "#         for variable in variables:\n",
    "#             executor.submit(request_era5_slv_static, variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808e130-714a-432a-aec3-c9fb5b76b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve static data for slope of sub-gridscale orography, geopotential (to plot elevation) and land-sea mask\n",
    "# retrieve_era5_slv_static([\"slope_of_sub_gridscale_orography\", \"geopotential\", \"land_sea_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4eadc7-5d9b-4bdb-bc7e-97cc3a127639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
