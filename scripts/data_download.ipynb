{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c33f8a5-7262-4268-a3cd-66a6431c7a15",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Note:\n",
    "- Download of ERA5 data below will require around 70 GB of storage, and may take several days due to queueing in the ECMWF Climate Data Store (CDS)\n",
    "- Download of GLASS data will require around 30 GB of storage\n",
    "- So a total of around 100 GB of storage will be required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2f851-e9fd-4c7d-a07f-4774bdf282e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import cdsapi\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45348c69-c048-4ad1-8e82-3b6404409a97",
   "metadata": {},
   "source": [
    "# Download ERA5 data\n",
    "\n",
    "If haven't already, first set up ECMWF CDS API using instructions from here: https://confluence.ecmwf.int/display/CKB/How+to+download+ERA5#HowtodownloadERA5-4-DownloadERA5familydatathroughtheCDSAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c88fbb-2824-41fd-bc52-6c52c5b13b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open CDS API client for ERA5 downloads\n",
    "c = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1cb6ab-18af-4f3e-90aa-9281ada92bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Areas for each region in NWSE format to retrieve data for\n",
    "area = {\n",
    "    \"ca\": [17, -91, 7, -81],\n",
    "    \"sa\": [0, -65, -15, -30],\n",
    "    \"wa\": [-30, 113, -35, 123],\n",
    "    \"global\": [90, -180, -90, 180]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d6a4d-1240-4ee1-9b06-41390f26f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months to retrieve data for\n",
    "months = [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "]\n",
    "\n",
    "# Days to retrieve data for\n",
    "days = [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "            '13', '14', '15',\n",
    "            '16', '17', '18',\n",
    "            '19', '20', '21',\n",
    "            '22', '23', '24',\n",
    "            '25', '26', '27',\n",
    "            '28', '29', '30',\n",
    "            '31',\n",
    "]\n",
    "\n",
    "# Times to retrieve data for\n",
    "times = [\n",
    "            '00:00', '01:00', '02:00',\n",
    "            '03:00', '04:00', '05:00',\n",
    "            '06:00', '07:00', '08:00',\n",
    "            '09:00', '10:00', '11:00',\n",
    "            '12:00', '13:00', '14:00',\n",
    "            '15:00', '16:00', '17:00',\n",
    "            '18:00', '19:00', '20:00',\n",
    "            '21:00', '22:00', '23:00',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b67b3d-dca8-41aa-ba2e-a7aaadd7af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable names in ECMWF CDS, available here:\n",
    "# https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation\n",
    "\n",
    "vars_era5_static = [\n",
    "            'angle_of_sub_gridscale_orography', 'anisotropy_of_sub_gridscale_orography', 'geopotential',\n",
    "            'high_vegetation_cover', 'lake_cover', 'lake_depth',\n",
    "            'land_sea_mask', 'low_vegetation_cover', 'slope_of_sub_gridscale_orography',\n",
    "            'soil_type', 'standard_deviation_of_filtered_subgrid_orography', 'standard_deviation_of_orography',\n",
    "            'type_of_high_vegetation', 'type_of_low_vegetation',\n",
    "]\n",
    "\n",
    "vars_era5 = {\n",
    "    \"sfc\": [\n",
    "            '100m_u_component_of_wind', '100m_v_component_of_wind', '10m_u_component_of_wind',\n",
    "            '10m_v_component_of_wind', '2m_temperature', 'mean_sea_level_pressure',\n",
    "            'surface_latent_heat_flux', 'surface_sensible_heat_flux',\n",
    "    ],\n",
    "    \"atm\": [\n",
    "            'evaporation', 'total_column_cloud_liquid_water', 'total_column_water_vapour',\n",
    "            'vertical_integral_of_divergence_of_moisture_flux', 'vertical_integral_of_energy_conversion', \n",
    "            'vertical_integral_of_kinetic_energy', 'vertical_integral_of_potential_internal_and_latent_energy',\n",
    "    ],\n",
    "    \"cld\": [\n",
    "            'boundary_layer_height', 'cloud_base_height', 'convective_available_potential_energy',\n",
    "            'convective_inhibition', 'forecast_albedo', 'total_cloud_cover',\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8163630c-875d-486e-b444-6caa5ddf6ae3",
   "metadata": {},
   "source": [
    "## Static data (global)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a77e0-f860-4c12-9aaf-a0687ff93710",
   "metadata": {},
   "source": [
    "### Request all static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097551ba-aa1c-408d-a9aa-1c4f9836a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_era5_slv_static_all():\n",
    "    # Create global_era5-slv_static folder to download data into (if it doesn't already exist)\n",
    "    Path(\"../data_raw/global_era5-slv_static\").mkdir(parents=True, exist_ok=True)\n",
    "    file_name = \"../data_raw/global_era5-slv_static/global_era5-slv_static_all.nc\"\n",
    "    if Path(file_name).exists():\n",
    "        print(file_name, \"already exists\")\n",
    "    else:\n",
    "        try:\n",
    "            c.retrieve(\n",
    "                'reanalysis-era5-single-levels-monthly-means',\n",
    "                {\n",
    "                    'product_type': 'monthly_averaged_reanalysis',\n",
    "                    'variable': vars_era5_static,\n",
    "                    'year': '2022',\n",
    "                    'month': '01',\n",
    "                    'time': '00:00',\n",
    "                    'format': 'netcdf',\n",
    "                },\n",
    "                file_name)\n",
    "            print(\"Retrieved\", file_name)\n",
    "        except:\n",
    "            print(\"Failed to retrieve \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc74c5-947f-4669-b15e-b90ac7a3586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all static data\n",
    "retrieve_era5_slv_static_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0d7fe-d615-4a5c-a731-69416bff35e0",
   "metadata": {},
   "source": [
    "## Monthly averaged reanalysis by hour of day, on single levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc561f-a9f3-4689-b4cb-456ed79b399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define request to retrieve monthly reanalysis (to be used with retrieve function)\n",
    "def request_era5_slv_month_hour(region, year, vars_type):\n",
    "    file_name = '../data_raw/{region}_era5-slv-{vars_type}_month-hour/{region}_era5-slv-{vars_type}_month-hour_{year}.nc'.format(\n",
    "        region=region, vars_type=vars_type, year=year)\n",
    "    if Path(file_name).exists():\n",
    "        print(file_name + \" already exists\")\n",
    "    else:\n",
    "        try:\n",
    "            c.retrieve(\n",
    "                'reanalysis-era5-single-levels-monthly-means',\n",
    "                {\n",
    "                    'product_type': 'monthly_averaged_reanalysis_by_hour_of_day',\n",
    "                    'variable': vars_era5[vars_type],\n",
    "                    'year': year,\n",
    "                    'month': months,\n",
    "                    'time': times,\n",
    "                    'format': 'netcdf',\n",
    "                    'area': area[region],\n",
    "                },\n",
    "                file_name)\n",
    "            print(\"Retrieved \" + file_name)\n",
    "        except:\n",
    "            print(\"Failed to retrieve \" + file_name)\n",
    "        \n",
    "# Define function to retrieve monthly reanalysis    \n",
    "def retrieve_era5_slv_month_hour(region, vars_type, year_start, year_end):\n",
    "    # Assert region and vars_type is valid so we don't unneccessarily create a folder in the next part\n",
    "    # And so we don't unnecessarily trigger the exception message\n",
    "    assert region in area.keys(), f\"region not one of: {*[*area],}\"\n",
    "    assert vars_type in [*vars_era5], f\"vars_type not one of {[*vars_era5]}\"\n",
    "    # Create {region}_era5-slv-{vars_type}_month-hour folder to download data into\n",
    "    # (if it doesn't already exist)\n",
    "    Path(\"../data_raw/{region}_era5-slv-{vars_type}_month-hour\".format(region=region, vars_type=vars_type)).mkdir(parents=True, exist_ok=True)\n",
    "    # Run up to 10 parallel retrieve requests (ECMWF CDS only allows 1 year per request for hourly data)\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        for year in range(year_start, year_end+1):\n",
    "            executor.submit(request_era5_slv_month_hour, region, year, vars_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c91dde-0123-4bb1-8298-cd403903cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for surface analysis in Western Australia\n",
    "retrieve_era5_slv_month_hour(\"wa\", \"sfc\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e22f5f-86bd-42b4-a614-83eebddc8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for atmospheric analysis in Western Australia\n",
    "retrieve_era5_slv_month_hour(\"wa\", \"atm\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831cce6c-60bd-44fe-91ca-76edf6eb01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for cloud analysis in Western Australia\n",
    "retrieve_era5_slv_month_hour(\"wa\", \"cld\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b163f-0b95-4083-a089-1a758938d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for surface analysis in Central America\n",
    "retrieve_era5_slv_month_hour(\"ca\", \"sfc\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9909dc1-7a2d-4d0c-b213-743e44927b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for atmospheric analysis in Central America\n",
    "retrieve_era5_slv_month_hour(\"ca\", \"atm\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9aa0c-0f54-4dcb-943e-bf00db529f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for cloud analysis in Central America\n",
    "retrieve_era5_slv_month_hour(\"ca\", \"cld\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f27829-6366-4e9c-994d-737cb716e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for surface analysis in South America\n",
    "retrieve_era5_slv_month_hour(\"sa\", \"sfc\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88f046-5834-4e61-9509-ffc7a13eb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for atmospheric analysis in South America\n",
    "retrieve_era5_slv_month_hour(\"sa\", \"atm\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375d592-60cc-4642-86f0-2f92ccde5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for cloud analysis in South America\n",
    "retrieve_era5_slv_month_hour(\"sa\", \"cld\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183dff3-58f6-4bb6-bbf9-c0d4a859975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for global surface analysis\n",
    "retrieve_era5_slv_month_hour(\"global\", \"sfc\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba040c-16d5-4fb3-b0ac-d84cec072cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for global atmospheric analysis\n",
    "retrieve_era5_slv_month_hour(\"global\", \"atm\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02d9af-9133-4c99-9762-36bae54f6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve monthly averaged by hour reanalysis data for global cloud analysis\n",
    "retrieve_era5_slv_month_hour(\"global\", \"cld\", 1980, 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa95ea-9a7e-4449-94ac-4a45037b674e",
   "metadata": {},
   "source": [
    "## Hourly reanalysis, on single levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341419dc-664e-48d6-a1d6-097f6a2ada83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define request to retrieve hourly reanalysis (to be used with retrieve function)\n",
    "def request_era5_slv_hour(region, year, vars_type):\n",
    "    file_name = '../data_raw/{region}_era5-slv-{vars_type}_hour/{region}_era5-slv-{vars_type}_hour_{year}.nc'.format(\n",
    "        region=region, vars_type=vars_type, year=year)\n",
    "    if Path(file_name).exists():\n",
    "        print(file_name + \" already exists\")\n",
    "    else:\n",
    "        try:\n",
    "            c.retrieve(\n",
    "            'reanalysis-era5-single-levels',\n",
    "            {\n",
    "                'product_type': 'reanalysis',\n",
    "                'variable': vars_era5[vars_type],\n",
    "                'year': year,\n",
    "                'month': months,\n",
    "                'day': days,\n",
    "                'time': times,\n",
    "                'area': area[region],\n",
    "                'format': 'netcdf',\n",
    "            },\n",
    "            file_name)\n",
    "            print(\"Retrieved \" + file_name)\n",
    "        except:\n",
    "            print(\"Failed to retrieve \" + file_name)\n",
    "\n",
    "# Define function to retrieve hourly reanalysis    \n",
    "def retrieve_era5_slv_hour(region, vars_type, year_start, year_end):\n",
    "    # Assert region and vars_type is valid so we don't unneccessarily create a folder in the next part\n",
    "    # And so we don't unnecessarily trigger the exception message\n",
    "    assert region in area.keys(), f\"region not one of: {*[*area],}\"\n",
    "    assert vars_type in [*vars_era5], f\"vars_type not one of {[*vars_era5]}\"\n",
    "    # Create {region}_era5-slv-{vars_type}_hour folder to download data into\n",
    "    # (if it doesn't already exist)\n",
    "    Path(\"../data_raw/{region}_era5-slv-{vars_type}_hour\".format(region=region, vars_type=vars_type)).mkdir(parents=True, exist_ok=True)\n",
    "    # Run up to 10 parallel retrieve requests (ECMWF CDS only allows 1 year per request for hourly data)\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        for year in range(year_start, year_end+1):\n",
    "            executor.submit(request_era5_slv_hour, region, year, vars_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d36474-719d-4e5a-9303-be583057f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve hourly reanalysis data for surface analysis in Central America\n",
    "retrieve_era5_slv_hour(\"ca\", \"sfc\", 1981, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd02aeff-e99f-4dcd-9655-d105b19ec999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve hourly reanalysis data for surface analysis in South America\n",
    "retrieve_era5_slv_hour(\"sa\", \"sfc\", 1981, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6e71d-fbc5-4f16-a56b-e305d6b88c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve hourly reanalysis data for surface analysis in Western Australia\n",
    "retrieve_era5_slv_hour(\"wa\", \"sfc\", 1981, 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3cedb-edc9-4306-bf18-005654aeebfe",
   "metadata": {},
   "source": [
    "# Download GLASS data\n",
    "\n",
    "First check that the naming conventions for the file urls are still up to date here: http://www.glass.umd.edu/Overview.html\n",
    "\n",
    "Of the different components in the naming convention, the product_version and production_date is most likely to change so check these by browsing the downloads page here: http://www.glass.umd.edu/Download.html\n",
    "\n",
    "Take care in that the production_date may vary for different years within the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabed11-8c80-45ba-89ab-194880fad4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve GLASS data\n",
    "# Check on server that the url components are up to date (especially product_version)\n",
    "def retrieve_glass_8_day(variable, data_source, year_start, year_end, production_date):\n",
    "    # Define dictionaries according to GLASS dataset names (user may need to update these)\n",
    "    variable_number = {\"lai\": \"01\", \"fapar\": \"09\"}\n",
    "    data_source_number = {\"modis\": \"01\", \"avhrr\": \"02\"}\n",
    "    product_version = {\"modis\": \"V60\", \"avhrr\": \"V40\"}\n",
    "    dl_dir_path = {\"modis\": \"MODIS/0.05D\", \"avhrr\": \"AVHRR\"}\n",
    "    # Assert arguments are valid so we don't unneccessarily create a folder in the next part\n",
    "    # And so we don't unnecessarily trigger the exception message\n",
    "    assert variable in variable_number.keys(), f\"variable not one of: {*[*variable_number],}\"\n",
    "    assert data_source in data_source_number.keys(), f\"data_source not one of: {*[*data_source_number],}\"\n",
    "    # Create global_glass-{variable}-{data_source}_8-day folder to download data into\n",
    "    # (if it doesn't already exist)\n",
    "    file_path = \"../data_raw/global_glass-{variable}-{data_source}_8-day\".format(\n",
    "        variable=variable, data_source=data_source)\n",
    "    Path(file_path).mkdir(parents=True, exist_ok=True)\n",
    "    # Download data from the correct url, and to the correct file name\n",
    "    for year in range(year_start, year_end+1):\n",
    "        for day in range(1, 361+1, 8):\n",
    "            file_name = file_path + \"/global_glass-{variable}-{data_source}_8-day_{year}-{day:03}.hdf\".format(\n",
    "                variable=variable, data_source=data_source, year=year, day=day)\n",
    "            dl_url = (\"http://www.glass.umd.edu/{variable}/{dl_dir_path}/{year}/GLASS{variable_number}\" + \n",
    "                      \"B{data_source_number}.{product_version}.A{year}{day:03}.{production_date}.hdf\").format(\n",
    "                variable=variable.upper(), dl_dir_path=dl_dir_path[data_source], year=year, day=day,\n",
    "                variable_number=variable_number[variable], data_source_number = data_source_number[data_source],\n",
    "                product_version=product_version[data_source], production_date=production_date)\n",
    "            if Path(file_name).exists():\n",
    "                print(file_name + \" already exists\")\n",
    "            else:\n",
    "                try:\n",
    "                    wget.download(dl_url, file_name)\n",
    "                    print(\"Retrieved \" + file_name)\n",
    "                except:\n",
    "                    print(\"Failed to retrieve \" + file_name + \"; check on server if there is missing data \" +\n",
    "                          \"for the given date, and/or if the product_version and production_date for that \" +\n",
    "                          \"file is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39524d-935f-429a-82e5-3a6893ccfb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve LAI data derived from MODIS\n",
    "# Check on server for the correct production_date to enter for each year\n",
    "retrieve_glass_8_day(\"lai\", \"modis\", 2000, 2019, \"2022010\")\n",
    "retrieve_glass_8_day(\"lai\", \"modis\", 2020, 2021, \"2022138\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42224f-ca61-4b42-b2b2-55f1f8e80c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve LAI data derived from AVHRR\n",
    "# Check on server for the correct production_date to enter for each year\n",
    "retrieve_glass_8_day(\"lai\", \"avhrr\", 1981, 2017, \"2019353\")\n",
    "retrieve_glass_8_day(\"lai\", \"avhrr\", 2018, 2018, \"2019358\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5943b6-c383-4938-981c-2b548a3e5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve FAPAR data derived from MODIS\n",
    "# Check on server for the correct production_date to enter for each year\n",
    "retrieve_glass_8_day(\"fapar\", \"modis\", 2000, 2020, \"2022092\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50f3f1-bd55-4a49-81fc-1bdfc3bd1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve FAPAR data derived from AVHRR\n",
    "# Check on server for the correct production_date to enter for each year\n",
    "retrieve_glass_8_day(\"fapar\", \"avhrr\", 1982, 2015, \"2019353\")\n",
    "retrieve_glass_8_day(\"fapar\", \"avhrr\", 2016, 2018, \"2019358\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4993a-4b27-4afd-8ab1-842ecf81f0f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Download other data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91152b82-cab5-4a53-9721-a947af6cbc2d",
   "metadata": {},
   "source": [
    "## BoM hourly observation data\n",
    "\n",
    "Request from http://www.bom.gov.au/catalogue/data-feeds.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667814af-0f0f-4dc4-b4b1-7538f90a581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wa_bom_hour folder to download data into\n",
    "# (if it doesn't already exist)\n",
    "Path(\"../data_raw/wa_bom_hour\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73d932-d1a6-49b0-9ec1-53f9377208c6",
   "metadata": {},
   "source": [
    "# (Deprecated)\n",
    "\n",
    "Data downloads which were executed but were not used within the thesis project due to time constraints, change of scope, or finding that it was unnecessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c504d001-da1a-454d-a0bb-144fff9be156",
   "metadata": {},
   "source": [
    "## (Deprecated) BoM minutely observation data\n",
    "\n",
    "Request from http://www.bom.gov.au/catalogue/data-feeds.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671795ab-9b46-4bd2-b53a-39e16de862bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wa_bom_minute folder to download data into\n",
    "# (if it doesn't already exist)\n",
    "Path(\"../data_raw/wa_bom_minute\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefcf2cf-a6c9-419e-823e-0235cae59907",
   "metadata": {},
   "source": [
    "## (Deprecated) Bunny Fence Experiment (2005-2007) data\n",
    "\n",
    "Request from https://www.eol.ucar.edu/field_projects/bufex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec968c1e-6b9d-4c83-bf29-10bee19bb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wa_bufex folder to download data into\n",
    "# (if it doesn't already exist)\n",
    "Path(\"../data_raw/wa_bufex\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee24a04-3745-4320-9a7f-deaeacb826d1",
   "metadata": {},
   "source": [
    "## (Deprecated) Original set of ERA5 variables which were retrieved\n",
    "\n",
    "In the original set of data retrievals, the atmospheric variables included 'vertical_integral_of_divergence_of_cloud_frozen_water_flux' and 'vertical_integral_of_divergence_of_cloud_liquid_water_flux'. This is because it was thought that the vertical integral of divergence of *water vapour* flux needed to be derived by subtracting these two variables from 'vertical_integral_of_divergence_of_moisture_flux'. But correspondence with ECMWF specialist support confirmed that 'vertical_integral_of_divergence_of_moisture_flux' includes the divergence for water vapour only (i.e. does not include cloud liquid or frozen water fluxes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21c2a3-c72c-4cd0-894c-b6a2cb69bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable names in ECMWF CDS, available here:\n",
    "# https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation\n",
    "\n",
    "vars_era5_static = [\n",
    "            'angle_of_sub_gridscale_orography', 'anisotropy_of_sub_gridscale_orography', 'geopotential',\n",
    "            'high_vegetation_cover', 'lake_cover', 'lake_depth',\n",
    "            'land_sea_mask', 'low_vegetation_cover', 'slope_of_sub_gridscale_orography',\n",
    "            'soil_type', 'standard_deviation_of_filtered_subgrid_orography', 'standard_deviation_of_orography',\n",
    "            'type_of_high_vegetation', 'type_of_low_vegetation',\n",
    "]\n",
    "\n",
    "vars_era5 = {\n",
    "    \"sfc\": [\n",
    "            '100m_u_component_of_wind', '100m_v_component_of_wind', '10m_u_component_of_wind',\n",
    "            '10m_v_component_of_wind', '2m_temperature', 'mean_sea_level_pressure',\n",
    "            'surface_latent_heat_flux', 'surface_sensible_heat_flux',\n",
    "    ],\n",
    "    \"atm\": [\n",
    "            'evaporation', 'total_column_cloud_liquid_water', 'total_column_water_vapour',\n",
    "            'vertical_integral_of_divergence_of_cloud_frozen_water_flux', 'vertical_integral_of_divergence_of_cloud_liquid_water_flux', 'vertical_integral_of_divergence_of_moisture_flux',\n",
    "            'vertical_integral_of_energy_conversion', 'vertical_integral_of_kinetic_energy', 'vertical_integral_of_potential_internal_and_latent_energy',\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afeebfc-c426-4a66-8a6c-00307aa91d96",
   "metadata": {},
   "source": [
    "## (Deprecated) Request one static ERA5 variable at a time\n",
    "\n",
    "Abandoned in favour of retrieving all static variables simultaneously (since these don't take up much storage anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e474e5-9bb3-44ed-a70e-ead21f80b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define request to retrieve static data (to be used with retrieve function)\n",
    "def request_era5_slv_static(variable):\n",
    "    file_name = \"../data_raw/global_era5-slv_static/global_era5-slv_static_{output_name}.nc\".format(\n",
    "        output_name=variable.replace(\"_\", \"-\"))\n",
    "    if Path(file_name).exists():\n",
    "        print(file_name, \"already exists\")\n",
    "    else:\n",
    "        try:\n",
    "            c.retrieve(\n",
    "                'reanalysis-era5-single-levels-monthly-means',\n",
    "                {\n",
    "                    'product_type': 'monthly_averaged_reanalysis',\n",
    "                    'variable': variable,\n",
    "                    'year': '2022',\n",
    "                    'month': '01',\n",
    "                    'time': '00:00',\n",
    "                    'format': 'netcdf',\n",
    "                },\n",
    "                file_name)\n",
    "            print(\"Retrieved\", file_name)\n",
    "        except:\n",
    "            print(\"Failed to retrieve \" + file_name)\n",
    "            \n",
    "# Define function to retrieve static data \n",
    "def retrieve_era5_slv_static(variables):\n",
    "    # Assert variables are valid so we don't unneccessarily create folders in the next part\n",
    "    # And so we don't unnecessarily trigger the exception message\n",
    "    assert all(variable in vars_era5_static for variable in variables), \\\n",
    "        \"variables not subset of: {}\".format(vars_era5[\"static\"])\n",
    "    # Create global_era5-slv_static folder to download data into\n",
    "    # (if it doesn't already exist)\n",
    "    Path(\"../data_raw/global_era5-slv_static\").mkdir(parents=True, exist_ok=True)\n",
    "    # Run up to 10 parallel retrieve requests (to queue and download data for all variables simultaneously)\n",
    "    with ThreadPoolExecutor(max_workers=min(len(variables), 10)) as executor:\n",
    "        for variable in variables:\n",
    "            executor.submit(request_era5_slv_static, variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808e130-714a-432a-aec3-c9fb5b76b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve static data for slope of sub-gridscale orography, geopotential (to plot elevation) and land-sea mask\n",
    "retrieve_era5_slv_static([\"slope_of_sub_gridscale_orography\", \"geopotential\", \"land_sea_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4eadc7-5d9b-4bdb-bc7e-97cc3a127639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
