{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f8680-5d1d-428f-8c44-d471c5ef256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries for calculations\n",
    "\n",
    "import logging\n",
    "import inspect\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import metpy.calc as mpcalc\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy.special import gamma\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3876d-1842-41ee-bc78-663c7762c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings and global variables for calculations\n",
    "\n",
    "# This is to get the version number of the calc_funcs script being used so that it\n",
    "# can be appended to the file name of any outputs. The reason this is done is because\n",
    "# the calculation functions below and the plot functions in the plot_funcs script both\n",
    "# output intermediate files one at a time from low level to high level, and that each\n",
    "# file name is used in recognising whether there is a need to re-run a script (if the\n",
    "# file already exists then the script is not run so as to save on computation).\n",
    "# However, this method can propagate errors from low level through to high level\n",
    "# if there has been a change to the code and/or output at the lower levels. By\n",
    "# appending the version number of the calc_funcs script being used, it forces all\n",
    "# intermediate files to be recreated from scratch rather than reuse intermediate files\n",
    "# which was outputted by outdated code. \"v00\" is used as a placeholder version number\n",
    "# if there is an error: it is used mostly for scripting purposes within an\n",
    "# interactive python notebook where the file name cannot be directly extracted\n",
    "# using the __file__ python variable.\n",
    "try:\n",
    "    calc_funcs_ver = \"cf\" + Path(__file__).stem[-3:]\n",
    "except:\n",
    "    calc_funcs_ver = \"cfv00\"\n",
    "\n",
    "# Set level of logging out of (in decreasing order of detail): \n",
    "# [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.CRITICAL]\n",
    "calc_log_level = logging.INFO\n",
    "log_levels = [logging.DEBUG, logging.INFO, logging.WARNING, \n",
    "              logging.ERROR, logging.CRITICAL]\n",
    "assert calc_log_level in log_levels, \\\n",
    "    f\"calc_log_level (global variable in settings section) must be one of: {log_levels}\"\n",
    "\n",
    "# Set priority of code to one of: [\"speed\", \"memory\"]. \"speed\" sacrifices additional \n",
    "# memory for faster processing while \"memory\" sacrifices faster processing for lower \n",
    "# RAM consumption. \n",
    "priority = \"memory\"\n",
    "priorities = [\"speed\", \"memory\"]\n",
    "assert priority in priorities, \\\n",
    "    f\"priority (global variable in settings section) must be one of: {priorities}\"\n",
    "\n",
    "# Valid regions and their mapping to axis extents in [W, E, S, N] format \n",
    "# as well as timezones in hour +- GMT\n",
    "regions = {\n",
    "    # Central America (mostly Honduras-Nicaragua-Costa Rica)\n",
    "    \"ca\": {\"extent\": [-91, -81, 7, 17], \"tz\": -6},\n",
    "    # South America (mostly central and eastern Brazil)\n",
    "    \"sa\": {\"extent\": [-65, -30, -15, 0], \"tz\": -3},\n",
    "    # Western Australia (mostly near the west coast)\n",
    "    \"wa\": {\"extent\": [113, 123, -35, -30], \"tz\": +8},\n",
    "    # Global (requires a lot of memory)\n",
    "    \"global\": {\"extent\": [-180, 180, -90, 90], \"tz\": +0}\n",
    "}\n",
    "\n",
    "# Size of chunks\n",
    "chunksize = \"500MB\"\n",
    "\n",
    "# Valid subset strings to use as argument in climatologies and\n",
    "# their mapping to month numbers for use in xarray time slicing\n",
    "months_subsets = {\n",
    "    \"all\": list(range(1, 12+1)),\n",
    "    \"djf\": [12,1,2], \"mam\": [3,4,5], \"jja\": [6,7,8], \"son\": [9,10,11]\n",
    "}\n",
    "\n",
    "# File number check to make sure data_download notebook was run correctly\n",
    "number_of_glass_files = {\"lai\": {\"avhrr\": 1748, \"modis\": 1005},\n",
    "                         \"fapar\": {\"avhrr\": 1702, \"modis\": 960}\n",
    "                        }\n",
    "number_of_era5_month_hour_files = 42\n",
    "number_of_era5_hour_files = 42\n",
    "\n",
    "# GLASS data sources\n",
    "glass_sources_all = [\"avhrr\", \"modis\"]\n",
    "\n",
    "# Earliest and latest entries in each GLASS dataset\n",
    "avhrr_earliest = \"Jan-1981\"\n",
    "modis_earliest = \"Mar-2000\"\n",
    "avhrr_latest = \"Dec-2018\"\n",
    "modis_latest = \"Dec-2021\"\n",
    "fapar_earliest = \"Jan-1982\"\n",
    "fapar_latest = \"Dec-2020\"\n",
    "\n",
    "assert (datetime.strptime(fapar_earliest, \"%b-%Y\") > \n",
    "        datetime.strptime(avhrr_earliest, \"%b-%Y\")), \\\n",
    "    \"fapar_earliest must be later than avhrr_earliest since this was a design assumption\"\n",
    "assert (datetime.strptime(fapar_latest, \"%b-%Y\") < \n",
    "        datetime.strptime(modis_latest, \"%b-%Y\")), \\\n",
    "    \"fapar_latest must be earlier than modis_latest since this was a design assumption\"\n",
    "assert (datetime.strptime(modis_earliest, \"%b-%Y\") > \n",
    "        datetime.strptime(avhrr_earliest, \"%b-%Y\")), \\\n",
    "    \"modis_earliest must be later than avhrr_earliest since this was a design assumption\"\n",
    "assert (datetime.strptime(modis_latest, \"%b-%Y\") > \n",
    "        datetime.strptime(avhrr_latest, \"%b-%Y\")), \\\n",
    "    \"modis_latest must be later than avhrr_latest since this was a design assumption\"\n",
    "\n",
    "avhrr_earliest_year = int(avhrr_earliest[-4:])\n",
    "avhrr_latest_year = int(avhrr_latest[-4:])\n",
    "modis_earliest_year = int(modis_earliest[-4:])\n",
    "modis_latest_year = int(modis_latest[-4:])\n",
    "fapar_earliest_year = int(fapar_earliest[-4:])\n",
    "fapar_latest_year = int(fapar_latest[-4:])\n",
    "\n",
    "# Resolution of ERA5 dataset in degrees (used for regridding)\n",
    "res_era5 = 0.25\n",
    "\n",
    "# Valid ERA5/ERA5-derived parameters for use in analysis\n",
    "hours_all = list(range(0, 23+1))\n",
    "vars_and_dvars_era5 = {\n",
    "    \"vars\": {\n",
    "        \"sfc\": [\"u10\", \"v10\", \"ws10\", \"wv10\", \"u100\", \"v100\", \"ws100\", \"wv100\", \n",
    "                \"mslp\", \"t2\", \"slhf\", \"sshf\"],\n",
    "        \"atm\": [\"nse\", \"vidmf\", \"viec\", \"vipile\", \"vike\", \"tcclw\", \"tcwv\", \"nac\"],\n",
    "        \"cld\": [\"blh\", \"fa\", \"cbh\", \"tcc\", \"cape\", \"ci\"]\n",
    "    },\n",
    "    \"dvars\": {\n",
    "        \"sfc\": [\"du10\", \"dv10\", \"dws10\", \"dwv10\", \"du100\", \"dv100\", \"dws100\", \"dwv100\", \n",
    "                \"dmslp\", \"dt2\", \"dslhf\", \"dsshf\"],\n",
    "        \"atm\": [\"dnse\", \"dvidmf\", \"dviec\", \"dvipile\", \"dvike\", \"dtcclw\", \"dtcwv\", \"dnac\"],\n",
    "        \"cld\": [\"dblh\", \"dfa\", \"dcbh\", \"dtcc\", \"dcape\", \"dci\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "vars_era5_all = []\n",
    "for _, var_list in vars_and_dvars_era5[\"vars\"].items():\n",
    "    for var in var_list:\n",
    "        vars_era5_all.append(var)\n",
    "\n",
    "dvars_era5_all = []\n",
    "for _, dvar_list in vars_and_dvars_era5[\"dvars\"].items():\n",
    "    for dvar in dvar_list:\n",
    "        dvars_era5_all.append(dvar)\n",
    "\n",
    "vars_and_dvars_era5_all = vars_era5_all + dvars_era5_all\n",
    "\n",
    "# Valid time strings to use as argument in plot_funcs script,\n",
    "times = {\n",
    "    \"0-5\": list(range(0, 5+1)), \"6-11\": list(range(6, 11+1)),\n",
    "    \"12-17\": list(range(12, 17+1)), \"18-23\": list(range(18, 23+1)),\n",
    "    \"night\": list(range(0, 5+1)), \"morning\": list(range(6, 11+1)),\n",
    "    \"afternoon\": list(range(12, 17+1)), \"evening\": list(range(18, 23+1))\n",
    "}\n",
    "\n",
    "# Parameters which are vectors\n",
    "params_vector = [\"wv10\", \"wv100\", \"dwv10\", \"dwv100\"]\n",
    "\n",
    "# Output parameters for calc_glass_mean_clim\n",
    "params_glass_mean = [\"mlai\", \"mfapar\"]\n",
    "\n",
    "# Output parameters for calc_era5_mdp_clim_stats_given_var_or_dvar\n",
    "params_stat = [\"hour_max\", \"hour_min\", \"max\", \"max_u\", \"max_v\", \n",
    "               \"min\", \"min_u\", \"min_v\", \"mean\", \"mean_u\", \"mean_v\", \"range\"]\n",
    "\n",
    "# Output parameters for calc_era5_wsd_clim\n",
    "params_wsd = [\"ws10_mean\", \"ws10_std\", \"c10\", \"k10\", \"ws100_mean\", \n",
    "              \"ws100_std\", \"c100\", \"k100\", \"eroe100\", \"tgcf100\"]\n",
    "\n",
    "# Output parameters for static orographic calculations\n",
    "params_orog = [\"lse\", \"ssgo\"]\n",
    "\n",
    "# Mapping from ERA5 dataset variable names to own desired names, while\n",
    "# also accounting for any var_or_dvar variable dependencies\n",
    "vars_deps_and_rename = {\"u10\": {\"u10\": \"u10\"},\n",
    "                        \"v10\": {\"v10\": \"v10\"},\n",
    "                        \"ws10\": {\"u10\": \"u10\", \"v10\": \"v10\"},\n",
    "                        \"wv10\": {\"u10\": \"u10\", \"v10\": \"v10\"},\n",
    "                        \"u100\": {\"u100\": \"u100\"},\n",
    "                        \"v100\": {\"v100\": \"v100\"},\n",
    "                        \"ws100\": {\"u100\": \"u100\", \"v100\": \"v100\"},\n",
    "                        \"wv100\": {\"u100\": \"u100\", \"v100\": \"v100\"},\n",
    "                        \"mslp\": {\"msl\": \"mslp\"},\n",
    "                        \"t2\": {\"t2m\": \"t2\"},\n",
    "                        \"slhf\": {\"slhf\": \"slhf\"},\n",
    "                        \"sshf\": {\"sshf\": \"sshf\"},\n",
    "                        \"nse\": {\"e\": \"nse\"},\n",
    "                        \"vidmf\": {\"p84.162\": \"vidmf\"},\n",
    "                        \"viec\": {\"p64.162\": \"viec\"},\n",
    "                        \"vipile\": {\"p62.162\": \"vipile\"},\n",
    "                        \"vike\": {\"p59.162\": \"vike\"},\n",
    "                        \"tcclw\": {\"tclw\": \"tcclw\"},\n",
    "                        \"tcwv\": {\"tcwv\": \"tcwv\"},\n",
    "                        \"nac\": {\"e\": \"nse\", \"p84.162\": \"vidmf\", \"tcwv\": \"tcwv\"},\n",
    "                        \"blh\": {\"blh\": \"blh\"},\n",
    "                        \"fa\": {\"fal\": \"fa\"},\n",
    "                        \"cbh\": {\"cbh\": \"cbh\"},\n",
    "                        \"tcc\": {\"tcc\": \"tcc\"},\n",
    "                        \"cape\": {\"cape\": \"cape\"},\n",
    "                        \"ci\": {\"cin\": \"ci\"}\n",
    "                       }\n",
    "\n",
    "# Speed (in m/s) for expected rate of exceedance analysis at 100 m\n",
    "speed_eroe = 42.5\n",
    "\n",
    "# Typical power curve for a 100 m turbine with 100 m rotor diameter and \n",
    "# a nameplate rating of around 2500 kW (used to compute gross capacity factor)\n",
    "# Speeds are in m/s, powers are in kW, data from https://www.thewindpower.net\n",
    "speeds_common = np.append(np.linspace(0, 25.5, 52), 999)\n",
    "power_nameplate = 2500\n",
    "# Vestas V100/2600\n",
    "powers_vestas = np.array([0, 0, 0, 0, 0, 0, 21, 63, 115, 172, 239, 318, 405, 550,\n",
    "                          706, 890, 1080, 1283, 1485, 1641, 1796, 1944, 2092, 2225,\n",
    "                          2351, 2440, 2502, 2560, 2584, 2597, 2600, 2600, 2600,\n",
    "                          2600, 2600, 2600, 2600, 2600, 2600, 2600, 2600, 2600,\n",
    "                          2600, 2600, 2600, 2600, 2600, 2600, 2600, 2600, 2600, 0, 0])\n",
    "# Goldwind GW100/2500\n",
    "powers_gw = np.array([0, 0, 0, 0, 0, 6, 34, 65, 101, 165, 235, 320, 409, 530, 655,\n",
    "                      826, 997, 1196, 1394, 1669, 1943, 2170, 2313, 2415, 2458,\n",
    "                      2485, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500,\n",
    "                      2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500,\n",
    "                      2500, 2500, 2500, 2500, 2500, 2500, 0, 0])\n",
    "# GE Energy 2.5-100\n",
    "powers_ge = np.array([0, 0, 0, 0, 0, 0, 10, 80, 160, 250, 340, 460, 590, 770, 952,\n",
    "                      1170, 1389, 1650, 1869, 2100, 2260, 2400, 2487, 2500, 2500,\n",
    "                      2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500,\n",
    "                      2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500,\n",
    "                      2500, 2500, 2500, 2500, 2500, 2500, 0, 0])\n",
    "# Average\n",
    "powers_avg = (powers_vestas/26*25 + powers_gw + powers_ge) / 3\n",
    "\n",
    "# Names of main functions\n",
    "calc_func_names = [\"calc_glass_mean_clim\",\n",
    "                   \"calc_era5_mdp_clim_given_var_or_dvar\",\n",
    "                   \"calc_era5_mdp_clim_stats_given_var_or_dvar\",\n",
    "                   \"calc_era5_wsd_clim\"]\n",
    "extra_func_names = [\"calc_diff\",\n",
    "                    \"calc_era5_orog\",\n",
    "                    \"calc_glass_rolling_avg_of_annual_diff\"]\n",
    "main_func_names = calc_func_names + extra_func_names\n",
    "\n",
    "# Maximum percentage of annual difference files used in computing glass rolling avg\n",
    "# of annual difference which can be NaN DataArray's\n",
    "per_diff_nan_max = 25\n",
    "\n",
    "# Plot-specific arguments for use in the plot_funcs script which can take on None\n",
    "# values (these args are excepted from the check_args_for_none function below)\n",
    "args_plot = [\"extents\", \"mask_period1\", \"mask_period2\", \"vmin\", \"vmax\", \n",
    "             \"vmin_periods\", \"vmax_periods\", \"vmin_diff\", \"vmax_diff\", \n",
    "             \"ax\", \"ax_period1\", \"ax_period2\", \"ax_diff\", \"cfv_data\", \"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09823e61-aa69-407f-9c81-4f032baed773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes for DataArray's within output datasets.\n",
    "attrs_da = {\n",
    "    \n",
    "    # For calc_era5_glass_mean\n",
    "    \"mlai\": {\"abbreviation\": \"MLAI\",\n",
    "             \"full_name\": \"Mean Leaf Area Index\",\n",
    "             \"units\": \"dimensionless\", \n",
    "             \"source\": \"\"},\n",
    "    \"mfapar\": {\"abbreviation\": \"MFAPAR\",\n",
    "               \"full_name\": (\"Mean Fraction of Absorbed Photosynthetically \" +\n",
    "                             \"Active Radiation\"),\n",
    "               \"units\": \"dimensionless\",\n",
    "               \"source\": \"\"},\n",
    "    \n",
    "    # For calc_era5_mdp_clim_given_var_or_dvar\n",
    "    \"u10\": {\"abbreviation\": \"U10\",\n",
    "            \"full_name\": \"Zonal Component of Wind Velocity at 10 m Above Surface\",\n",
    "            \"units\": \"$m s^{-1}$\"},\n",
    "    \"v10\": {\"abbreviation\": \"V10\",\n",
    "            \"full_name\": \"Meridional Component of Wind Velocity at 10 m Above Surface\",\n",
    "            \"units\": \"$m s^{-1}$\"},\n",
    "    \"ws10\": {\"abbreviation\": \"WS10\",\n",
    "             \"full_name\": \"Wind Speed at 10 m Above Surface\",\n",
    "             \"units\": \"$m s^{-1}$\"},\n",
    "    \"wv10\": {\"abbreviation\": \"WV10\",\n",
    "             \"full_name\": \"Wind Velocity at 10 m Above Surface\",\n",
    "             \"units\": \"$m s^{-1}$\"},\n",
    "    \"u100\": {\"abbreviation\": \"U100\",\n",
    "             \"full_name\": \"Zonal Component of Wind Velocity at 100 m Above Surface\",\n",
    "             \"units\": \"$m s^{-1}$\"},\n",
    "    \"v100\": {\"abbreviation\": \"V100\",\n",
    "             \"full_name\": \"Meridional Component of Wind Velocity at 100 m Above Surface\",\n",
    "             \"units\": \"$m s^{-1}$\"},\n",
    "    \"ws100\": {\"abbreviation\": \"WS100\",\n",
    "              \"full_name\": \"Wind Speed at 100 m Above Surface\",\n",
    "              \"units\": \"$m s^{-1}$\"},\n",
    "    \"wv100\": {\"abbreviation\": \"WV100\",\n",
    "              \"full_name\": \"Wind Velocity at 100 m Above Surface\",\n",
    "              \"units\": \"$m s^{-1}$\"},\n",
    "    \"mslp\": {\"abbreviation\": \"MSLP\",\n",
    "             \"full_name\": \"Mean Sea Level Pressure\",\n",
    "             \"units\": \"$Pa$\"},\n",
    "    \"t2\": {\"abbreviation\": \"T2\",\n",
    "           \"full_name\": \"Temperature at 2 m Above Surface\",\n",
    "           \"units\": \"$K$\"},\n",
    "    \"slhf\": {\"abbreviation\": \"SLHF\",\n",
    "             \"full_name\": \"Surface Latent Heat Flux\",\n",
    "             \"units\": \"$W m^{-2}$\"},\n",
    "    \"sshf\": {\"abbreviation\": \"SSHF\",\n",
    "             \"full_name\": \"Surface Sensible Heat Flux\",\n",
    "             \"units\": \"$W m^{-2}$\"},\n",
    "    \"viec\": {\"abbreviation\": \"VIEC\",\n",
    "             \"full_name\": \"Vertical Integral of Energy Conversion\",\n",
    "             \"units\": \"$W m^{-2}$\"},\n",
    "    \"vipile\": {\"abbreviation\": \"VIPILE\",\n",
    "               \"full_name\": \"Vertical Integral of Potential, Internal and Latent Energy\",\n",
    "               \"units\": \"$J m^{-2}$\"},\n",
    "    \"vike\": {\"abbreviation\": \"VIKE\",\n",
    "             \"full_name\": \"Vertical Integral of Kinetic Energy\",\n",
    "             \"units\": \"$J m^{-2}$\"},\n",
    "    \"tcclw\": {\"abbreviation\": \"TCCLW\",\n",
    "              \"full_name\": \"Total Column Cloud Liquid Water\",\n",
    "              \"units\": \"$kg m^{-2}$\"},\n",
    "    \"tcwv\": {\"abbreviation\": \"TCWV\",\n",
    "             \"full_name\": \"Total Column Water Vapour\",\n",
    "             \"units\": \"$kg m^{-2}$\"},\n",
    "    \"nse\": {\"abbreviation\": \"NSE\",\n",
    "            \"full_name\": \"Net Surface Evaporation\",\n",
    "            \"units\": \"$kg m^{-2} s^{-1}$\"},\n",
    "    \"vidmf\": {\"abbreviation\": \"VIDMF\",\n",
    "              \"full_name\": \"Vertical Integral of Divergence of Moisture Flux\",\n",
    "              \"units\": \"$kg m^{-2} s^{-1}$\"},\n",
    "    \"vidcfwf\": {\"abbreviation\": \"VIDCFWF\",\n",
    "                \"full_name\": \"Vertical Integral of Divergence of Cloud Frozen Water Flux\",\n",
    "                \"units\": \"$kg m^{-2} s^{-1}$\"},\n",
    "    \"vidclwf\": {\"abbreviation\": \"VIDCLWF\",\n",
    "                \"full_name\": \"Vertical Integral of Divergence of Cloud Liquid Water Flux\",\n",
    "                \"units\": \"$kg m^{-2} s^{-1}$\"},\n",
    "    \"nac\": {\"abbreviation\": \"NAC\",\n",
    "            \"full_name\": \"Net Atmospheric Condensation\",\n",
    "            \"units\": \"$kg m^{-2} s^{-1}$\"},\n",
    "    \"blh\": {\"abbreviation\": \"BLH\",\n",
    "            \"full_name\": \"Boundary Layer Height\",\n",
    "            \"units\": \"$m$\"},\n",
    "    \"fa\": {\"abbreviation\": \"FA\",\n",
    "           \"full_name\": \"Forecast Albedo\",\n",
    "           \"units\": \"dimensionless\"},\n",
    "    \"cbh\": {\"abbreviation\": \"CBH\",\n",
    "            \"full_name\": \"Cloud Base Height\",\n",
    "            \"units\": \"$m$\"},\n",
    "    \"tcc\": {\"abbreviation\": \"TCC\",\n",
    "            \"full_name\": \"Total Cloud Cover\",\n",
    "            \"units\": \"dimensionless\"},\n",
    "    \"cape\": {\"abbreviation\": \"CAPE\",\n",
    "             \"full_name\": \"Convective Available Potential Energy\",\n",
    "             \"units\": \"$J kg^{-1}$\"},\n",
    "    \"ci\": {\"abbreviation\": \"CI\",\n",
    "           \"full_name\": \"Convective Inhibition\",\n",
    "           \"units\": \"$J kg^{-1}$\"},\n",
    "    \n",
    "    # For calc_era5_mdp_clim_stats_given_var_or_dvar\n",
    "    \"hour_max\": {\"abbreviation\": \"$hour_{{max}}$({})\",\n",
    "                 \"full_name\": \"Hour of Maximum for {}\",\n",
    "                 \"units\": \"UTC {}\"},\n",
    "    \"hour_min\": {\"abbreviation\": \"$hour_{{min}}$({})\",\n",
    "                 \"full_name\": \"Hour of Minimum for {}\",\n",
    "                 \"units\": \"UTC {}\"},\n",
    "    \"max\": {\"abbreviation\": \"$max$({})\",\n",
    "            \"full_name\": \"Maximum for {}\",\n",
    "            \"units\": \"{}\"},\n",
    "    \"max_u\": {\"abbreviation\": \"$max_u$({})\",\n",
    "              \"full_name\": \"Zonal Component of Maximum for {}\",\n",
    "              \"units\": \"{}\"},\n",
    "    \"max_v\": {\"abbreviation\": \"$max_v$({})\",\n",
    "              \"full_name\": \"Meridional Component of Maximum for {}\",\n",
    "              \"units\": \"{}\"},\n",
    "    \"min\": {\"abbreviation\": \"$min$({})\",\n",
    "            \"full_name\": \"Minimum for {}\",\n",
    "            \"units\": \"{}\"},\n",
    "    \"min_u\": {\"abbreviation\": \"$min_u$({})\",\n",
    "              \"full_name\": \"Zonal Component of Minimum for {}\",\n",
    "              \"units\": \"{}\"},\n",
    "    \"min_v\": {\"abbreviation\": \"$min_v$({})\",\n",
    "              \"full_name\": \"Meridional Component of Minimum for {}\",\n",
    "              \"units\": \"{}\"},\n",
    "    \"mean\": {\"abbreviation\": \"$mean$({})\",\n",
    "             \"full_name\": \"Mean for {}\",\n",
    "             \"units\": \"{}\"},\n",
    "    \"mean_u\": {\"abbreviation\": \"$mean_u$({})\",\n",
    "               \"full_name\": \"Zonal Component of Mean for {}\",\n",
    "               \"units\": \"{}\"},\n",
    "    \"mean_v\": {\"abbreviation\": \"$mean_v$({})\",\n",
    "               \"full_name\": \"Meridional Component of Mean for {}\",\n",
    "               \"units\": \"{}\"},\n",
    "    \"range\": {\"abbreviation\": \"$range$({})\",\n",
    "              \"full_name\": \"Range for {}\",\n",
    "              \"units\": \"{}\"},\n",
    "    \n",
    "    # For calc_era5_wsd_clim\n",
    "    \"ws10_mean\": {\"abbreviation\": \"$mean$(WS10)\",\n",
    "                  \"full_name\": \"Mean of Wind Speed at 10 m Above Surface\",\n",
    "                  \"units\": \"$m s^{-1}$\"},\n",
    "    \"ws10_std\": {\"abbreviation\": \"$std$(WS10)\",\n",
    "                 \"full_name\": \"Standard Deviation of Wind Speed at 10 m Above Surface\",\n",
    "                 \"units\": \"$m s^{-1}$\"},\n",
    "    \"c10\": {\"abbreviation\": \"C10\",\n",
    "            \"full_name\": (\"Scale Parameter of Wind Speed Weibull Distribution at \" +\n",
    "                          \"10 m Above Surface\"),\n",
    "            \"units\": \"$m s^{-1}$\"},\n",
    "    \"k10\": {\"abbreviation\": \"K10\",\n",
    "            \"full_name\": (\"Shape Parameter of Wind Speed Weibull Distribution at \" +\n",
    "                          \"$10 m Above Surface$\"),\n",
    "            \"units\": \"dimensionless\"},\n",
    "    \"ws100_mean\": {\"abbreviation\": \"$mean$(WS100)\",\n",
    "                   \"full_name\": \"Mean of Wind Speed at 100 m Above Surface\",\n",
    "                   \"units\": \"$m s^{-1}$\"},\n",
    "    \"ws100_std\": {\"abbreviation\": \"$std$(WS100)\",\n",
    "                  \"full_name\": \"Standard Deviation of Wind Speed at 100 m Above Surface\",\n",
    "                  \"units\": \"$m s^{-1}$\"},\n",
    "    \"c100\": {\"abbreviation\": \"C100\",\n",
    "             \"full_name\": (\"Scale Parameter of Wind Speed Weibull Distribution at \" +\n",
    "                           \"100 m Above Surface\"),\n",
    "             \"units\": \"$m s^{-1}$\"},\n",
    "    \"k100\": {\"abbreviation\": \"K100\",\n",
    "             \"full_name\": (\"Shape Parameter of Wind Speed Weibull Distribution at \" +\n",
    "                           \"100 m Above Surface\"),\n",
    "             \"units\": \"dimensionless\"},\n",
    "    \"eroe100\": {\"abbreviation\": \"EROE100\",\n",
    "                \"full_name\": (f\"Expected Rate of Exceeding {speed_eroe} m/s for Wind \" +\n",
    "                              \"Speed Weibull Distribution at 100 m Above Surface\"),\n",
    "                \"units\": \"dimensionless\"},\n",
    "    \"tgcf100\": {\"abbreviation\": \"TGCF100\",\n",
    "                \"full_name\": (\"Gross Capacity Factor for Typical Turbine at 100 m \" +\n",
    "                              \"Above Surface given the Wind Speed Weibull Distribution \" +\n",
    "                              \"at 100 m Above Surface\"),\n",
    "                \"units\": \"dimensionless\"},\n",
    "    \n",
    "    # For calc_era5_orog\n",
    "    \"lse\": {\"abbreviation\": \"LSE\",\n",
    "            \"full_name\": \"Land Surface Elevation\",\n",
    "            \"units\": \"$m$\"},\n",
    "    \"ssgo\": {\"abbreviation\": \"SSGO\",\n",
    "             \"full_name\": \"Slope of Sub-Gridscale Orography\",\n",
    "             \"units\": \"dimensionless\"}\n",
    "\n",
    "}\n",
    "\n",
    "# Attributes for coordinates within output datasets.\n",
    "coord_attrs = {\n",
    "    \"longitude\": {\"abbreviation\": \"lon\",\n",
    "                  \"full_name\": \"Longitude\",\n",
    "                  \"units\": \"$^{\\circ} E$\"},\n",
    "    \"latitude\": {\"abbreviation\": \"lat\",\n",
    "                 \"full_name\": \"Latitude\",\n",
    "                 \"units\": \"$^{\\circ} N$\"},\n",
    "    \"hour\": {\"abbreviation\": \"h\",\n",
    "             \"full_name\": \"Hour\",\n",
    "             \"units\": \"UTC {}\"},\n",
    "    \"year\": {\"abbreviation\": \"y\",\n",
    "             \"full_name\": \"Year\",\n",
    "             \"units\": \"CE\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c995aa6-b65b-4f19-9ae7-396d4cb1cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Supplementary functions for calculations\n",
    "\n",
    "def create_log_if_directly_executed(time_exec_1up, func_1up=None, func_2up=None, \n",
    "                                    args_1up=None, args_1up_values=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a debugging log for the function which was directly executed.\n",
    "    Designed to be called within the start of other functions.\n",
    "    \n",
    "    Arguments:\n",
    "        time_exec_1up (datetime.datetime): Time of when func_1up was executed.\n",
    "        func_1up (str): Name of function calling this function.\n",
    "        func_2up (str): Name of function calling the function calling this function.\n",
    "        args_1up (list): List of argument names for func_1up.\n",
    "        args_1up_values (dict): Mapping of argument names for func_1up to their\n",
    "            input values.\n",
    "    \n",
    "    Returns:\n",
    "        ../logs/{func_1up}/{calc_funcs_ver}_{func_1up}({args})_{time_str}.txt:\n",
    "            Output log file in logs folder. {calc_funcs_ver} is the \n",
    "            version of the calc_funcs script being used. {args} is the set\n",
    "            of arguments input into {func_1up}. {time_str} is a string giving\n",
    "            the time of when {func_1up} was executed, in \"%Y-%m-%d-%H-%M-%S\" format.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert str(type(time_exec_1up)) == \"<class 'datetime.datetime'>\", \\\n",
    "        \"time_exec_1up must be a datetime.datetime object\"\n",
    "    \n",
    "    if time_exec_1up == None:\n",
    "        time_exec_1up = datetime.today()\n",
    "    \n",
    "    if func_1up == None:\n",
    "        func_1up = inspect.stack()[1][3]\n",
    "        \n",
    "    if func_2up == None:\n",
    "        func_2up = inspect.stack()[2][3]\n",
    "        \n",
    "    if (func_2up == \"<cell line: 1>\") | (func_2up == \"<module>\"):\n",
    "        \n",
    "        if (args_1up == None) | (args_1up_values == None):\n",
    "            frame_1up = inspect.currentframe().f_back\n",
    "            args_1up, _, _, args_1up_values = inspect.getargvalues(frame_1up)\n",
    "        \n",
    "        time_str = time_exec_1up.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        \n",
    "        args_1up_list = []\n",
    "        \n",
    "        for arg in args_1up:\n",
    "            arg_value = args_1up_values[arg]\n",
    "            arg_value_type = str(type(arg_value))\n",
    "            \n",
    "            if ((arg_value_type == \"<class 'xarray.core.dataset.Dataset'>\") | \n",
    "                (arg_value_type == \"<class 'xarray.core.dataarray.DataArray'>\")):\n",
    "                arg_str = arg\n",
    "            else:\n",
    "                arg_str = str(arg_value)\n",
    "                \n",
    "            if arg_value_type == \"<class 'str'>\":\n",
    "                arg_str = arg_str.replace(arg_value, f\"'{arg_value}'\")\n",
    "                \n",
    "            if arg_value_type == \"<class 'function'>\":\n",
    "                arg_str = arg_str.split(\" \")[1]\n",
    "                \n",
    "            args_1up_list.append(arg_str)\n",
    "            \n",
    "        args_1up_str = \", \".join(arg_input for arg_input in args_1up_list)\n",
    "        path_log = (f\"../logs/{func_1up}/({args_1up_str})_\" +\n",
    "                    f\"{time_str}_{calc_funcs_ver}\")\n",
    "        Path(f\"../logs/{func_1up}\").mkdir(parents=True, exist_ok=True)\n",
    "        # File names can only have maximum 255 characters.\n",
    "        logging.basicConfig(level=calc_log_level, filename=path_log[:255], force=True)\n",
    "        \n",
    "        msg_log = f\"CREATED: log file for {func_1up}: {path_log}.\"\n",
    "        logging.info(msg_log)\n",
    "        print(msg_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c12e61-9ef4-420d-9356-6a3281fff55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_handlers_if_directly_executed(func_2up=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Remove all handlers associated with the root logger object if the function was \n",
    "    directly executed. Designed to be called within the end of other functions or \n",
    "    just before each function return where create_log_if_directly_executed \n",
    "    was called within the start of the function. This is used to avoid accidentally \n",
    "    appending additional entries to the created log.\n",
    "    \n",
    "    Arguments:\n",
    "        func_2up (str): Name of function calling the function calling this function.\n",
    "    \"\"\"\n",
    "    \n",
    "    if func_2up == None:\n",
    "        func_2up = inspect.stack()[2][3]\n",
    "        \n",
    "    if (func_2up == \"<cell line: 1>\") | (func_2up == \"<module>\"):\n",
    "        for handler in logging.root.handlers[:]:\n",
    "            logging.root.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95068c24-45da-4d94-9cdf-84550a1b1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminate_if_file_exists(path_output, func_1up=None, func_2up=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Terminates the code if the given path_output already exists. This is to avoid\n",
    "    overwriting existing files or creating duplicates. This function is designed to \n",
    "    be called within one of the calc_func functions.\n",
    "    \n",
    "    Arguments:\n",
    "        path_output (str): Output path for func_1up.\n",
    "        func_1up (str): Name of function calling this function.\n",
    "        func_2up (str): Name of function calling the function calling this function.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert isinstance(path_output, str), \\\n",
    "        \"path_output must have data type str\"\n",
    "    \n",
    "    if func_1up == None:\n",
    "        func_1up = inspect.stack()[1][3]\n",
    "        \n",
    "    if func_2up == None:\n",
    "        func_2up = inspect.stack()[2][3]\n",
    "        \n",
    "    if Path(path_output).exists():\n",
    "        msg_exist = f\"TERMINATED: {func_1up} because file already exists: {path_output}.\"\n",
    "        logging.error(msg_exist)\n",
    "        remove_handlers_if_directly_executed(func_2up)\n",
    "        raise Exception(msg_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c612d4f-7483-420a-b850-19f7bc5cca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_file(ds, path_output, func_2up=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Output the dataset ds as a netcdf4 file into the given path_output.\n",
    "    \n",
    "    Arguments:\n",
    "        ds (xarray.Dataset): Dataset to create output file for.\n",
    "        path_output (str): Output path for the output file of ds.\n",
    "        func_2up (str): Name of function calling the function calling this function.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert str(type(ds)) == \"<class 'xarray.core.dataset.Dataset'>\", \\\n",
    "        \"ds must be an xarray.Dataset\"\n",
    "    assert isinstance(path_output, str), \\\n",
    "        \"path_output must have data type str\"\n",
    "    \n",
    "    if func_2up == None:\n",
    "        func_2up = inspect.stack()[2][3]\n",
    "    \n",
    "    logging.info(f\"Creating: file: {path_output}.\")\n",
    "    path_output_dir = \"/\".join(path_output.split(\"/\")[:-1])\n",
    "    Path(path_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    ds.to_netcdf(path_output)\n",
    "    \n",
    "    if (func_2up == \"<cell line: 1>\") | (func_2up == \"<module>\"):\n",
    "        msg_cre_1up = f\"CREATED: file: {path_output}.\"\n",
    "        logging.info(msg_cre_1up)\n",
    "        print(msg_cre_1up)\n",
    "    else:\n",
    "        msg_cre_2up = f\"CREATED: file for use in {func_2up}: {path_output}.\"\n",
    "        logging.info(msg_cre_2up)\n",
    "        print(msg_cre_2up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abac556-c748-4e0e-9577-11a7e0124fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_args_for_none(func_name, args_1up=None, args_1up_values=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to check whether input arguments are correctly or incorrectly\n",
    "    set to None. Used to avoid erroneous passes in check_args function.\n",
    "    \n",
    "    Arguments:\n",
    "        func_name (str): Name of function to check Nones for.\n",
    "        args_1up (list): List of argument names for func_1up.\n",
    "        args_1up_values (dict): Mapping of argument names for func_1up to their\n",
    "            input values.\n",
    "            \n",
    "    Returns:\n",
    "        AssertionError if any of the input arguments are incorrectly set to None\n",
    "            or incorrectly set to something other than None.\n",
    "    \"\"\"\n",
    "    \n",
    "    if (args_1up == None) | (args_1up_values == None):\n",
    "        frame_1up = inspect.currentframe().f_back\n",
    "        args_1up, _, _, args_1up_values = inspect.getargvalues(frame_1up)\n",
    "        \n",
    "    if func_name in [\"calc_era5_mdp_clim_given_var_or_dvar\", \n",
    "                     \"calc_era5_mdp_clim_stats_given_var_or_dvar\",\n",
    "                     \"calc_era5_wsd_clim\"]:\n",
    "        assert args_1up_values[\"glass_source_pref\"] == None, \\\n",
    "            f\"glass_source_pref must be None if calc_func = {func_name}\"\n",
    "        args_1up.remove(\"glass_source_pref\")\n",
    "    \n",
    "    if func_name in [\"calc_glass_mean_clim\", \"calc_era5_wsd_clim\"]:\n",
    "        assert args_1up_values[\"var_or_dvar\"] == None, \\\n",
    "            f\"var_or_dvar must be None if calc_func = {func_name}\"\n",
    "        args_1up.remove(\"var_or_dvar\")\n",
    "    \n",
    "    # Make exceptions for args in plot_funcs script which can be None.\n",
    "    for arg_plot in args_plot:\n",
    "        try:\n",
    "            args_1up.remove(arg_plot)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    for arg in args_1up:\n",
    "        assert args_1up_values[arg] != None, \\\n",
    "            f\"{arg} cannot be None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500730ee-f637-47fb-861d-617517dbaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_args(\n",
    "    calc_func=None, region=None, period_start=None, period_end=None, period1_start=None, \n",
    "    period1_end=None, period2_start=None, period2_end=None, months_subset=None, \n",
    "    glass_source_pref=None, var_or_dvar=None, year_start=None, year_end=None, \n",
    "    window_size=None, arg_extra=None, hour=None, time=None, param_orog=None,\n",
    "    param_glass_mean=None, var_or_dvar_layer=None, var_or_dvar_type=None, perc=None, \n",
    "    mask_perc_quantile=None, mask_period1=None, mask_period2=None, extents=None, \n",
    "    vmin=None, vmax=None, vmin_periods=None, vmax_periods=None, vmin_diff=None, \n",
    "    vmax_diff=None, ax=None, ax_period1=None, ax_period2=None, ax_diff=None, \n",
    "    cfv_data=None, output=None\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to check whether input arguments are valid.\n",
    "    \n",
    "    Arguments:\n",
    "        calc_func (function): Calculation function to use in analysis. Must be one of: \n",
    "            [calc_glass_mean_clim,\n",
    "            calc_era5_mdp_clim_given_var_or_dvar,\n",
    "            calc_era5_mdp_clim_stats_given_var_or_dvar,\n",
    "            calc_era5_wsd_clim].\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of: [\"ca\", \"sa\", \"wa\"].\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period1_start (str): Start of first period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period1_end (str): End of first period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period2_start (str): Start of second period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period2_end (str): End of second period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "        glass_source_pref (str): Preferred glass data source to use when analysis is \n",
    "            over a period which is completely contained within both the available\n",
    "            AVHRR and MODIS datasets. Must be one of: [\"avhrr\", \"modis\"].\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['u10', 'v10', 'ws10', 'wv10', 'u100', \n",
    "            'v100', 'ws100', 'wv100', 'mslp', 't2', 'slhf', 'sshf', 'nse', 'vidmf', \n",
    "            'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac', 'blh', 'fa', 'cbh', 'tcc', \n",
    "            'cape', 'ci', 'du10', 'dv10', 'dws10', 'dwv10', 'du100', 'dv100', 'dws100', \n",
    "            'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dnse', 'dvidmf', 'dviec', \n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac', 'dblh', 'dfa', 'dcbh', \n",
    "            'dtcc', 'dcape', 'dci'].\n",
    "        hour (int): Hour of mean diurnal profile to compute value for.\n",
    "            Must be one of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "            13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23].\n",
    "        year_start (int): Earliest year to compute the rolling average for.\n",
    "        year_end (int): Latest year to compute the rolling average for.\n",
    "        window_size (int): Rolling window size (in years) to compute average for.\n",
    "            Must be an odd number and greater than or equal to 3.\n",
    "        arg_extra (str or int): Extra plotting argument used to specify which GLASS \n",
    "            parameter to plot, which hour for the mean diurnal profile of an ERA5 \n",
    "            parameter to plot, which statistic of the mean diurnal profile to plot, \n",
    "            or which parameter of the wind speed distribution to plot. Must be one of:\n",
    "            [\"mlai\", \"mfapar\", 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n",
    "            16, 17, 18, 19, 20, 21, 22, 23, \"hour_max\", \"hour_min\", \"max\", \"max_u\", \n",
    "            \"max_v\", \"min\", \"min_u\", \"min_v\", \"mean\", \"mean_u\", \"mean_v\", \"range\", \n",
    "            \"ws10_mean\", \"ws10_std\", \"c10\", \"k10\", \"ws100_mean\", \"ws100_std\", \"c100\", \n",
    "            \"k100\", \"eroe100\", \"tgcf100\"].\n",
    "        var_or_dvar_layer (str): Spatial layer from which to draw ERA5 parameters for \n",
    "            analysis. This is used for the plot_funcs script. Must be one of: \n",
    "            [\"sfc\", \"atm\", \"cld\"].\n",
    "        var_or_dvar_type (str): Whether to analyse the variables themselves or the \n",
    "            change in their mean diurnal profile values as compared with their values\n",
    "            in the previous hour. This is used for the plot_funcs script.\n",
    "            Must be one of: [\"vars\", \"dvars\"].\n",
    "        time (str): Which times of the day to display MDP values for. This\n",
    "            is used for the plot_func_script. Must be one of: \n",
    "            [\"0-5\"/\"night\", \"6-11\"/\"morning\", \"12-17\"/\"afternoon\", \"18-23\"/\"evening\"].\n",
    "    \n",
    "    Returns:\n",
    "        AssertionError if any of the input arguments are invalid.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to check whether input arguments are\" + \n",
    "                      \"valid.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to check whether input arguments into \" +\n",
    "                      f\"{func_1up} are valid.\")\n",
    "    \n",
    "    if calc_func:\n",
    "        assert callable(calc_func), \\\n",
    "            f\"calc_func must be a function and one of: {calc_func_names}\"\n",
    "        assert calc_func.__name__ in calc_func_names, \\\n",
    "            f\"calc_func must be a function and one of: {calc_func_names}\"\n",
    "        \n",
    "    if region:\n",
    "        assert region in [*regions], \\\n",
    "            f\"region must be one of: {[*regions]}\"\n",
    "        \n",
    "    if period_start:\n",
    "        period_start = datetime.strptime(period_start, \"%b-%Y\")\n",
    "        assert period_start >= datetime.strptime(avhrr_earliest, \"%b-%Y\"), \\\n",
    "            f\"period_start must be equal to or later than {avhrr_earliest}\"\n",
    "        \n",
    "    if period_end:\n",
    "        period_end = datetime.strptime(period_end, \"%b-%Y\")\n",
    "        assert period_end <= datetime.strptime(modis_latest, \"%b-%Y\"), \\\n",
    "            f\"period_end must be equal to or earlier than {modis_latest}\"\n",
    "        \n",
    "    if (period_start is not None) & (period_end is not None):\n",
    "        assert period_end >= period_start, \\\n",
    "            \"period_end must be equal to or later than period_start\"\n",
    "        \n",
    "    if months_subset:\n",
    "        assert (isinstance(months_subset, list) & (months_subset != []) & \n",
    "                all(month in months_subsets[\"all\"] for month in months_subset)\n",
    "               ) | (months_subset in [*months_subsets]), \\\n",
    "            (f\"months_subset must be type str and one of: {[*months_subsets]}, or type \" +\n",
    "             \"list and subset of: {} with at least one item\".format(months_subsets[\"all\"]))\n",
    "        \n",
    "    if (period_start is not None) & (period_end is not None) & (months_subset is not None):\n",
    "        dates_in_period = pd.date_range(period_start, period_end, freq = \"MS\")\n",
    "        months_in_period = set(map(int, dates_in_period.strftime(\"%-m\")))\n",
    "        if isinstance(months_subset, str):\n",
    "            months_subset = months_subsets[months_subset]\n",
    "        assert any(month in months_subset for month in months_in_period), \\\n",
    "            \"period(s) must contain at least one month within the given months_subset\"\n",
    "        \n",
    "    if glass_source_pref:\n",
    "        assert glass_source_pref in glass_sources_all, \\\n",
    "            f\"glass_source_pref must be one of: {glass_sources_all}\"\n",
    "    \n",
    "    if var_or_dvar:\n",
    "        assert var_or_dvar in vars_and_dvars_era5_all, \\\n",
    "            f\"var_or_dvar must be one of: {vars_and_dvars_era5_all}\"\n",
    "        \n",
    "    if hour:\n",
    "        assert hour in hours_all, \\\n",
    "            f\"hour must be one of: {hours_all}\"\n",
    "        \n",
    "    if year_start:\n",
    "        year_earliest = int(avhrr_earliest[-4:])\n",
    "        assert isinstance(year_start, int) & (year_start >= year_earliest), \\\n",
    "            f\"year_start must be an integer year equal to or later than {year_earliest}\"\n",
    "        \n",
    "    if year_end:\n",
    "        year_latest = int(modis_latest[-4:])\n",
    "        assert isinstance(year_end, int) & (year_end <= year_latest), \\\n",
    "            f\"year_end must be an integer year equal to or earlier than {year_latest}\"\n",
    "        \n",
    "    if (year_start is not None) & (year_end is not None):\n",
    "        assert year_end >= year_start, \\\n",
    "            \"year_end must be equal to or later than year_start\"\n",
    "        \n",
    "    if window_size:\n",
    "        assert (window_size % 2 == 1) & (window_size >= 3), \\\n",
    "            \"window_size must be an odd integer greater than or equal to 3\"\n",
    "        \n",
    "    if (year_start is not None) & (window_size is not None):\n",
    "        year_earliest_roll = year_earliest + int((window_size-1)/2)\n",
    "        assert year_start >= year_earliest_roll, \\\n",
    "            (f\"year_start must be equal to or later than {year_earliest_roll} \" + \n",
    "             f\"if window_size is {window_size}\")\n",
    "        \n",
    "    if (year_end is not None) & (window_size is not None):\n",
    "        year_latest_roll = year_latest - int((window_size-1)/2)\n",
    "        assert year_end <= year_latest_roll, \\\n",
    "            (f\"year_end must be equal to or earlier than {year_latest_roll} \" + \n",
    "             f\"if window_size is {window_size}\")\n",
    "        \n",
    "    if var_or_dvar_layer:\n",
    "        assert var_or_dvar_layer in [*[*vars_and_dvars_era5.values()][0].keys()], \\\n",
    "            (\"var_or_dvar_layer must be one of: \"+\n",
    "             f\"{[*[*vars_and_dvars_era5.values()][0].keys()]}\")\n",
    "        \n",
    "    if var_or_dvar_type:\n",
    "        assert var_or_dvar_type in [*vars_and_dvars_era5], \\\n",
    "            f\"var_or_dvar_type must be one of: {[*vars_and_dvars_era5]}\"\n",
    "        \n",
    "    if time:\n",
    "        assert time in [*times], \\\n",
    "            f\"time must be one of: {[*times]}\"\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(\"Passed: validity check for input arguments.\")\n",
    "    else:\n",
    "        logging.info(f\"Passed: validity check for input arguments into {func_1up}.\")\n",
    "        \n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02f438-3c69-467c-83f7-cc3dcc22027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_glass_source(period_start, period_end, glass_source_pref):\n",
    "    \n",
    "    \"\"\"\n",
    "    Select which GLASS data source (AVHRR or MODIS) to use.\n",
    "    \n",
    "    Arguments:\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        glass_source_pref (str): Preferred glass data source to use when analysis is \n",
    "            over a period which is completely contained within both the available\n",
    "            AVHRR and MODIS datasets. Must be one of: [\"avhrr\", \"modis\"].\n",
    "        \n",
    "    Returns:\n",
    "        glass_source (str): String indicating whether to use\n",
    "            \"avhrr\" or \"modis\" data for the given period.\n",
    "    \n",
    "    For the given period, select the most appropriate GLASS data source to use \n",
    "    (out of AVHRR and MODIS). Where a period is completely contained within\n",
    "    the time ranges of both AVHRR and MODIS data, glass_source_pref \n",
    "    is selected as the data source for use. Otherwise, AVHRR data \n",
    "    is used where the given period is completely contained only within the time \n",
    "    range of AVHRR data, and conversely for MODIS data. Periods which simultaneously \n",
    "    cover both an AVHRR-only period (i.e. before Mar-2000) and a MODIS-only period \n",
    "    (i.e. after Dec-2018) are prevented from selection since summary statistics \n",
    "    over this range are subject to artefacts from the change in instruments.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(period_start=period_start, period_end=period_end, \n",
    "               glass_source_pref=glass_source_pref)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to select the appropriate glass \" +\n",
    "                      f\"data source for use between {period_start} and {period_end}.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to select the appropriate glass \" + \n",
    "                      f\"data source for use between {period_start} and \" +\n",
    "                      f\"{period_end} in {func_1up}.\")\n",
    "    \n",
    "    period_start = datetime.strptime(period_start, \"%b-%Y\")\n",
    "    period_end = datetime.strptime(period_end, \"%b-%Y\")\n",
    "    \n",
    "    if ((period_start >= datetime.strptime(modis_earliest, \"%b-%Y\")) &\n",
    "        (period_end <= datetime.strptime(avhrr_latest, \"%b-%Y\"))\n",
    "       ):\n",
    "        glass_source = glass_source_pref\n",
    "    elif ((period_start >= datetime.strptime(avhrr_earliest, \"%b-%Y\")) &\n",
    "          (period_end <= datetime.strptime(avhrr_latest, \"%b-%Y\"))\n",
    "         ):\n",
    "        glass_source = \"avhrr\"\n",
    "    elif ((period_start >= datetime.strptime(modis_earliest, \"%b-%Y\")) &\n",
    "          (period_end <= datetime.strptime(modis_latest, \"%b-%Y\"))\n",
    "         ):\n",
    "        glass_source = \"modis\"\n",
    "    else:\n",
    "        raise Exception(f\"If period_start is before {modis_earliest}, \" +\n",
    "                        f\"period_end cannot be after {avhrr_latest} \" +\n",
    "                        \"(since this would cover both an \" +\n",
    "                        \"AVHRR-only and a MODIS-only period)\")\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(\"Selected: {} glass data source for use between {} and {}.\"\n",
    "                     .format(glass_source, period_start.strftime(\"%b-%Y\"),\n",
    "                             period_end.strftime(\"%b-%Y\"))\n",
    "                    )\n",
    "    else:\n",
    "        logging.info(\"Selected: {} glass data source for use between {} and {} in {}.\"\n",
    "                     .format(glass_source, period_start.strftime(\"%b-%Y\"),\n",
    "                             period_end.strftime(\"%b-%Y\"), func_1up)\n",
    "                    )\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)    \n",
    "    return glass_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2636bb-5641-4b8b-8cd9-ef4b1a8d95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_or_dvar_layer_and_type(var_or_dvar):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain the var_or_dvar_layer and var_or_dvar_type classification for the \n",
    "    given var_or_dvar.\n",
    "    \n",
    "    Arguments:\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['u10', 'v10', 'ws10', 'wv10', 'u100', \n",
    "            'v100', 'ws100', 'wv100', 'mslp', 't2', 'slhf', 'sshf', 'nse', 'vidmf', \n",
    "            'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac', 'blh', 'fa', 'cbh', 'tcc', \n",
    "            'cape', 'ci', 'du10', 'dv10', 'dws10', 'dwv10', 'du100', 'dv100', 'dws100', \n",
    "            'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dnse', 'dvidmf', 'dviec', \n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac', 'dblh', 'dfa', 'dcbh', \n",
    "            'dtcc', 'dcape', 'dci'].\n",
    "    \n",
    "    Returns:\n",
    "        var_or_dvar_layer (str): var_or_dvar_layer classification indicating which \n",
    "            spatial layer var_or_dvar primarily sits in. Can be one of: \n",
    "            [\"sfc\", \"atm\", \"cld\"].\n",
    "        var_or_dvar_type (str): var_or_dvar_type classification indicating whether \n",
    "            var_or_dvar is the variable itself (\"vars\") or the change in the value of a\n",
    "            variable as compared with the previous hour (\"dvars\").\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(var_or_dvar=var_or_dvar)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain the var_or_dvar_layer and \" +\n",
    "                      f\"var_or_dvar_type classification of {var_or_dvar}.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain the var_or_dvar_layer and \" +\n",
    "                      f\"var_or_dvar_type classification of {var_or_dvar} for use in \" +\n",
    "                      f\"{func_1up}.\")\n",
    "    \n",
    "    for var_or_dvar_type_ans, dict_ans in vars_and_dvars_era5.items():\n",
    "        for var_or_dvar_layer_ans, list_ans in dict_ans.items():\n",
    "            if var_or_dvar in list_ans:\n",
    "                var_or_dvar_layer = var_or_dvar_layer_ans\n",
    "                var_or_dvar_type = var_or_dvar_type_ans\n",
    "                \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Obtained: {var_or_dvar} classifications of \" +\n",
    "                     f\"{var_or_dvar_layer, var_or_dvar_type}.\")\n",
    "    else:\n",
    "        logging.info(f\"Obtained: {var_or_dvar} classifications of \" +\n",
    "                     f\"{var_or_dvar_layer, var_or_dvar_type} for use in {func_1up}.\")\n",
    "        \n",
    "    remove_handlers_if_directly_executed(func_1up)    \n",
    "    return var_or_dvar_layer, var_or_dvar_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03cfc4-5dda-41d5-be65-34d798824ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ds_attrs(ds, time_exec_1up=None, func_1up=None, func_2up=None,\n",
    "                 args_1up=None, args_1up_values=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Add attributes to the output dataset from one of the main functions.\n",
    "    Designed to be called from within one of the main functions.\n",
    "    \n",
    "    Arguments:\n",
    "        ds (xarray.Dataset): Dataset to add attributes for.\n",
    "        time_exec_1up (datetime.datetime): Time of when func_1up was executed.\n",
    "        func_1up (str): Name of function calling this function.\n",
    "            Must be one of: [calc_glass_mean_clim,\n",
    "            calc_era5_mdp_clim_given_var_or_dvar,\n",
    "            calc_era5_mdp_clim_stats_given_var_or_dvar,\n",
    "            calc_era5_wsd_clim,\n",
    "            calc_diff,\n",
    "            calc_era5_orog,\n",
    "            calc_glass_rolling_avg_of_annual_diff].\n",
    "        func_2up (str): Name of function calling the function calling this function.\n",
    "        args_1up (list): List of argument names for func_1up.\n",
    "        args_1up_values (dict): Mapping of argument names for func_1up to their\n",
    "            input values.\n",
    "    \n",
    "    Add attributes for the abbreviation, full name and units for each coordinate in \n",
    "    the Dataset. Add attributes for the function executed and time that it was \n",
    "    executed to the input dataset itself.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtain arguments if they were not explicitly input.\n",
    "    \n",
    "    if time_exec_1up == None:\n",
    "        time_exec_1up = datetime.today()\n",
    "        \n",
    "    if func_1up == None:\n",
    "        func_1up = inspect.stack()[1][3]\n",
    "        \n",
    "    if func_2up == None:\n",
    "        func_2up = inspect.stack()[2][3]\n",
    "        \n",
    "    if (args_1up == None) | (args_1up_values == None):\n",
    "        frame_1up = inspect.currentframe().f_back\n",
    "        args_1up, _, _, args_1up_values = inspect.getargvalues(frame_1up)\n",
    "        \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    \n",
    "    # The if statement here is redundant since the create_log function also invokes this \n",
    "    # same if statement. But by doing this earlier we avoid having to inspect the frame\n",
    "    # stack an additional time were it not necessary, thus saving some time.\n",
    "    \n",
    "    if (func_2up == \"<cell line: 1>\") | (func_2up == \"<module>\"):\n",
    "        frame_cur = inspect.currentframe()\n",
    "        args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "        create_log_if_directly_executed(time_exec_1up, func_cur, func_1up, \n",
    "                                        args_cur, args_cur_values)\n",
    "    \n",
    "    # Assert ds is an xarray.Dataset and is the output from one of the main functions.\n",
    "    \n",
    "    assert str(type(ds)) == \"<class 'xarray.core.dataset.Dataset'>\", \\\n",
    "        \"ds must be an xarray.Dataset\"\n",
    "    assert func_1up in main_func_names, \\\n",
    "        f\"func_1up must be one of: {main_func_names}\"\n",
    "    \n",
    "    # Logging to indicate this function is being executed.\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to add appropriate attributes to dataset.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to add appropriate attributes to dataset \" +\n",
    "                      f\"output from {func_1up}.\")\n",
    "    \n",
    "    # Add attributes for the coordinates of the input dataset.\n",
    "    \n",
    "    for coord in ds.coords:\n",
    "        ds[coord].attrs = coord_attrs[coord]\n",
    "        if coord == \"hour\":\n",
    "            # Obtain string for timezone relative to UTC (used for hour_max and hour_min).\n",
    "            region = args_1up_values[\"region\"]\n",
    "            tz = regions[region][\"tz\"]\n",
    "            tz_str = str(tz) if tz < 0 else \"+\" + str(tz)\n",
    "            ds[coord].attrs[\"units\"] = ds[coord].attrs[\"units\"].format(tz_str)\n",
    "            \n",
    "    # Add attributes for input dataset indicating the function executed and time executed.\n",
    "    \n",
    "    time_str = time_exec_1up.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    \n",
    "    args_1up_list = []\n",
    "        \n",
    "    for arg in args_1up:\n",
    "        arg_value = args_1up_values[arg]\n",
    "        arg_value_type = str(type(arg_value))\n",
    "        \n",
    "        if ((arg_value_type == \"<class 'xarray.core.dataset.Dataset'>\") | \n",
    "            (arg_value_type == \"<class 'xarray.core.dataarray.DataArray'>\")):\n",
    "            arg_str = arg\n",
    "        else:\n",
    "            arg_str = str(arg_value)\n",
    "            \n",
    "        if arg_value_type == \"<class 'str'>\":\n",
    "            arg_str = arg_str.replace(arg_value, f\"'{arg_value}'\")\n",
    "              \n",
    "        if arg_value_type == \"<class 'function'>\":\n",
    "            arg_str = arg_str.split(\" \")[1]\n",
    "                \n",
    "        args_1up_list.append(arg_str)\n",
    "            \n",
    "    args_1up_str = \", \".join(arg_input for arg_input in args_1up_list)\n",
    "        \n",
    "    ds.attrs = {\"func_executed\": f\"{func_1up}({args_1up_str})\",\n",
    "                \"time_executed\": time_str}\n",
    "    \n",
    "    # Logging to indicate this function was executed successfully.\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(\"Added: attributes to dataset.\")\n",
    "    else:\n",
    "        logging.info(f\"Added: attributes to dataset output from {func_1up}.\")\n",
    "    \n",
    "    # Remove handlers so if log was created, entries won't be accidentally appended later.\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3644ec3-35e8-4f32-9450-f2fbfe8bb44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_era5(ds):\n",
    "    \n",
    "    \"\"\"\n",
    "    Regrid ERA5 xarray dataset.\n",
    "    \n",
    "    Arguments:\n",
    "        ds (xarray.Dataset): Dataset containing ERA5 data, loaded in\n",
    "            with xarray using the netcdf4 engine.\n",
    "                                \n",
    "    Returns:\n",
    "        ds_rg (xarray.Dataset): Dataset with regridded coordinates.\n",
    "        \n",
    "    Shifts each latitude coordinate south and longitude coordinate east by\n",
    "    half a grid cell. This reflects the fact that coordinates in the\n",
    "    original ERA5 dataset defines the north-western corner of each grid\n",
    "    cell, whereas xarray plots assuming the coordinates refer to the centre.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    assert str(type(ds)) == \"<class 'xarray.core.dataset.Dataset'>\", \\\n",
    "        \"ds must be an xarray.Dataset\"\n",
    "    \n",
    "    file_name = ds.encoding[\"source\"]\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} on file to make ERA5 coordinates \" +\n",
    "                      f\"consistent with xarray plotting: {file_name}.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} on file to make ERA5 coordinates \" +\n",
    "                      f\"consistent with xarray plotting for use in {func_1up}: \" +\n",
    "                      f\"{file_name}.\")\n",
    "    \n",
    "    ds_rg = (ds\n",
    "            .assign_coords({\"latitude\": ds.latitude - res_era5/2,\n",
    "                            \"longitude\": (ds.longitude + 180 + res_era5/2) % 360 - 180})\n",
    "            # Redundant measure just in case longitudes exceed 180 degrees.\n",
    "            .sortby(\"longitude\")\n",
    "            )\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Regridded: ERA5 coordinates in file: {file_name}.\")\n",
    "    else:\n",
    "        logging.debug(\"Regridded: ERA5 coordinates in file for use in \" +\n",
    "                      f\"{func_1up}: {file_name}.\")\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)    \n",
    "    return ds_rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f703f44e-a764-44ac-ab1b-3c548af6d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_magnitude(da_x, da_y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate magnitude of 2D vectors given their components.\n",
    "    \n",
    "    Arguments:\n",
    "        da_x (xarray.DataArray): x-component of vectors [m s-1].\n",
    "        da_y (xarray.DataArray): y-component of vectors [m s-1].\n",
    "        \n",
    "    Returns:\n",
    "        da_r (xarray.DataArray): Magnitude of vectors [m s-1].\n",
    "        \n",
    "    Performs a vectorised computation on two different data arrays\n",
    "    containing the x and y component of some vectors and returns\n",
    "    the magnitude of the vectors. Dask is allowed.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    assert str(type(da_x)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_x must be an xarray.DataArray\"\n",
    "    assert str(type(da_y)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_y must be an xarray.DataArray\"\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(\"Executing: {} to calculate vector magnitudes from {} and {}.\"\n",
    "                      .format(func_cur, da_x.name, da_y.name)\n",
    "                     )\n",
    "    else:\n",
    "        logging.debug(\"Executing: {} to calculate vector magnitudes from {} and {} \"\n",
    "                      .format(func_cur, da_x.name, da_y.name) + f\"for use in {func_1up}.\"\n",
    "                     )\n",
    "    \n",
    "    r = lambda x, y: np.sqrt(x**2 + y**2)\n",
    "    da_r = xr.apply_ufunc(r, da_x, da_y, dask = \"allowed\")\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(\"Obtained: vector magnitudes from {} and {}.\"\n",
    "                     .format(da_x.name, da_y.name)\n",
    "                    )\n",
    "    else:\n",
    "        logging.info(\"Obtained: vector magnitudes from {} and {} for use in {}.\"\n",
    "                     .format(da_x.name, da_y.name, func_1up)\n",
    "                    )\n",
    "        \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return da_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fbad50-8e2f-4047-930b-80dad2cb065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_da_mdp_for_and_lag(da_mdp):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain DataArray's with values shifted forward (for) or back (lag) 1 hour from input.\n",
    "    \n",
    "    Arguments:\n",
    "        da_mdp (xarray.DataArray): Mean diurnal profile of a variable.\n",
    "        \n",
    "    Returns:\n",
    "        da_for (xarray.DataArray): DataArray with values shifted forward 1 hour.\n",
    "        da_lag (xarray.DataArray): DataArray with values shifted back 1 hour.\n",
    "        \n",
    "    Obtain da_for and da_lag by reassigning hour coordinates and exploiting the fact\n",
    "    that fixing the mean diurnal profile (MDP) values then moving the corresponding \n",
    "    hour back by one position is equivalent to fixing the hour values then moving the\n",
    "    corresponding MDP values forward by one position (and conversely with moving hours\n",
    "    forward / values back). The coordinates are then sorted for subtraction or addition,\n",
    "    for use in handling the fact that some ERA5 variables are instantaneous while others\n",
    "    are accumulated with hour representing end of accumulation period.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    assert str(type(da_mdp)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_mdp must be an xarray.DataArray\"\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain forwarded and lagged \" +\n",
    "                      f\"{da_mdp.name} DataArray's.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain forwarded and lagged \" +\n",
    "                      f\"{da_mdp.name} DataArray's for use in {func_1up}.\")\n",
    "        \n",
    "    da_mdp_for = (da_mdp\n",
    "                  .assign_coords({\"hour\": (da_mdp.hour - 1) % 24})\n",
    "                  .sortby(\"hour\")\n",
    "                 )\n",
    "    da_mdp_lag = (da_mdp\n",
    "                  .assign_coords({\"hour\": (da_mdp.hour + 1) % 24})\n",
    "                  .sortby(\"hour\")\n",
    "                 )\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Obtained: forwarded and lagged {da_mdp.name} DataArray's.\")\n",
    "    else:\n",
    "        logging.info(f\"Obtained: forwarded and lagged {da_mdp.name} DataArray's \" +\n",
    "                     f\"for use in {func_1up}.\")\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return da_mdp_for, da_mdp_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b24268-8051-42d2-ab35-63414b0d0f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nac(da_nse, da_vidmf, da_tcwv):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate net atmospheric condensation from ERA5 atmospheric variables.\n",
    "    \n",
    "    Arguments:\n",
    "        da_nse (xarray.DataArray): Net surface evaporation [kg m-2 s-1].\n",
    "        da_vidmf (xarray.DataArray): Vertical integral of\n",
    "            divergence of moisture flux [kg m-2 s-1].\n",
    "        da_tcwv (xarray.DataArray): Total column water vapour [kg m-2].\n",
    "        \n",
    "    Returns:\n",
    "        da_nac (xarray.DataArray): Net atmospheric condensation [kg m-2 s-1].\n",
    "        \n",
    "    Performs a vectorised computation on data arrays containing ERA5 atmospheric\n",
    "    variables and returns the net atmospheric condensation. Dask is allowed.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    assert str(type(da_nse)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_nse must be an xarray.DataArray\"\n",
    "    assert str(type(da_vidmf)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_vidmf must be an xarray.DataArray\"\n",
    "    assert str(type(da_tcwv)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_tcwv must be an xarray.DataArray\"\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to calculate net atmospheric condensation \" +\n",
    "                      \"from ERA5 atmospheric variables.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to calculate net atmospheric condensation \" +\n",
    "                      f\"from ERA5 atmospheric variables for use in {func_1up}.\")\n",
    "            \n",
    "    logging.debug(\"Computing: average rate of change in tcwv over consecutive hours to \" +\n",
    "                  \"estimate instantaneous rate of change at each hour for use in \" +\n",
    "                  f\"{func_cur}.\")\n",
    "    da_tcwv_for, da_tcwv_lag = get_da_mdp_for_and_lag(da_tcwv)\n",
    "    # Estimate midpoint of rate of change using mean rate (result is in kg m-2 s-1).\n",
    "    da_tcwv_change = (da_tcwv_for - da_tcwv_lag)/(2*3600)\n",
    "    \n",
    "    def nac(nse, vidmf, tcwv_change):\n",
    "        return nse - vidmf - tcwv_change\n",
    "    da_nse = xr.apply_ufunc(nac, da_nse, da_vidmf, da_tcwv_change, dask = \"allowed\")\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(\"Obtained: net atmospheric condensation from ERA5 atmospheric \" +\n",
    "                     \"variables.\")\n",
    "    else:\n",
    "        logging.info(\"Obtained: net atmospheric condensation from ERA5 atmospheric \" +\n",
    "                     f\"variables for use in {func_1up}.\")\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return da_nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3368e4d4-4098-489f-a96e-412578edf8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_da_range_for_vector_mdp_values(ds_era5_mdp, var_or_dvar):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the mean diurnal profile (MDP) climatology statistics for a particular\n",
    "    variable or change in variable (compared to previous hour) using ERA5 data.\n",
    "    \n",
    "    Arguments:\n",
    "        ds_era5_mdp (xarray.Dataset): xarray Dataset containing MDP values for\n",
    "            the given var_or_dvar.\n",
    "        var_or_dvar (str): Vector variable or value of change in vector variable to \n",
    "            perform calculation over. Must be one of: \n",
    "            ['wv10', 'wv100', 'dwv10', 'dwv100'].\n",
    "                        \n",
    "    Returns:\n",
    "        da_range (xarray.DataArray): Range of vector MDP values.\n",
    "    \n",
    "    Range for vector values here refers to the largest magnitude of all possible \n",
    "    subtractions (corresponding to all possible hourly combinations) between the 24 \n",
    "    vector MDP values. The calculation creates a dataset for each possible subtraction, \n",
    "    merges them into a single dataset along the dimension \"iteration\", computes the\n",
    "    magnitude of the vectors from its components, then finds the maximum magnitude\n",
    "    along the \"iteration\" dimension.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    assert str(type(ds_era5_mdp)) == \"<class 'xarray.core.dataset.Dataset'>\", \\\n",
    "        \"ds_era5_mdp must be an xarray.Dataset\"\n",
    "    assert var_or_dvar in params_vector, \\\n",
    "        f\"var_or_dvar must be one of: {params_vector}\"\n",
    "    assert ((var_or_dvar.replace(\"wv\", \"u\") in [*ds_era5_mdp.keys()]) & \n",
    "            (var_or_dvar.replace(\"wv\", \"v\") in [*ds_era5_mdp.keys()])\n",
    "           ), \\\n",
    "        f\"ds_era5_mdp must be the MDP dataset for {var_or_dvar}\"\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to compute {var_or_dvar} MDP range \" +\n",
    "                      \"DataArray.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to compute {var_or_dvar} MDP range \" +\n",
    "                      f\"DataArray for use in {func_1up}.\")\n",
    "    \n",
    "    if priority == \"speed\":\n",
    "        # Append every possible subtraction to a list, concatenate into a dataset by \n",
    "        # the \"iteration\" dimension, compute magnitudes for each iteration, then find \n",
    "        # maximum magnitude along the iteration dimension.\n",
    "        ds_subtract_list = []\n",
    "        for i in range(0, 23+1):\n",
    "            for j in range(0, 23+1):\n",
    "                ds_subtract_ij = (ds_era5_mdp.isel(hour = i, drop = True) - \n",
    "                                  ds_era5_mdp.isel(hour = j, drop = True))\n",
    "                ds_subtract_list.append(ds_subtract_ij)\n",
    "        ds_subtract = xr.concat(ds_subtract_list, \"iteration\")\n",
    "        da_range = (get_magnitude(ds_subtract[var_or_dvar.replace(\"wv\", \"u\")],\n",
    "                                  ds_subtract[var_or_dvar.replace(\"wv\", \"v\")])\n",
    "                    .max(\"iteration\")\n",
    "                   )\n",
    "        da_range.name = \"range\"\n",
    "        \n",
    "    elif priority == \"memory\":\n",
    "        # For each possible subtraction, first compute the magnitude of that iteration\n",
    "        # and append to a list, then only update the result corresponding to a\n",
    "        # (latitude, longitude) coordinate if a following iteration has a larger\n",
    "        # magnitude at that (latitude, longitude) coordinate.\n",
    "        da_sub_mag_list = []\n",
    "        for i in range(0, 23+1):\n",
    "            for j in range(0, 23+1):\n",
    "                ds_sub_ij = (ds_era5_mdp.isel(hour = i, drop = True) - \n",
    "                             ds_era5_mdp.isel(hour = j, drop = True))\n",
    "                da_sub_mag_ij = get_magnitude(ds_sub_ij[var_or_dvar.replace(\"wv\", \"u\")], \n",
    "                                              ds_sub_ij[var_or_dvar.replace(\"wv\", \"v\")])\n",
    "                da_sub_mag_list.append(da_sub_mag_ij)\n",
    "                da_sub_mag_list = [xr.concat(da_sub_mag_list, \"iteration\")\n",
    "                                   .max(\"iteration\")]\n",
    "        da_range = xr.DataArray(da_sub_mag_list[0], name = \"range\")\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"priority (global variable in settings section) must be one of: \" +\n",
    "                        \"['speed', 'memory'].\")\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Obtained: {var_or_dvar} MDP range DataArray.\")\n",
    "    else:\n",
    "        logging.info(f\"Obtained: {var_or_dvar} MDP range DataArray \" +\n",
    "                     f\"for use in {func_1up}.\")\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return da_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d70f25-ec3c-4832-8aa6-b7f45e6498b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weibull_params(da_mean, da_std):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain Weibull parameters for wind speed distribution from\n",
    "    mean and standard deviation.\n",
    "    \n",
    "    Arguments:\n",
    "        da_mean (xarray.DataArray): Mean wind speed [m s-1].\n",
    "        da_std (xarray.DataArray): Standard deviation of wind speed [m s-1].\n",
    "    \n",
    "    Returns:\n",
    "        da_c (xarray.DataArray): Scale parameter for empirical Weibull fit [m s-1].\n",
    "        da_k (xarray.DataArray): Shape parameter for empirical Weibull fit.\n",
    "    \n",
    "    Performs a vectorised computation on two different data arrays\n",
    "    containing the mean and standard deviation of wind speed and returns\n",
    "    the Weibull scale and shape parameters for the fit. Dask is allowed.\n",
    "    This method uses equations (15) and (16) from an article by Justus et al.\n",
    "    (1977) titled \"Methods for Estimating Wind Speed Frequency Distributions\".\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    assert str(type(da_mean)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_mean must be an xarray.DataArray\"\n",
    "    assert str(type(da_std)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_std must be an xarray.DataArray\"\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(\"Executing: {} to obtain Weibull parameters from {} and {}.\"\n",
    "                      .format(func_cur, da_mean.name, da_std.name)\n",
    "                     )\n",
    "    else:\n",
    "        logging.debug(\"Executing: {} to obtain Weibull parameters from {} and {} \"\n",
    "                      .format(func_cur, da_mean.name, da_std.name) +\n",
    "                      f\"for use in {func_1up}.\"\n",
    "                     )\n",
    "    \n",
    "    k = lambda mean, std: (std / mean)**(-1.086)\n",
    "    da_k = xr.apply_ufunc(k, da_mean, da_std, dask = \"allowed\")\n",
    "    c = lambda mean, k: mean / gamma(1 + 1/k)\n",
    "    da_c = xr.apply_ufunc(c, da_mean, da_k, dask = \"allowed\")\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(\"Obtained: Weibull parameters from {} and {}.\"\n",
    "                     .format(da_mean.name, da_std.name)\n",
    "                    )\n",
    "    else:\n",
    "        logging.info(\"Obtained: Weibull parameters from {} and {} for use in {}.\"\n",
    "                     .format(da_mean.name, da_std.name, func_1up)\n",
    "                    )\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return da_c, da_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ce666-cc81-4e53-86ce-67e6ccb0a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weibull_eroe(da_c, da_k, ws_exc):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain the expected rate of exceedance for a particular wind speed\n",
    "    from fitted Weibull parameters.\n",
    "    \n",
    "    Arguments:\n",
    "        da_c (xarray.DataArray): Scale parameter for empirical Weibull fit [m s-1].\n",
    "        da_k (xarray.DataArray): Shape parameter for empirical Weibull fit.\n",
    "        ws_exc (float or int): Particular wind speed on which to conduct the\n",
    "            expected rate of exceedance analysis [m s-1].\n",
    "        \n",
    "    Returns:\n",
    "        da_eroe (xarray.DataArray): Expected rate of exceedance from Weibull.\n",
    "        \n",
    "    For the given Weibull parameters, the expected rate of exceedance for a \n",
    "    particular wind speed is computed as 1 minus the cumulative probability\n",
    "    distribution for the Weibull fit.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    assert str(type(da_c)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_c must be an xarray.DataArray\"\n",
    "    assert str(type(da_k)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_k must be an xarray.DataArray\"\n",
    "    assert (isinstance(ws_exc, float) | isinstance(ws_exc, int)), \\\n",
    "        \"ws_exc must have data type float or int\"\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug((\"Executing: {} to obtain {} m/s expected rate of exceedance \" +\n",
    "                       \"from {} and {}.\").format(func_cur, ws_exc, da_c.name, da_k.name)\n",
    "                     )\n",
    "    else:\n",
    "        logging.debug((\"Executing: {} to obtain {} m/s expected rate of exceedance \" +\n",
    "                       \"from {} and {} for use in {}.\")\n",
    "                      .format(func_cur, ws_exc, da_c.name, da_k.name, func_1up)\n",
    "                     )\n",
    "    \n",
    "    eroe = lambda c, k: np.exp(-(ws_exc / c)**k)\n",
    "    da_eroe = xr.apply_ufunc(eroe, da_c, da_k, dask = \"allowed\")\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(\"Obtained: {} m/s expected rate of exceedance from {} and {}.\"\n",
    "                     .format(ws_exc, da_c.name, da_k.name)\n",
    "                    )\n",
    "    else:\n",
    "        logging.info((\"Obtained: {} m/s expected rate of exceedance from {} and {} \" +\n",
    "                      \"for use in {}.\").format(ws_exc, da_c.name, da_k.name, func_1up)\n",
    "                    )\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return da_eroe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d0aff-6a42-4101-8ff3-1bab65c0e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gcf(da_ws, speeds, powers, power_max):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the gross capacity factor for a typical wind turbine.\n",
    "    \n",
    "    Arguments:\n",
    "        da_ws (xarray.DataArray): Wind speed data over a period [m s-1].\n",
    "        speeds (numpy.ndarray): Speed bins for the turbine's power curve [m s-1].\n",
    "        powers (numpy.ndarray): Powers for each speed bin according to manufacturer\n",
    "            power curve data [kW].\n",
    "        power_max (float or int): The maximum power which the turbine can produce [kW].\n",
    "        \n",
    "    Returns:\n",
    "        da_gcf (xarray.DataArray): Gross capacity factor over the period.\n",
    "        \n",
    "    First uses the speeds and powers arguments to produce an interpolation\n",
    "    function for the power curve. Then this interpolation function is applied\n",
    "    to obtain the power at each wind speed data point in da_ws. Finally, this\n",
    "    is divided over the maximum power and averaged over the period to obtain\n",
    "    the gross capacity factor.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    assert str(type(da_ws)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "        \"da_ws must be an xarray.DataArray\"\n",
    "    assert speeds.ndim == 1, \\\n",
    "        (f\"speeds argument must be a 1D numpy array with \" +\n",
    "         \"data type 'float64' or 'int64'\")\n",
    "    assert (speeds.dtype == \"float64\") | (speeds.dtype == \"int64\"), \\\n",
    "        f\"speeds must be a 1D numpy array with data type 'float64' or 'int64'\"\n",
    "    assert powers.ndim == 1, \\\n",
    "        f\"powers must be a 1D numpy array with data type 'float64' or 'int64'\"\n",
    "    assert (powers.dtype == \"float64\") | (powers.dtype == \"int64\"), \\\n",
    "        f\"powers must be a 1D numpy array with data type 'float64' or 'int64'\"\n",
    "    assert isinstance(power_max, float) | isinstance(power_max, int), \\\n",
    "        f\"power_max must have data type 'float' or 'int'\"\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(\"Executing: {} to obtain {} gross capacity factor.\"\n",
    "                      .format(func_cur, da_ws.name)\n",
    "                     )\n",
    "    else:\n",
    "        logging.debug(\"Executing: {} to obtain {} gross capacity factor for use in {}.\"\n",
    "                      .format(func_cur, da_ws.name, func_1up)\n",
    "                     )\n",
    "    \n",
    "    power_curve = interp1d(speeds, powers, kind = \"nearest\")\n",
    "    gcf_instant = lambda ws: power_curve(ws) / power_max\n",
    "    da_gcf = (xr.apply_ufunc(gcf_instant, da_ws, dask = \"allowed\")\n",
    "              .mean(\"time\")\n",
    "             )\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(\"Obtained: {} gross capacity factor.\".format(da_ws.name))\n",
    "    else:\n",
    "        logging.info(\"Obtained: {} gross capacity factor for use in {}.\"\n",
    "                     .format(da_ws.name, func_1up)\n",
    "                    )              \n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return da_gcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc01e41-fcdf-41b9-938f-9fdd8e49d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_months_subset_str(months_subset):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain the string representation of months_subset for use in output paths.\n",
    "    \n",
    "    Arguments:\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "            \n",
    "    Returns:\n",
    "        months_subset_str (str): String representation of months_subset.\n",
    "        \n",
    "    If months_subset is one of the string inputs then this function does nothing. But\n",
    "    if months_subset is a list input, this function concatenates the elements of the\n",
    "    list into a string joined by \"-\" and in ascending numerical order.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain string representation of \" +\n",
    "                      f\"{months_subset}.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain string representation of \" +\n",
    "                      f\"{months_subset} for use in {func_1up}.\")\n",
    "    \n",
    "    if isinstance(months_subset, str):\n",
    "        months_subset_str = months_subset\n",
    "    \n",
    "    if isinstance(months_subset, list):\n",
    "        months_subset.sort()\n",
    "        months_subset_str = \"-\".join(str(month) for month in months_subset)\n",
    "        \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Obtained: string representation of {months_subset}.\")\n",
    "    else:\n",
    "        logging.info(f\"Obtained: string representation of {months_subset} \" +\n",
    "                     f\"for use in {func_1up}.\")\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return months_subset_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff81da-7ee5-479a-902f-8c2cc39d68bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_period_data_types(period_start, period_end, months_subset):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert period_start, period_end and months_subset to appropriate data\n",
    "    types for use within calculation functions.\n",
    "    \n",
    "    Arguments:\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "            \n",
    "    Returns:\n",
    "        period_start (datetime.datetime): Start of period to perform calculation over.\n",
    "        period_end (datetime.datetime): End of period to perform calculation over.\n",
    "        months_subset (list): Subset of period to perform calculation over.\n",
    "        \n",
    "    Converts period_start to period_end to datetime.datetime objects. If months_subset\n",
    "    is a list then there is no conversion but if it is a string specifying \"all\" or a \n",
    "    season then it will be converted to a list with the months in that subset.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(period_start=period_start, period_end=period_end, \n",
    "               months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to convert period data types.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to convert period data types \" +\n",
    "                      f\"for use in {func_1up}.\")\n",
    "    \n",
    "    period_start = datetime.strptime(period_start, \"%b-%Y\")\n",
    "    period_end = datetime.strptime(period_end, \"%b-%Y\")\n",
    "    if isinstance(months_subset, str):\n",
    "        months_subset = months_subsets[months_subset]\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Obtained: converted period data types.\")\n",
    "    else:\n",
    "        logging.info(f\"Obtained: converted period data types for use in {func_1up}.\")\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return period_start, period_end, months_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6197b9-b762-45a6-988d-d9ab4d6865dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_for_calc_func(calc_func_name, region, period_start, period_end, \n",
    "                           months_subset, glass_source_pref=None,\n",
    "                           var_or_dvar=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain output path for calc_func function.\n",
    "    \n",
    "    Arguments:\n",
    "        calc_func_name (str): Name of calculation function to obtain path for.\n",
    "            Must be one of: [\"calc_glass_mean_clim\",\n",
    "            \"calc_era5_mdp_clim_given_var_or_dvar\",\n",
    "            \"calc_era5_mdp_clim_stats_given_var_or_dvar\",\n",
    "            \"calc_era5_wsd_clim\"].\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of: [\"ca\", \"sa\", \"wa\"].\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "        glass_source_pref (str): Preferred glass data source to use when analysis is \n",
    "            over a period which is completely contained within both the available\n",
    "            AVHRR and MODIS datasets. Must be one of: [\"avhrr\", \"modis\"].\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['u10', 'v10', 'ws10', 'wv10', 'u100', \n",
    "            'v100', 'ws100', 'wv100', 'mslp', 't2', 'slhf', 'sshf', 'nse', 'vidmf', \n",
    "            'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac', 'blh', 'fa', 'cbh', 'tcc', \n",
    "            'cape', 'ci', 'du10', 'dv10', 'dws10', 'dwv10', 'du100', 'dv100', 'dws100', \n",
    "            'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dnse', 'dvidmf', 'dviec', \n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac', 'dblh', 'dfa', 'dcbh', \n",
    "            'dtcc', 'dcape', 'dci'].\n",
    "            \n",
    "    Returns:\n",
    "        path_output_calc_func (str): Output path for results from calc_func.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    # Assert that input arguments are valid, and create path for months_subset.\n",
    "    \n",
    "    assert calc_func_name in calc_func_names, \\\n",
    "        f\"calc_func_name must be one of: {calc_func_names}\"\n",
    "    check_args_for_none(calc_func_name, args_cur, args_cur_values)\n",
    "    check_args(region=region, period_start=period_start, period_end=period_end, \n",
    "               months_subset=months_subset, glass_source_pref=glass_source_pref,\n",
    "               var_or_dvar=var_or_dvar)\n",
    "    \n",
    "    months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain {calc_func_name} output path.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain {calc_func_name} output path \" +\n",
    "                      f\"for use in {func_1up}.\")\n",
    "\n",
    "    # Define path stem.\n",
    "    \n",
    "    path_output_calc_func = (f\"../data_processed/{calc_func_name[5:None]}/\" +\n",
    "                             f\"{calc_funcs_ver}_calc_{region}_{period_start}_\" + \n",
    "                             f\"{period_end}_{months_subset_str}_\")\n",
    "    \n",
    "    # Append path endings.\n",
    "    \n",
    "    if calc_func_name == \"calc_glass_mean_clim\":\n",
    "        glass_source = select_glass_source(period_start=period_start, \n",
    "                                           period_end=period_end, \n",
    "                                           glass_source_pref=glass_source_pref)\n",
    "        path_output_calc_func += f\"glass-mean_{glass_source}.nc\"\n",
    "        \n",
    "    if calc_func_name == \"calc_era5_mdp_clim_given_var_or_dvar\":\n",
    "        path_output_calc_func += f\"era5-mdp_{var_or_dvar}.nc\"\n",
    "        \n",
    "    if calc_func_name == \"calc_era5_mdp_clim_stats_given_var_or_dvar\":\n",
    "        path_output_calc_func += f\"era5-mdp_{var_or_dvar}_stats.nc\"\n",
    "        \n",
    "    if calc_func_name == \"calc_era5_wsd_clim\":\n",
    "        path_output_calc_func += f\"era5-wsd.nc\"\n",
    "        \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Obtained: {calc_func_name} output path.\")\n",
    "    else:\n",
    "        logging.info(f\"Obtained: {calc_func_name} output path for use in {func_1up}.\")\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return path_output_calc_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c00ab-feb2-4125-89ff-a3084aab1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_for_calc_diff(calc_func_name, region, period1_start, period1_end,\n",
    "                           period2_start, period2_end, months_subset,\n",
    "                           glass_source_pref=None, var_or_dvar=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain output path for calc_diff function.\n",
    "    \n",
    "    Arguments:\n",
    "        calc_func_name (str): Name of calculation function to compute difference in\n",
    "            results for. Must be one of: [\"calc_glass_mean_clim\",\n",
    "            \"calc_era5_mdp_clim_given_var_or_dvar\",\n",
    "            \"calc_era5_mdp_clim_stats_given_var_or_dvar\",\n",
    "            \"calc_era5_wsd_clim\"].\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of: [\"ca\", \"sa\", \"wa\"].\n",
    "        period1_start (str): Start of first period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period1_end (str): End of first period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period2_start (str): Start of second period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period2_end (str): End of second period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "        glass_source_pref (str): Preferred glass data source to use when analysis is \n",
    "            over a period which is completely contained within both the available\n",
    "            AVHRR and MODIS datasets. Must be one of: [\"avhrr\", \"modis\"].\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['u10', 'v10', 'ws10', 'wv10', 'u100', \n",
    "            'v100', 'ws100', 'wv100', 'mslp', 't2', 'slhf', 'sshf', 'nse', 'vidmf', \n",
    "            'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac', 'blh', 'fa', 'cbh', 'tcc', \n",
    "            'cape', 'ci', 'du10', 'dv10', 'dws10', 'dwv10', 'du100', 'dv100', 'dws100', \n",
    "            'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dnse', 'dvidmf', 'dviec', \n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac', 'dblh', 'dfa', 'dcbh', \n",
    "            'dtcc', 'dcape', 'dci'].\n",
    "            \n",
    "    Returns:\n",
    "        path_output_calc_diff (str): Output path for results from calc_diff.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    # Assert that input arguments are valid, and create path for months_subset.\n",
    "    \n",
    "    assert calc_func_name in calc_func_names, \\\n",
    "        f\"calc_func_name must be one of: {calc_func_names}\"\n",
    "    check_args_for_none(calc_func_name, args_cur, args_cur_values)\n",
    "    check_args(region=region, period_start=period1_start, period_end=period1_end,\n",
    "               months_subset=months_subset, var_or_dvar=var_or_dvar, \n",
    "               glass_source_pref=glass_source_pref)\n",
    "    check_args(period_start=period2_start, period_end=period2_end, \n",
    "               months_subset=months_subset)\n",
    "    \n",
    "    months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain calc_diff output path \" +\n",
    "                      f\"corresponding to {calc_func_name}.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain calc_diff output path \" +\n",
    "                      f\"corresponding to {calc_func_name} for use in {func_1up}.\")\n",
    "    \n",
    "    # Define path stem.\n",
    "    \n",
    "    path_output_calc_diff = (f\"../data_processed/{calc_func_name[5:None]}/\" + \n",
    "                             f\"{calc_funcs_ver}_diff_{region}_{period1_start}_\" +\n",
    "                             f\"{period1_end}_{period2_start}_{period2_end}_\" +\n",
    "                             f\"{months_subset_str}_\")\n",
    "    \n",
    "    # Append path endings.\n",
    "    \n",
    "    if calc_func_name == \"calc_glass_mean_clim\":\n",
    "        glass_source_period1 = select_glass_source(period_start=period1_start, \n",
    "                                                   period_end=period1_end, \n",
    "                                                   glass_source_pref=glass_source_pref)\n",
    "        glass_source_period2 = select_glass_source(period_start=period2_start, \n",
    "                                                   period_end=period2_end, \n",
    "                                                   glass_source_pref=glass_source_pref)\n",
    "        \n",
    "        if glass_source_period1 == glass_source_period2:\n",
    "            glass_source = glass_source_period1\n",
    "        else:\n",
    "            glass_source = \"mixed\"\n",
    "            \n",
    "        path_output_calc_diff += f\"glass-mean_{glass_source}.nc\"\n",
    "        \n",
    "    if calc_func_name == \"calc_era5_mdp_clim_given_var_or_dvar\":\n",
    "        path_output_calc_diff += f\"era5-mdp_{var_or_dvar}.nc\"\n",
    "        \n",
    "    if calc_func_name == \"calc_era5_mdp_clim_stats_given_var_or_dvar\":\n",
    "        path_output_calc_diff += f\"era5-mdp_{var_or_dvar}_stats.nc\"\n",
    "        \n",
    "    if calc_func_name == \"calc_era5_wsd_clim\":\n",
    "        path_output_calc_diff += f\"era5-wsd.nc\"\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Obtained: calc_diff output path corresponding to \" +\n",
    "                     f\"{calc_func_name}.\")\n",
    "    else:\n",
    "        logging.info(f\"Obtained: calc_diff output path corresponding to \" +\n",
    "                     f\"{calc_func_name} for use in {func_1up}.\")\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return path_output_calc_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599df3ae-e230-42e7-990e-6f1c1faeeb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_for_era5_orog():\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain output path for calc_era5_orog function.\n",
    "            \n",
    "    Returns:\n",
    "        path_output_orog (str): Output path for results from calc_era5_orog.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain calc_era5_orog output path.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain calc_era5_orog output path \" +\n",
    "                      f\"for use in {func_1up}.\")\n",
    "        \n",
    "    # Obtain output path.\n",
    "    \n",
    "    path_output_orog = (f\"../data_processed/era5_orog/{calc_funcs_ver}_\" +\n",
    "                        \"calc_global_era5-orog.nc\")\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Obtained: calc_era5_orog output path.\")\n",
    "    else:\n",
    "        logging.info(f\"Obtained: calc_era5_orog output path for use in {func_1up}.\")\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return path_output_orog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772093a-928d-40e7-993d-9711923e71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_for_calc_glass_rolling(region, year_start, year_end, months_subset, \n",
    "                                    window_size, glass_source_pref):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain output path for calc_glass_rolling_avg_of_annual_diff function.\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "        year_start (int): Earliest year to compute the rolling average for.\n",
    "        year_end (int): Latest year to compute the rolling average for.\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "        window_size (int): Rolling window size (in years) to compute average for.\n",
    "            Must be an odd number and greater than or equal to 3.\n",
    "        glass_source_pref (str): Preferred glass data source to use when analysis is \n",
    "            over a period which is completely contained within both the available\n",
    "            AVHRR and MODIS datasets. Must be one of: [\"avhrr\", \"modis\"].\n",
    "            \n",
    "    Returns:\n",
    "        path_output_glass_roll (str): Output path for results from \n",
    "            calc_glass_rolling_avg_of_annual_diff.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    # Assert that input arguments are valid, and create path for months_subset.\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(region=region, year_start=year_start, year_end=year_end, \n",
    "               months_subset=months_subset, window_size=window_size, \n",
    "               glass_source_pref=glass_source_pref)\n",
    "    \n",
    "    months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain \" \n",
    "                      + \"calc_glass_rolling_avg_of_annual_diff output path.\")\n",
    "    else:\n",
    "        logging.debug(f\"Executing: {func_cur} to obtain \" +\n",
    "                      \"calc_glass_rolling_avg_of_annual_diff output path for\" +\n",
    "                      f\"use in {func_1up}.\")\n",
    "        \n",
    "    # Obtain output path.\n",
    "    \n",
    "    path_output_glass_roll = (\"../data_processed/glass_rolling_avg_of_annual_diff/\" +\n",
    "                              f\"{calc_funcs_ver}_calc_{region}_{year_start}_\" +\n",
    "                              f\"{year_end}_{months_subset_str}_{window_size}-year_\" +\n",
    "                              f\"glass-rolling-diff_pref-{glass_source_pref}.nc\")\n",
    "        \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Obtained: calc_glass_rolling_avg_of_annual_diff output path.\")\n",
    "    else:\n",
    "        logging.info(\"Obtained: calc_glass_rolling_avg_of_annual_diff output path \" +\n",
    "                     f\"for use in {func_1up}.\")\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)\n",
    "    return path_output_glass_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b0d4c-a3a7-4632-8b0a-90a15b7bc35d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Main calculation functions\n",
    "\n",
    "def calc_glass_mean_clim(region, period_start, period_end, months_subset, \n",
    "                         glass_source_pref, var_or_dvar=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate mean leaf area index (MLAI) and mean fraction of absorbed\n",
    "    photosynthetically active radiation (MFAPAR) climatology using GLASS data.\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "        glass_source_pref (str): Preferred glass data source to use when analysis is \n",
    "            over a period which is completely contained within both the available\n",
    "            AVHRR and MODIS datasets. Must be one of: [\"avhrr\", \"modis\"].\n",
    "        var_or_dvar (None): This argument is not used for this analysis. It is used \n",
    "            for applying the calc_diff function over an arbitrary calc_func.\n",
    "                        \n",
    "    Returns:\n",
    "        ../data_processed/glass_mean_clim/{calc_funcs_ver}_calc_{region}_{period_start}_\n",
    "        {period_end}_{months_subset_str}_glass-mean_{glass_source}.nc:\n",
    "            Output netcdf4 file in data_processed folder containing both MLAI and\n",
    "            MFAPAR. {calc_funcs_ver} is the version of the calc_funcs script being\n",
    "            used. {months_subset_str} is a string representing the list of selected \n",
    "            months to use as a subset. {glass_source} is automatically selected \n",
    "            between [\"avhrr\", \"modis\"] based on the selected period. \n",
    "    \n",
    "    For each grid cell, calculate the mean glass climatology (MLAI and MFAPAR). These\n",
    "    values are computed over the period from period_start to period_end (inclusive),\n",
    "    and only using a subset of data within this period (if months_subset not \"all\" is \n",
    "    specified). The calculation uses 8-day satellite HDF data from the data_raw\n",
    "    folder as input, then outputs the result as a netcdf4 file into the\n",
    "    data_processed folder.\n",
    "    \n",
    "    Where a period is completely contained within the time ranges of both AVHRR and \n",
    "    MODIS data, glass_source_pref is selected as the data source for use. Otherwise, \n",
    "    AVHRR data is used where the given period is completely contained only within \n",
    "    the time range of AVHRR data, and conversely for MODIS data. Periods which \n",
    "    simultaneously cover both an AVHRR-only period (i.e. before Mar-2000) and \n",
    "    a MODIS-only period (i.e. after Dec-2018) are prevented from selection since \n",
    "    summary statistics over this range are subject to artefacts from the change in \n",
    "    instruments.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    # Assert that input arguments are valid, select the appropriate data source \n",
    "    # (AVHRR or MODIS) to use depending on period, and create path for months_subset.\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(region=region, period_start=period_start, period_end=period_end,\n",
    "               months_subset=months_subset, glass_source_pref=glass_source_pref)\n",
    "    \n",
    "    glass_source = select_glass_source(period_start=period_start, \n",
    "                                       period_end=period_end,\n",
    "                                       glass_source_pref=glass_source_pref)\n",
    "    months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Executing: {func_cur} to obtain {months_subset_str} \" +\n",
    "                     f\"climatology of MLAI and MFAPAR using {glass_source} data \" + \n",
    "                     f\"between {period_start} and {period_end}.\")\n",
    "    else:\n",
    "        logging.info(f\"Executing: {func_cur} to obtain {months_subset_str} \" +\n",
    "                     f\"climatology of MLAI and MFAPAR using {glass_source} data \" + \n",
    "                     f\"between {period_start} and {period_end} for use in {func_1up}.\")\n",
    "    \n",
    "    # Define the output path, convert period_start and period_end to\n",
    "    # datetime.datetime objects, and months_subset to list if a str was used as input.\n",
    "    \n",
    "    path_output_glass_mean = get_path_for_calc_func(\n",
    "        calc_func_name=func_cur, region=region, period_start=period_start, \n",
    "        period_end=period_end, months_subset=months_subset, \n",
    "        glass_source_pref=glass_source_pref, var_or_dvar=var_or_dvar)\n",
    "    terminate_if_file_exists(path_output_glass_mean, func_cur, func_1up)\n",
    "    \n",
    "    period_start, period_end, months_subset = convert_period_data_types(\n",
    "        period_start=period_start, period_end=period_end, months_subset=months_subset)\n",
    "\n",
    "    # The two functions below are used with xarray's open_mfdataset for parallel\n",
    "    # computing using dask. The region and times (period with months_subset) are\n",
    "    # selected within separate functions and uses different logic as compared with\n",
    "    # filtering in the ERA5 datasets. This is because each GLASS file contains\n",
    "    # global data whereas the ERA5 datasets were downloaded for each local region.\n",
    "    \n",
    "    def filter_glass_files(file_name):\n",
    "        # This function is used as a mask in conjunction with the default python\n",
    "        # filter function later, in order to select out the raw data files within\n",
    "        # the input period and climatological subset within the original function \n",
    "        # arguments (by using dates contained within each file name). This is done \n",
    "        # (as opposed to using open_mfdataset then filtering) for scalability reasons \n",
    "        # since we may need to persist the data in RAM to speed up certain computations.\n",
    "        time = file_name[-12:-4]\n",
    "        time = datetime.strptime(time, \"%Y-%j\")\n",
    "        if ((time.month in months_subset) &\n",
    "            # We add an extra month to period_end here because period_end was\n",
    "            # specified as a month, and conversion into a datetime object\n",
    "            # defaults to the first (rather than last) day of that month.\n",
    "            (period_start <= time < period_end + relativedelta(months=1))\n",
    "           ):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def preprocess_glass(ds):\n",
    "        # This function is used for the preprocess argument in open_mfdataset.\n",
    "        # It uses the dates in each raw data file name to assign a time dimension\n",
    "        # and coordinate for the corresponding dataset. This then forms the\n",
    "        # dimension along which the files are combined into a single dataset\n",
    "        # and rechunked. This function also selects out the input region within\n",
    "        # the original function arguments before the files are concatenated using\n",
    "        # open_mfdataset (this is again done for persist scalability).\n",
    "        file_name = ds.encoding[\"source\"]\n",
    "        logging.debug(f\"Preprocessing: file for use in {func_cur}: {file_name}.\")\n",
    "        time = datetime.strptime(file_name[-12:-4], \"%Y-%j\")\n",
    "        ds = (ds\n",
    "              .expand_dims({\"time\": [time]})\n",
    "              # Redundant measure just in case longitudes exceed 180 degrees.\n",
    "              .assign_coords({\"x\": (ds.x + 180) % 360 - 180})\n",
    "              .sortby(\"x\")\n",
    "              .rename({\"x\": \"longitude\", \"y\": \"latitude\"})\n",
    "              .drop_vars(\"spatial_ref\")\n",
    "              .squeeze(\"band\", drop=True)\n",
    "              )\n",
    "        ds = ds.sel(longitude=slice(regions[region][\"extent\"][0],\n",
    "                                    regions[region][\"extent\"][1]),\n",
    "                    latitude=slice(regions[region][\"extent\"][3],\n",
    "                                   regions[region][\"extent\"][2])\n",
    "                   )\n",
    "        return ds\n",
    "    \n",
    "    # The following code creates the mean climatology datasets for each GLASS\n",
    "    # variable, by using the previous functions along with open_mfdataset.\n",
    "    # An initally empty dataset is iteratively appended then merged so that\n",
    "    # future scalability is possible in case one wishes to add more GLASS\n",
    "    # variables to the params_glass_mean global python variable.\n",
    "    \n",
    "    datasets = []\n",
    "    \n",
    "    for param_glass_mean in params_glass_mean:\n",
    "        param_glass = param_glass_mean[1:]\n",
    "        files_glass_all = glob(f\"../data_raw/global_glass-{param_glass}-\" +\n",
    "                               f\"{glass_source}_8-day/global_glass-\" +\n",
    "                               f\"{param_glass}-{glass_source}*\")\n",
    "        \n",
    "        if len(files_glass_all) != number_of_glass_files[param_glass][glass_source]:\n",
    "            msg_files = (\n",
    "                f\"WARNING: Expected \" +\n",
    "                f\"{number_of_glass_files[param_glass][glass_source]} files in \" +\n",
    "                f\"../data_raw/global_glass-{param_glass}-{glass_source}_8-day/ \" +\n",
    "                f\"but got {len(files_glass_all)}. This could be because the \" +\n",
    "                \"data_download.ipynb notebook was not run properly. Or it could be \" +\n",
    "                \"that the number of GLASS files on the server from which the data \" +\n",
    "                \"was downloaded has changed. Or it may be that the user has changed \" +\n",
    "                \"the period coverage from the original values in the \" +\n",
    "                \"data_download.ipynb notebook. Alternatively, the user may have \" +\n",
    "                \"changed some files in this folder.\"\n",
    "            )\n",
    "            logging.warning(msg_files)\n",
    "            print(msg_files)\n",
    "            \n",
    "        logging.debug(f\"Filtering: {param_glass} files from data_raw folder \" +\n",
    "                      f\"for use in {func_cur}.\")\n",
    "        files_glass_filtered = list(filter(filter_glass_files, files_glass_all))\n",
    "        files_glass_filtered.sort()\n",
    "        \n",
    "        # This if statement is to ensure an array full of NaNs is returned for MFAPAR\n",
    "        # when the input period includes 1981 or 2021. At the time of writing, GLASS\n",
    "        # FAPAR data is not available for these years.\n",
    "        \n",
    "        if (param_glass == \"fapar\") & (\n",
    "            (period_start < datetime.strptime(fapar_earliest, \"%b-%Y\")) |\n",
    "            (period_end > datetime.strptime(fapar_latest, \"%b-%Y\"))\n",
    "        ):\n",
    "            # This line exploits the fact that the for loop runs in sequence and \n",
    "            # will have computed MLAI before it attempts to compute MFAPAR. \n",
    "            # Therefore an MLAI array with appropriate coordinates already exists \n",
    "            # in the datasets list and can be used to create an array of NaNs.\n",
    "            ds_mean = (datasets[0]\n",
    "                       .where(np.isnan(datasets[0][\"mlai\"]))\n",
    "                       .rename({\"mlai\": \"mfapar\"})\n",
    "                      )\n",
    "            msg_avail = (\"WARNING: GLASS FAPAR data is not available for dates \" +\n",
    "                         f\"on or before {fapar_earliest}, and dates on or after \" +\n",
    "                         f\"{fapar_latest}. A data array with NaNs was returned \" +\n",
    "                         \"for MFAPAR instead.\")\n",
    "            logging.warning(msg_avail)\n",
    "            print(msg_avail)\n",
    "            \n",
    "        else:\n",
    "            logging.debug(f\"Opening: {param_glass} files from data_raw folder for use \" +\n",
    "                          f\"in {func_cur}.\")\n",
    "            ds_mean = (xr.open_mfdataset(files_glass_filtered, engine = \"rasterio\",\n",
    "                                         preprocess=preprocess_glass, parallel = True)\n",
    "                       # Rechunking after open_mfdataset here is actually bad practice\n",
    "                       # since it requires extra computation, but the chunks argument\n",
    "                       # for open_mfdataset doesn't seem to work here for some reason.\n",
    "                       .chunk(chunks = {\"time\": chunksize})\n",
    "                      )\n",
    "            if priority == \"speed\":\n",
    "                ds_mean = ds_mean.persist()\n",
    "            \n",
    "            logging.debug(f\"Computing: {param_glass_mean} values for use in {func_cur}.\")\n",
    "            ds_mean = (ds_mean\n",
    "                       .mean(\"time\")\n",
    "                       .rename({\"band_data\": f\"{param_glass_mean}\"})\n",
    "                      )\n",
    "            \n",
    "        datasets.append(ds_mean)\n",
    "        \n",
    "    logging.debug(\"Merging: glass mean datasets.\")\n",
    "    ds_glass_mean = xr.merge(datasets)\n",
    "    \n",
    "    # Add attributes to each DataArray in Dataset.\n",
    "    \n",
    "    logging.info(\"Adding: attributes for each DataArray within output \"+\n",
    "                 f\"Dataset from {func_cur}.\")\n",
    "    for da_name in [*ds_glass_mean.keys()]:\n",
    "            ds_glass_mean[da_name].attrs = copy.deepcopy(attrs_da[da_name])\n",
    "            ds_glass_mean[da_name].attrs[\"source\"] = glass_source\n",
    "            \n",
    "    # Add attributes to Dataset.\n",
    "    \n",
    "    add_ds_attrs(ds_glass_mean, time_exec, func_cur, func_1up, args_cur, args_cur_values)\n",
    "    \n",
    "    # Create output file in data_processed folder.\n",
    "    \n",
    "    create_output_file(ds_glass_mean, path_output_glass_mean, func_1up)\n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be56ea3-f0ec-4abf-914b-81440dbb2825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_era5_mdp_clim_given_var_or_dvar(region, period_start, period_end, \n",
    "                                         months_subset, var_or_dvar, \n",
    "                                         glass_source_pref=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the mean diurnal profile (MDP) climatology for a particular\n",
    "    variable or change in variable (compared to previous hour) using ERA5 data.\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['u10', 'v10', 'ws10', 'wv10', 'u100', \n",
    "            'v100', 'ws100', 'wv100', 'mslp', 't2', 'slhf', 'sshf', 'nse', 'vidmf', \n",
    "            'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac', 'blh', 'fa', 'cbh', 'tcc', \n",
    "            'cape', 'ci', 'du10', 'dv10', 'dws10', 'dwv10', 'du100', 'dv100', 'dws100', \n",
    "            'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dnse', 'dvidmf', 'dviec', \n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac', 'dblh', 'dfa', 'dcbh', \n",
    "            'dtcc', 'dcape', 'dci'].\n",
    "        glass_source_pref (None): This argument is not used for this analysis. It is used \n",
    "            for applying the calc_diff function over an arbitrary calc_func.\n",
    "                        \n",
    "    Returns:\n",
    "        ../data_processed/era5_mdp_clim_given_var_or_dvar/{calc_funcs_ver}_calc_{region}_\n",
    "        {period_start}_{period_end}_{months_subset_str}_era5-mdp_{var_or_dvar}.nc:\n",
    "            Output netcdf4 file in data_processed folder containing the MDP for\n",
    "            var_or_dvar. {calc_funcs_ver} is the version of the calc_funcs script\n",
    "            being used. {months_subset_str} is a string representing the list of \n",
    "            selected months to use as a subset.\n",
    "    \n",
    "    For each grid cell, calculate the MDP for the selected var_or_dvar. The MDP\n",
    "    values are computed over the period from period_start to period_end (inclusive),\n",
    "    and only using a subset of data within this period (if months_subset not \"all\" is\n",
    "    specified). The calculation uses monthly averaged reanalysis by hour of day netcdf4\n",
    "    data from the data_raw folder as input, then outputs the result as a netcdf4 file\n",
    "    into the data_processed folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    # Assert that input arguments are valid, and create path for months_subset.\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(region=region, period_start=period_start, period_end=period_end,\n",
    "               months_subset=months_subset, var_or_dvar=var_or_dvar)\n",
    "    \n",
    "    months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Executing: {func_cur} to obtain {months_subset_str} climatology \" +\n",
    "                     f\"of {var_or_dvar} MDP between {period_start} and {period_end}.\")\n",
    "    else:\n",
    "        logging.info(f\"Executing: {func_cur} to obtain {months_subset_str} climatology \" +\n",
    "                     f\"of {var_or_dvar} MDP between {period_start} and {period_end} \" +\n",
    "                     f\"for use in {func_1up}.\")\n",
    "    \n",
    "    # Define the output path, convert period_start and period_end to\n",
    "    # datetime.datetime objects, and months_subset to list if a str was used as input.\n",
    "    \n",
    "    path_output_mdp_clim = get_path_for_calc_func(\n",
    "        calc_func_name=func_cur, region=region, period_start=period_start, \n",
    "        period_end=period_end, months_subset=months_subset, var_or_dvar=var_or_dvar)\n",
    "    terminate_if_file_exists(path_output_mdp_clim, func_cur, func_1up)\n",
    "    \n",
    "    period_start, period_end, months_subset = convert_period_data_types(\n",
    "        period_start=period_start, period_end=period_end, months_subset=months_subset)\n",
    "    \n",
    "    # Obtain the var_or_dvar_layer and var_or_dvar_type classifications for the given \n",
    "    # var_or_dvar. This is used later to identify which folder to open files from, \n",
    "    # and whether to compute changes since the previous hour.\n",
    "    \n",
    "    var_or_dvar_layer, var_or_dvar_type = get_var_or_dvar_layer_and_type(\n",
    "        var_or_dvar=var_or_dvar)\n",
    "    if var_or_dvar_type == \"vars\":\n",
    "        var = var_or_dvar\n",
    "    if var_or_dvar_type == \"dvars\":\n",
    "        var = var_or_dvar[1:]\n",
    "    \n",
    "    # The two functions below are used with xarray's open_mfdataset for parallel\n",
    "    # computing using dask. Together they select out the relevant files to read\n",
    "    # and persist in memory only the data which is necessary for the computation.\n",
    "    \n",
    "    def filter_era5_month_hour_files(file_name):\n",
    "        # This function is used as a mask in conjunction with the default python\n",
    "        # filter function later, in order to select out the raw data files with\n",
    "        # years within the input period. The following preprocess function also\n",
    "        # selects out the relevant years (as well as months) but by applying a\n",
    "        # filter on the list of file names first we can avoid preprocessing a \n",
    "        # lot of files and hence save on memory.\n",
    "        year = int(file_name[-7:-3])\n",
    "        if period_start.year <= year <= period_end.year:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def preprocess_era5_month_hour(ds):\n",
    "        # This function is used for the preprocess argument in open_mfdataset.\n",
    "        # It selects out only the subset months for persist scalability,\n",
    "        # renames variables and sorts data in time order.\n",
    "        file_name = ds.encoding[\"source\"]\n",
    "        logging.debug(f\"Preprocessing: file for use in {func_cur}: {file_name}.\")\n",
    "        ds = (regrid_era5(ds=ds)[[*vars_deps_and_rename[var].keys()]]\n",
    "              .rename(vars_deps_and_rename[var])\n",
    "              .sel(time = ds.time.dt.month.isin(months_subset))\n",
    "              # The downloaded ERA5 dataset is not sorted in time order (which\n",
    "              # is a necessity for open_mfdataset, so we sort first over here.\n",
    "              .sortby(\"time\")\n",
    "             )\n",
    "        return ds\n",
    "    \n",
    "    # The following code loads in an existing MDP file for the var corresponding to\n",
    "    # var_or_dvar, or creates one if it doesn't already exist. The True component of\n",
    "    # the if statement will only ever be run for dvars since if it were a var then\n",
    "    # path_output_var == path_output_mdp_clim and the code would have terminated earlier.\n",
    "    \n",
    "    path_output_var = path_output_mdp_clim.replace(var_or_dvar, var)\n",
    "    if Path(path_output_var).exists():\n",
    "        msg_open = f\"Opening: existing file for use in {func_cur}: {path_output_var}.\"\n",
    "        logging.info(msg_open)\n",
    "        print(msg_open)\n",
    "        ds_era5_mdp = xr.open_dataset(path_output_var, engine = \"netcdf4\")\n",
    "    else:      \n",
    "        # The following code opens the relevant monthy ERA5 files then computes\n",
    "        # mean over each hour of the day.\n",
    "        files_era5_month_hour = glob(\n",
    "            f\"../data_raw/{region}_era5-slv-{var_or_dvar_layer}_month-hour/*.nc\")\n",
    "        files_era5_month_hour.sort()\n",
    "        if len(files_era5_month_hour) != number_of_era5_month_hour_files:\n",
    "            msg_files = (\n",
    "                f\"WARNING: Expected {number_of_era5_month_hour_files} files in \" +\n",
    "                f\"../data_raw/{region}_era5-slv-{var_or_dvar_layer}_month-hour/ but \" +\n",
    "                f\"got {len(files_era5_month_hour)}. This could be because the \" + \n",
    "                \"data_download.ipynb notebook was not run properly. Or it could \" +\n",
    "                \"be that the user has selected a different number of years to \" +\n",
    "                \"retrieve data for in the data_download.ipynb notebook as \" +\n",
    "                \"compared with the original analysis. Or it may be that the \" +\n",
    "                \"user has changed some files in this folder.\"\n",
    "            )\n",
    "            logging.warning(msg_files)\n",
    "            print(msg_files)\n",
    "            \n",
    "        logging.debug(f\"Filtering: ERA5 {var_or_dvar_layer} files from data_raw \" +\n",
    "                      f\"folder for use in {func_cur}.\")\n",
    "        files_era5_month_hour_filtered = list(filter(filter_era5_month_hour_files, \n",
    "                                                     files_era5_month_hour))\n",
    "        files_era5_month_hour_filtered.sort()\n",
    "        \n",
    "        logging.debug(f\"Opening: ERA5 {var_or_dvar_layer} files from data_raw \" +\n",
    "                      f\"folder for use in {func_cur}.\")\n",
    "        ds_era5_mdp = (xr.open_mfdataset(files_era5_month_hour_filtered,\n",
    "                                         preprocess=preprocess_era5_month_hour,\n",
    "                                         engine = \"netcdf4\", parallel = True)\n",
    "                       # We add an extra month to period_end here because period_end was\n",
    "                       # specified as a month, and conversion into a datetime object\n",
    "                       # defaults to the first (rather than last) day of that month. The\n",
    "                       # -1 hr is to avoid selecting first hour of the following month.\n",
    "                       .sel(time = slice(period_start, period_end +\n",
    "                                         relativedelta(months=1, hours = -1)))\n",
    "                       # Rechunking after open_mfdataset here is actually bad practice\n",
    "                       # since it requires extra computation, but the chunks argument\n",
    "                       # for open_mfdataset doesn't seem to work here for some reason.\n",
    "                       .chunk(chunks = {\"time\": chunksize})\n",
    "                      )\n",
    "        if priority == \"speed\":\n",
    "            ds_era5_mdp = ds_era5_mdp.persist()\n",
    "        \n",
    "        if var == \"ws10\":\n",
    "            ds_era5_mdp = (get_magnitude(ds_era5_mdp[\"u10\"], ds_era5_mdp[\"v10\"])\n",
    "                           .to_dataset(name = \"ws10\")\n",
    "                          )\n",
    "            \n",
    "        if var == \"ws100\":\n",
    "            ds_era5_mdp = (get_magnitude(ds_era5_mdp[\"u100\"], ds_era5_mdp[\"v100\"])\n",
    "                           .to_dataset(name = \"ws100\")\n",
    "                          )\n",
    "        \n",
    "        logging.debug(f\"Computing: MDPs of {[*ds_era5_mdp.keys()]} for use in {func_cur}.\")\n",
    "        ds_era5_mdp = (ds_era5_mdp\n",
    "                       # The time coordinates for the downloaded ERA5 dataset do not\n",
    "                       # have perfect alignment across all variables, and sometimes\n",
    "                       # the hour components for a particular month are distributed\n",
    "                       # across different days (01 or 02) in that month. But this\n",
    "                       # shouldn't affect the results of an hour-wise average.\n",
    "                       .groupby(\"time.hour\")\n",
    "                       .mean(\"time\")\n",
    "                      )\n",
    "        \n",
    "        # For slhf, sshf and nse: average values from hour before and hour after.\n",
    "        # This is because these variables are hourly accumulations ending at each hour.\n",
    "        # The average then provides an estimate of the instantaneous value at the \n",
    "        # midpoint between these two accumulation periods. Afterwards, calculate net \n",
    "        # atmospheric condensation from atmospheric variables.\n",
    "        \n",
    "        if var == \"slhf\":\n",
    "            logging.debug(f\"Computing: averages for consecutive {var} accumulation \" +\n",
    "                          \"periods to estimate instantaneous hourly values for use \" +\n",
    "                          f\"in {func_cur}.\")\n",
    "            da_slhf_for, da_slhf_lag = get_da_mdp_for_and_lag(ds_era5_mdp[\"slhf\"])\n",
    "            # Estimate midpoint and convert from J m-2 to W m-2.\n",
    "            ds_era5_mdp[\"slhf\"] = (da_slhf_for + da_slhf_lag)/(2*3600)\n",
    "            \n",
    "        if var == \"sshf\":\n",
    "            logging.debug(f\"Computing: averages for consecutive {var} accumulation \" +\n",
    "                          \"periods to estimate instantaneous hourly values for use \" +\n",
    "                          f\"in {func_cur}.\")\n",
    "            da_sshf_for, da_sshf_lag = get_da_mdp_for_and_lag(ds_era5_mdp[\"sshf\"])\n",
    "            # Estimate midpoint and convert from J m-2 to W m-2.\n",
    "            ds_era5_mdp[\"sshf\"] = (da_sshf_for + da_sshf_lag)/(2*3600)\n",
    "            \n",
    "        if var == \"nac\":\n",
    "            logging.debug(\"Computing: averages for consecutive nse accumulation \" +\n",
    "                          f\"periods to estimate instantaneous {var} hourly values \" +\n",
    "                          f\"for use in {func_cur}.\")\n",
    "            da_nse_for, da_nse_lag = get_da_mdp_for_and_lag(ds_era5_mdp[\"nse\"])\n",
    "            # Estimate midpoint and convert from m of water equivalent to kg m-2 s-1.\n",
    "            ds_era5_mdp[\"nse\"] = (da_nse_for + da_nse_lag)/(2*3.6)\n",
    "            ds_era5_mdp[\"nac\"] = get_nac(ds_era5_mdp[\"nse\"], ds_era5_mdp[\"vidmf\"],  \n",
    "                                         ds_era5_mdp[\"tcwv\"])\n",
    "        \n",
    "        # Add attributes to each DataArray within Dataset.\n",
    "        \n",
    "        logging.info(\"Adding: attributes for each DataArray within output \"+\n",
    "                     f\"Dataset from {func_cur}.\")\n",
    "        for da_name in [*ds_era5_mdp.keys()]:\n",
    "            ds_era5_mdp[da_name].attrs = copy.deepcopy(attrs_da[da_name])\n",
    "        \n",
    "        # Add attributes to Dataset.\n",
    "    \n",
    "        add_ds_attrs(ds_era5_mdp, time_exec, func_cur, func_1up, \n",
    "                     args_cur, args_cur_values)\n",
    "        \n",
    "        # Modify attributes in Dataset and output if var_or_dvar_type == \"dvars\" \n",
    "        # (i.e. the MDP for var is being computed as an intermediate output \n",
    "        # for the dvar MDP).\n",
    "        \n",
    "        if var_or_dvar_type == \"dvars\":\n",
    "            ds_era5_mdp.attrs[\"func_executed\"] = (\n",
    "                ds_era5_mdp.attrs[\"func_executed\"]\n",
    "                .replace(var_or_dvar, var)\n",
    "            )\n",
    "            create_output_file(ds_era5_mdp, path_output_var, func_1up)\n",
    "    \n",
    "    # If a dvar was specified for var_or_dvar, calculate the change in the value\n",
    "    # of the variable as compared with its value in the previous hour.\n",
    "    \n",
    "    if var_or_dvar_type == \"dvars\":\n",
    "        for da_name in [*ds_era5_mdp.keys()]:\n",
    "            logging.info(f\"Obtaining d{da_name} MDP from {da_name} MDP for \" +\n",
    "                         f\"use in {func_cur}.\")\n",
    "            _, da_var_lag = get_da_mdp_for_and_lag(ds_era5_mdp[da_name])\n",
    "            ds_era5_mdp[da_name] += - da_var_lag\n",
    "            \n",
    "            # Add attributes to each DataArray within Dataset.\n",
    "            \n",
    "            logging.info(\"Adding: attributes for each DataArray within output \"+\n",
    "                         f\"Dataset from {func_cur}.\")\n",
    "            ds_era5_mdp[da_name].attrs = copy.deepcopy(attrs_da[da_name])\n",
    "            # Append entries to front of attributes if dvar is given.\n",
    "            ds_era5_mdp[da_name].attrs[\"abbreviation\"] = (\n",
    "                \"d\" + ds_era5_mdp[da_name].attrs[\"abbreviation\"])\n",
    "            ds_era5_mdp[da_name].attrs[\"full_name\"] = (\n",
    "                \"Hourly Change in \" + ds_era5_mdp[da_name].attrs[\"full_name\"])\n",
    "            \n",
    "            # Rename DataArray names to include \"d\" in front.\n",
    "            \n",
    "            ds_era5_mdp = ds_era5_mdp.rename({da_name: \"d\" + da_name})\n",
    "    \n",
    "        # Add attributes to Dataset.\n",
    "    \n",
    "        add_ds_attrs(ds_era5_mdp, time_exec, func_cur, func_1up, \n",
    "                     args_cur, args_cur_values)\n",
    "    \n",
    "    # Create output file in data_processed folder.\n",
    "    \n",
    "    create_output_file(ds_era5_mdp, path_output_mdp_clim, func_1up)\n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876c33f-aa86-4c5b-9213-94ef735a4aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_era5_mdp_clim_stats_given_var_or_dvar(region, period_start, period_end, \n",
    "                                               months_subset, var_or_dvar, \n",
    "                                               glass_source_pref=None):\n",
    "    \"\"\"\n",
    "    Calculate the mean diurnal profile (MDP) climatology statistics for a particular\n",
    "    variable or change in variable (compared to previous hour) using ERA5 data.\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['u10', 'v10', 'ws10', 'wv10', 'u100', \n",
    "            'v100', 'ws100', 'wv100', 'mslp', 't2', 'slhf', 'sshf', 'nse', 'vidmf', \n",
    "            'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac', 'blh', 'fa', 'cbh', 'tcc', \n",
    "            'cape', 'ci', 'du10', 'dv10', 'dws10', 'dwv10', 'du100', 'dv100', 'dws100', \n",
    "            'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dnse', 'dvidmf', 'dviec', \n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac', 'dblh', 'dfa', 'dcbh', \n",
    "            'dtcc', 'dcape', 'dci'].\n",
    "        glass_source_pref (None): This argument is not used for this analysis. It is used \n",
    "            for applying the calc_diff function over an arbitrary calc_func.\n",
    "                        \n",
    "    Returns:\n",
    "        ../data_processed/era5_mdp_clim_stats_given_var_or_dvar/{calc_funcs_ver}_calc_\n",
    "        {region}_{period_start}_{period_end}_{months_subset_str}_era5-mdp_\n",
    "        {var_or_dvar}_stats.nc:\n",
    "            Output netcdf4 file in data_processed folder containing the hour of maximum,\n",
    "            hour of minimum, maximum, minimum, mean and range of the MDP for\n",
    "            var_or_dvar. {calc_funcs_ver} is the version of the calc_funcs script\n",
    "            being used. {months_subset_str} is a string representing the list of \n",
    "            selected months to use as a subset.\n",
    "    \n",
    "    For each grid cell, calculate the max, min, mean, range, hour_max and hour_min of \n",
    "    the MDP for the selected var_or_dvar. The MDP values are computed over the period \n",
    "    from period_start to period_end (inclusive), and only using a subset of data within \n",
    "    this period (if months_subset not \"all\" is specified). If var_or_dvar is one of:\n",
    "    [\"wv10\", \"wv100\", \"dwv10\", \"dwv100\"], then hour_max and hour_min refer to the hours\n",
    "    for when the magnitude of these vectors are at a maximum or minimum respectively.\n",
    "    Max and min then refer to the vector quantities at hour_max and hour_min respectively.\n",
    "    Range refers to largest magnitude of all possible subtractions (corresponding to all \n",
    "    possible hourly combinations) between the 24 vector MDP values. The calculation uses\n",
    "    monthly averaged reanalysis by hour of day netcdf4 data from the data_raw folder as \n",
    "    input, then outputs the result as a netcdf4 file into the data_processed folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    # Assert that input arguments are valid, and create path for months_subset.\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(region=region, period_start=period_start, period_end=period_end,\n",
    "               months_subset=months_subset, var_or_dvar=var_or_dvar)\n",
    "    \n",
    "    months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Executing: {func_cur} to obtain {months_subset_str} \" +\n",
    "                     f\"climatology of {var_or_dvar} MDP stats between \" +\n",
    "                     f\"{period_start} and {period_end}.\")\n",
    "    else:\n",
    "        logging.info(f\"Executing: {func_cur} to obtain {months_subset_str} \" +\n",
    "                     f\"climatology of {var_or_dvar} MDP stats between \" +\n",
    "                     f\"{period_start} and {period_end} for use in {func_1up}.\")\n",
    "    \n",
    "    # Define the output path, and create intermediate output file for MDP of var_or_dvar \n",
    "    # if it doesn't yet exist.\n",
    "    \n",
    "    path_output_mdp_clim_stats = get_path_for_calc_func(\n",
    "        calc_func_name=func_cur, region=region, period_start=period_start, \n",
    "        period_end=period_end, months_subset=months_subset, var_or_dvar=var_or_dvar)\n",
    "    terminate_if_file_exists(path_output_mdp_clim_stats, func_cur, func_1up)\n",
    "    \n",
    "    path_era5_mdp = get_path_for_calc_func(\n",
    "        calc_func_name=\"calc_era5_mdp_clim_given_var_or_dvar\", region=region, \n",
    "        period_start=period_start, period_end=period_end, months_subset=months_subset, \n",
    "        var_or_dvar=var_or_dvar)\n",
    "    if Path(path_era5_mdp).exists():\n",
    "        msg_open = f\"Opening: existing file for use in {func_cur}: {path_era5_mdp}.\"\n",
    "        logging.info(msg_open)\n",
    "        print(msg_open)\n",
    "    else:\n",
    "        calc_era5_mdp_clim_given_var_or_dvar(region, period_start, period_end,\n",
    "                                             months_subset, var_or_dvar)\n",
    "        \n",
    "    # Convert period_start and period_end to datetime.datetime objects, \n",
    "    # and months_subset to list if a str was used as input.\n",
    "    \n",
    "    period_start, period_end, months_subset = convert_period_data_types(\n",
    "        period_start=period_start, period_end=period_end, months_subset=months_subset)\n",
    "    \n",
    "    # Compute MDP stats for given var_or_dvar, treating vector values separately.\n",
    "    logging.debug(f\"Computing: {var_or_dvar} MDP stats for use in {func_cur}.\")    \n",
    "    if var_or_dvar in params_vector:\n",
    "        if var_or_dvar in vars_era5_all:\n",
    "            var_or_dvar_attrs = copy.deepcopy(attrs_da[var_or_dvar])\n",
    "        if var_or_dvar in dvars_era5_all:\n",
    "            # Append entries to front of attributes if dvar is given.\n",
    "            var = var_or_dvar[1:]\n",
    "            var_or_dvar_attrs = copy.deepcopy(attrs_da[var])\n",
    "            var_or_dvar_attrs[\"abbreviation\"] = \"d\" + var_or_dvar_attrs[\"abbreviation\"]\n",
    "            var_or_dvar_attrs[\"full_name\"] = (\"Hourly Change in \" +\n",
    "                                              var_or_dvar_attrs[\"full_name\"])\n",
    "        ds_era5_mdp = xr.open_dataset(path_era5_mdp, engine = \"netcdf4\")\n",
    "        if priority == \"speed\":\n",
    "            ds_era5_mdp = ds_era5_mdp.persist()\n",
    "        da_u = ds_era5_mdp[var_or_dvar.replace(\"wv\", \"u\")]\n",
    "        da_v = ds_era5_mdp[var_or_dvar.replace(\"wv\", \"v\")]\n",
    "        da_mag = get_magnitude(da_u, da_v)\n",
    "        da_hour_max = xr.DataArray(da_mag.idxmax(\"hour\"), name = \"hour_max\")\n",
    "        da_hour_max = (da_hour_max + regions[region][\"tz\"]) % 24\n",
    "        da_hour_min = xr.DataArray(da_mag.idxmin(\"hour\"), name = \"hour_min\")\n",
    "        da_hour_min = (da_hour_min + regions[region][\"tz\"]) % 24\n",
    "        da_max_u = xr.DataArray(da_u.sel(hour = da_hour_max, drop = True), name = \"max_u\")\n",
    "        da_max_v = xr.DataArray(da_v.sel(hour = da_hour_max, drop = True), name = \"max_v\")\n",
    "        da_min_u = xr.DataArray(da_u.sel(hour = da_hour_min, drop = True), name = \"min_u\")\n",
    "        da_min_v = xr.DataArray(da_v.sel(hour = da_hour_min, drop = True), name = \"min_v\")\n",
    "        da_mean_u = xr.DataArray(da_u.mean(\"hour\"), name = \"mean_u\")\n",
    "        da_mean_v = xr.DataArray(da_v.mean(\"hour\"), name = \"mean_v\")\n",
    "        da_range = get_da_range_for_vector_mdp_values(ds_era5_mdp=ds_era5_mdp, \n",
    "                                                      var_or_dvar=var_or_dvar)\n",
    "        logging.debug(f\"Merging: {var_or_dvar} MDP stat DataArray's into Dataset.\")\n",
    "        ds_era5_mdp_stats = xr.merge([da_hour_max, da_hour_min, da_max_u, da_max_v, \n",
    "                                      da_min_u, da_min_v, da_mean_u, da_mean_v, da_range])\n",
    "    else:\n",
    "        da_era5_mdp = xr.open_dataset(path_era5_mdp, engine = \"netcdf4\")[var_or_dvar]\n",
    "        var_or_dvar_attrs = copy.deepcopy(da_era5_mdp.attrs)\n",
    "        if priority == \"speed\":\n",
    "            da_era5_mdp = da_era5_mdp.persist()\n",
    "        da_hour_max = xr.DataArray(da_era5_mdp.idxmax(\"hour\"), name = \"hour_max\")\n",
    "        da_hour_max = (da_hour_max + regions[region][\"tz\"]) % 24\n",
    "        da_hour_min = xr.DataArray(da_era5_mdp.idxmin(\"hour\"), name = \"hour_min\")\n",
    "        da_hour_min = (da_hour_min + regions[region][\"tz\"]) % 24\n",
    "        da_max = xr.DataArray(da_era5_mdp.max(\"hour\"), name = \"max\")\n",
    "        da_min = xr.DataArray(da_era5_mdp.min(\"hour\"), name = \"min\")\n",
    "        da_mean = xr.DataArray(da_era5_mdp.mean(\"hour\"), name = \"mean\")\n",
    "        da_range = xr.DataArray(da_max - da_min, name = \"range\")\n",
    "        logging.debug(f\"Merging: {var_or_dvar} MDP stat DataArray's into Dataset.\")\n",
    "        ds_era5_mdp_stats = xr.merge([da_hour_max, da_hour_min, da_max, da_min, \n",
    "                                      da_mean, da_range])\n",
    "    \n",
    "    # Obtain string for timezone relative to UTC (used for hour_max and hour_min).\n",
    "    \n",
    "    tz = regions[region][\"tz\"]\n",
    "    tz_str = str(tz) if tz < 0 else \"+\" + str(tz)\n",
    "    \n",
    "    # Add attributes to each DataArray within Dataset.\n",
    "    \n",
    "    logging.info(\"Adding: attributes for each DataArray within output \"+\n",
    "                 f\"Dataset from {func_cur}.\")\n",
    "    for da_name in [*ds_era5_mdp_stats.keys()]:\n",
    "        ds_era5_mdp_stats[da_name].attrs = copy.deepcopy(attrs_da[da_name])\n",
    "        # Append name of each statistic to front of var_or_dvar attributes.\n",
    "        ds_era5_mdp_stats[da_name].attrs[\"abbreviation\"] = (\n",
    "            ds_era5_mdp_stats[da_name].attrs[\"abbreviation\"]\n",
    "            .format(var_or_dvar_attrs[\"abbreviation\"])\n",
    "        )\n",
    "        ds_era5_mdp_stats[da_name].attrs[\"full_name\"] = (\n",
    "            ds_era5_mdp_stats[da_name].attrs[\"full_name\"]\n",
    "            .format(var_or_dvar_attrs[\"full_name\"])\n",
    "        )\n",
    "        if (da_name == \"hour_max\") | (da_name == \"hour_min\"):\n",
    "            ds_era5_mdp_stats[da_name].attrs[\"units\"] = (\n",
    "                ds_era5_mdp_stats[da_name].attrs[\"units\"]\n",
    "                .format(tz_str)\n",
    "            )\n",
    "        else:\n",
    "            ds_era5_mdp_stats[da_name].attrs[\"units\"] = (\n",
    "                ds_era5_mdp_stats[da_name].attrs[\"units\"]\n",
    "                .format(var_or_dvar_attrs[\"units\"])\n",
    "            )\n",
    "            \n",
    "    # Add attributes to Dataset.\n",
    "    \n",
    "    add_ds_attrs(ds_era5_mdp_stats, time_exec, func_cur, func_1up, \n",
    "                 args_cur, args_cur_values)\n",
    "    \n",
    "    # Create output file in data_processed folder.\n",
    "    \n",
    "    create_output_file(ds_era5_mdp_stats, path_output_mdp_clim_stats, func_1up)\n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c84eca-d587-4827-9b7d-15a25e5f1399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_era5_wsd_clim(region, period_start, period_end, months_subset, \n",
    "                       glass_source_pref=None, var_or_dvar=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate climatology of wind speed distribution (WSD) properties using \n",
    "    ERA5 data for heights of 10 m and 100 m above surface.\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "        glass_source_pref (None): This argument is not used for this analysis. It is used \n",
    "            for applying the calc_diff function over an arbitrary calc_func.\n",
    "        var_or_dvar (None): This argument is not used for this analysis. It is used \n",
    "            for applying the calc_diff function over an arbitrary calc_func.\n",
    "                        \n",
    "    Returns:\n",
    "        ../data_processed/era5_wsd_clim/{calc_funcs_ver}_calc_{region}_{period_start}_\n",
    "        {period_end}_{months_subset_str}_era5-wsd.nc:\n",
    "            Output netcdf4 file in data_processed folder containing Weibull shape and\n",
    "            scale parameters for wind speed at 10 m and 100 m above surface, expected\n",
    "            rate of exceedance for a particular wind speed at 100 m above surface,\n",
    "            and gross capacity factor for a typical turbine at 100 m above surface.\n",
    "            {calc_funcs_ver} is the version of the calc_funcs script being used.\n",
    "            {months_subset_str} is a string representing the list of selected months \n",
    "            to use as a subset.\n",
    "    \n",
    "    For each grid cell, calculate the Weibull scale and shape parameter for wind speed\n",
    "    at 10 m above surface (C10 and K10), the Weibull scale and shape parameter for\n",
    "    wind speed at 100 m above surface (C100 and K100), the expected rate of exceedance\n",
    "    for a particular wind speed at 100 m above surface (EROE100) and the gross\n",
    "    capacity factor for a typical wind turbine at 100 m above surface (TGCF100). The\n",
    "    wind speed distributions (WSDs) are computed over the period between period_start\n",
    "    and period_end (inclusive), and only using a subset of data within this period\n",
    "    (if a months_subset not \"all\" is specified). The calculation uses hourly ERA5 \n",
    "    netcdf4 data from the data_raw folder as input, then outputs the result as a\n",
    "    netcdf4 file into the data_processed folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    # Assert that input arguments are valid, and create path for months_subset.\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(region=region, period_start=period_start, period_end=period_end,\n",
    "               months_subset=months_subset)\n",
    "    \n",
    "    months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Executing: {func_cur} to obtain wind speed distribution \" +\n",
    "                     f\"parameters over {months_subset_str} months between \" + \n",
    "                     f\"{period_start} and {period_end}.\")\n",
    "    else:\n",
    "        logging.info(f\"Executing: {func_cur} to obtain wind speed distribution \" +\n",
    "                     f\"parameters over {months_subset_str} months between \" +\n",
    "                     f\"{period_start} and {period_end} for use in {func_1up}.\")\n",
    "    \n",
    "    # Define the output path, convert period_start and period_end to\n",
    "    # datetime.datetime objects, and months_subset to list if a str was used as input.\n",
    "    \n",
    "    path_output_wsd_clim = get_path_for_calc_func(\n",
    "        calc_func_name=func_cur, region=region, period_start=period_start, \n",
    "        period_end=period_end, months_subset=months_subset, var_or_dvar=var_or_dvar)\n",
    "    terminate_if_file_exists(path_output_wsd_clim, func_cur, func_1up)\n",
    "    \n",
    "    period_start, period_end, months_subset = convert_period_data_types(\n",
    "        period_start=period_start, period_end=period_end, months_subset=months_subset)\n",
    "    if period_start + relativedelta(years=5) > period_end:\n",
    "        msg_years = (\"WARNING: It is recommended to use at least 5 years of data \" +\n",
    "                     \"for the wind speed distribution analysis.\")\n",
    "        logging.warning(msg_years)\n",
    "        print(msg_years)\n",
    "    \n",
    "    # The two functions below are used with xarray's open_mfdataset for parallel\n",
    "    # computing using dask. Together they select out the relevant files to read\n",
    "    # and persist in memory only the data which is necessary for the computation.\n",
    "    \n",
    "    def filter_era5_hour_files(file_name):\n",
    "        # This function is used as a mask in conjunction with the default python\n",
    "        # filter function later, in order to select out the raw data files with\n",
    "        # years within the input period. The following preprocess function also\n",
    "        # selects out the relevant years (as well as months) but by applying a\n",
    "        # filter on the list of file names first we can avoid preprocessing a \n",
    "        # lot of files and hence save on memory.\n",
    "        year = int(file_name[-7:-3])\n",
    "        if period_start.year <= year <= period_end.year:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def preprocess_era5_hour(ds):\n",
    "        # This function is used for the preprocess argument in open_mfdataset.\n",
    "        # It selects out only the wind speed data, and only for\n",
    "        # the subset months. This is done for persist scalability.\n",
    "        file_name = ds.encoding[\"source\"]\n",
    "        logging.debug(f\"Preprocessing: file for use in {func_cur}: {file_name}.\")\n",
    "        ds = (regrid_era5(ds=ds)[[\"u10\", \"v10\", \"u100\", \"v100\"]]\n",
    "              .sel(time = ds.time.dt.month.isin(months_subset))\n",
    "             )\n",
    "        return ds\n",
    "    \n",
    "    # The following code opens the relevant hourly ERA5 files then uses the\n",
    "    # u and v components of wind velocity to compute the magnitude (wind speed).\n",
    "    \n",
    "    files_era5_hour = glob(f\"../data_raw/{region}_era5-slv-sfc_hour/*.nc\")\n",
    "    files_era5_hour.sort()\n",
    "    if len(files_era5_hour) != number_of_era5_hour_files:\n",
    "        msg_files = (\n",
    "            f\"WARNING: Expected {number_of_era5_hour_files} files in \" +\n",
    "            f\"../data_raw/{region}_era5-slv-sfc_hour/ but got {len(files_era5_hour)}. \" +\n",
    "            \"This could be because the data_download.ipynb notebook was not run \" + \n",
    "            \"properly. Or it could be that the user has selected a different \" +\n",
    "            \"number of years to retrieve data for in the data_download.ipynb \" +\n",
    "            \"notebook as compared with the original analysis. Or it may be that \" +\n",
    "            \"the user has changed some files in this folder.\"\n",
    "        )\n",
    "        logging.warning(msg_files)\n",
    "        print(msg_files)\n",
    "        \n",
    "    logging.debug(f\"Filtering: ERA5 atm files from data_raw folder for use in {func_cur}.\")\n",
    "    files_era5_hour_filtered = list(filter(filter_era5_hour_files, files_era5_hour))\n",
    "    files_era5_hour_filtered.sort()\n",
    "    \n",
    "    logging.debug(f\"Opening: ERA5 atm files from data_raw folder for use in {func_cur}.\")\n",
    "    ds_era5_hour = (xr.open_mfdataset(files_era5_hour_filtered, engine = \"netcdf4\",\n",
    "                                     preprocess=preprocess_era5_hour, parallel = True)\n",
    "                    # We add an extra month to period_end here because period_end was\n",
    "                    # specified as a month, and conversion into a datetime object\n",
    "                    # defaults to the first (rather than last) day of that month. The\n",
    "                    # -1 hr is to avoid selecting first hour of the following month.\n",
    "                    .sel(time = slice(period_start, period_end +\n",
    "                                relativedelta(months=1, hours = -1)))\n",
    "                    # Rechunking after open_mfdataset here is actually bad practice\n",
    "                    # since it requires extra computation, but the chunks argument\n",
    "                    # for open_mfdataset doesn't seem to work here for some reason.\n",
    "                    .chunk(chunks = {\"time\": chunksize})\n",
    "                   )\n",
    "    if priority == \"speed\":\n",
    "        ds_era5_hour = ds_era5_hour.persist()\n",
    "        \n",
    "    da_ws10 = get_magnitude(ds_era5_hour[\"u10\"], ds_era5_hour[\"v10\"])\n",
    "    da_ws100 = get_magnitude(ds_era5_hour[\"u100\"], ds_era5_hour[\"v100\"])\n",
    "    da_ws10.name, da_ws100.name = \"ws10\", \"ws100\"\n",
    "    \n",
    "    # Compute the mean and standard deviation of wind speed, from these the \n",
    "    # Weibull scale and shape parameters, then the expected rate of exceedance\n",
    "    # and typical gross capacity factor, then combine into a single dataset.\n",
    "    \n",
    "    da_ws10_mean = xr.DataArray(da_ws10.mean(\"time\"), name = \"ws10_mean\")\n",
    "    da_ws10_std = xr.DataArray(da_ws10.std(\"time\"), name = \"ws10_std\")\n",
    "    da_ws10_c, da_ws10_k = get_weibull_params(da_ws10_mean, da_ws10_std)\n",
    "    da_ws10_c.name, da_ws10_k.name = \"c10\", \"k10\"\n",
    "    da_ws100_mean = xr.DataArray(da_ws100.mean(\"time\"), name = \"ws100_mean\")\n",
    "    da_ws100_std = xr.DataArray(da_ws100.std(\"time\"), name = \"ws100_std\")\n",
    "    da_ws100_c, da_ws100_k = get_weibull_params(da_ws100_mean, da_ws100_std)\n",
    "    da_ws100_c.name, da_ws100_k.name = \"c100\", \"k100\"\n",
    "    da_ws100_eroe = get_weibull_eroe(da_ws100_c, da_ws100_k, speed_eroe)\n",
    "    da_ws100_gcf = get_gcf(da_ws100, speeds_common, powers_avg, power_nameplate)\n",
    "    da_ws100_eroe.name, da_ws100_gcf.name = \"eroe100\", \"tgcf100\"\n",
    "    \n",
    "    logging.debug(\"Merging: wind speed distribution parameter DataArray's into Dataset.\")\n",
    "    ds_era5_wsd = xr.merge([da_ws10_mean, da_ws10_std, da_ws10_c, da_ws10_k,\n",
    "                            da_ws100_mean, da_ws100_std, da_ws100_c,\n",
    "                            da_ws100_k, da_ws100_eroe, da_ws100_gcf])\n",
    "    \n",
    "    # Add attributes to each DataArray within Dataset.\n",
    "    \n",
    "    logging.info(\"Adding: attributes for each DataArray within output \"+\n",
    "                 f\"Dataset from {func_cur}.\")\n",
    "    for da_name in [*ds_era5_wsd.keys()]:\n",
    "        ds_era5_wsd[da_name].attrs = copy.deepcopy(attrs_da[da_name])\n",
    "    \n",
    "    # Add attributes to Dataset.\n",
    "    \n",
    "    add_ds_attrs(ds_era5_wsd, time_exec, func_cur, func_1up, args_cur, args_cur_values)\n",
    "    \n",
    "    # Create output file in data_processed folder.\n",
    "    \n",
    "    create_output_file(ds_era5_wsd, path_output_wsd_clim, func_1up)\n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb1180-723c-4cac-a827-39f3e178eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main extra functions\n",
    "\n",
    "def calc_diff(calc_func, region, period1_start, period1_end,\n",
    "              period2_start, period2_end, months_subset, \n",
    "              glass_source_pref=None, var_or_dvar=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the difference in results for two separate periods which have\n",
    "    each been outputted by the same calculation function.\n",
    "    \n",
    "    Arguments:\n",
    "        calc_func (function): Calculation function to use in analysis. Must be one of: \n",
    "            [calc_glass_mean_clim,\n",
    "            calc_era5_mdp_clim_given_var_or_dvar,\n",
    "            calc_era5_mdp_clim_stats_given_var_or_dvar,\n",
    "            calc_era5_wsd_clim].\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of: [\"ca\", \"sa\", \"wa\"].\n",
    "        period1_start (str): Start of first period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period1_end (str): End of first period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period2_start (str): Start of second period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period2_end (str): End of second period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "        glass_source_pref (str): Preferred glass data source to use when analysis is \n",
    "            over a period which is completely contained within both the available\n",
    "            AVHRR and MODIS datasets. Must be one of: [\"avhrr\", \"modis\"].\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['u10', 'v10', 'ws10', 'wv10', 'u100', \n",
    "            'v100', 'ws100', 'wv100', 'mslp', 't2', 'slhf', 'sshf', 'nse', 'vidmf', \n",
    "            'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac', 'blh', 'fa', 'cbh', 'tcc', \n",
    "            'cape', 'ci', 'du10', 'dv10', 'dws10', 'dwv10', 'du100', 'dv100', 'dws100', \n",
    "            'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dnse', 'dvidmf', 'dviec', \n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac', 'dblh', 'dfa', 'dcbh', \n",
    "            'dtcc', 'dcape', 'dci'].\n",
    "    \n",
    "    Returns:\n",
    "        ../data_processed/glass_mean_clim/{calc_funcs_ver}_diff_{region}_{period1_start}_\n",
    "            {period1_end}_{period2_start}_{period2_end}_{months_subset_str}_glass-mean_\n",
    "            {glass_source}.nc OR\n",
    "        ../data_processed/era5_mdp_clim_given_var_or_dvar/{calc_funcs_ver}_diff_{region}_\n",
    "            {period1_start}_{period1_end}_{period2_start}_{period2_end}_\n",
    "            {months_subset_str}_era5-mdp_{var_or_dvar}.nc OR\n",
    "        ../data_processed/era5_mdp_clim_stats_given_var_or_dvar/{calc_funcs_ver}_diff_\n",
    "            {region}_{period1_start}_{period1_end}_{period2_start}_{period2_end}_\n",
    "            {months_subset_str}_era5-mdp_{var_or_dvar}_stats.nc OR\n",
    "        ../data_processed/era5_wsd_clim/{calc_funcs_ver}_diff_{region}_{period1_start}_\n",
    "            {period1_end}_{period2_start}_{period2_end}_{months_subset_str}_era5-wsd.nc:\n",
    "                Output netcdf4 file in data_processed folder containing the difference\n",
    "                in results, with name depending on calc_func being used.\n",
    "                {calc_funcs_ver} is the version of the calc_funcs script being\n",
    "                used. {months_subset_str} is a string representing the list of selected \n",
    "                months to use as a subset. {glass_source} is automatically selected \n",
    "                between [\"avhrr\", \"modis\"] based on the selected period. \n",
    "    \n",
    "    First runs calc_func for each of the given periods if this has not already\n",
    "    been done. Then calculates the difference in results as period2 - period1.\n",
    "    For hour_max and hour_min stats, the result is expressed as a value between\n",
    "    -12 (hour_max or hour_min for period2 is 12 hours behind of that for period1) and\n",
    "    +12 (hour_max or hour_min for period2 is 12 hours ahead of that for period1).\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    # Assert that input arguments are valid.\n",
    "    \n",
    "    calc_func_name = calc_func.__name__\n",
    "    check_args_for_none(calc_func_name, args_cur, args_cur_values)\n",
    "    check_args(calc_func=calc_func, region=region, period_start=period1_start,\n",
    "               period_end=period1_end, months_subset=months_subset, \n",
    "               glass_source_pref=glass_source_pref, var_or_dvar=var_or_dvar)\n",
    "    check_args(period_start=period2_start, period_end=period2_end, \n",
    "               months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Executing: {func_cur} to obtain difference in outputs from \" +\n",
    "                     f\"{calc_func_name} over {period1_start} to {period1_end} and \" +\n",
    "                     f\"{period2_start} to {period2_end}.\")\n",
    "    else:\n",
    "        logging.info(f\"Executing: {func_cur} to obtain difference in outputs from \" +\n",
    "                     f\"{calc_func_name} over {period1_start} to {period1_end} and \" +\n",
    "                     f\"{period2_start} to {period2_end} for use in {func_1up}.\")\n",
    "    \n",
    "    # Obtain paths for calc_diff output as well as intermediate calc_func outputs \n",
    "    # from each period.\n",
    "    \n",
    "    path_output_diff = get_path_for_calc_diff(\n",
    "        calc_func_name=calc_func_name, region=region, period1_start=period1_start,\n",
    "        period1_end=period1_end, period2_start=period2_start, period2_end=period2_end,\n",
    "        months_subset=months_subset, glass_source_pref=glass_source_pref,\n",
    "        var_or_dvar=var_or_dvar)\n",
    "    terminate_if_file_exists(path_output_diff, func_cur, func_1up)\n",
    "    \n",
    "    # Create intermediate output files from each period if they don't already\n",
    "    # exist, then read in these files as xarray datasets and compute difference.\n",
    "    path_period1 = get_path_for_calc_func(\n",
    "        calc_func_name=calc_func_name, region=region, period_start=period1_start, \n",
    "        period_end=period1_end, months_subset=months_subset, \n",
    "        glass_source_pref=glass_source_pref, var_or_dvar=var_or_dvar)\n",
    "    if Path(path_period1).exists():\n",
    "        msg_open1 = f\"Opening: existing file for use in {func_cur}: {path_period1}.\"\n",
    "        logging.info(msg_open1)\n",
    "        print(msg_open1)\n",
    "    else:\n",
    "        calc_func(region=region, period_start=period1_start, period_end=period1_end, \n",
    "                  months_subset=months_subset, glass_source_pref=glass_source_pref, \n",
    "                  var_or_dvar=var_or_dvar)\n",
    "    ds_period1 = xr.open_dataset(path_period1, engine = \"netcdf4\")\n",
    "    \n",
    "    path_period2 = get_path_for_calc_func(\n",
    "        calc_func_name=calc_func_name, region=region, period_start=period2_start, \n",
    "        period_end=period2_end, months_subset=months_subset,\n",
    "        glass_source_pref=glass_source_pref, var_or_dvar=var_or_dvar)\n",
    "    if Path(path_period2).exists():\n",
    "        msg_open2 = f\"Opening: existing file for use in {func_cur}: {path_period2}.\"\n",
    "        logging.info(msg_open2)\n",
    "        print(msg_open2)\n",
    "    else:\n",
    "        calc_func(region=region, period_start=period2_start, period_end=period2_end,\n",
    "                  months_subset=months_subset, glass_source_pref=glass_source_pref,\n",
    "                  var_or_dvar=var_or_dvar)\n",
    "    ds_period2 = xr.open_dataset(path_period2, engine = \"netcdf4\")\n",
    "    \n",
    "    if priority == \"speed\":\n",
    "        ds_period1 = ds_period1.persist()\n",
    "        ds_period2 = ds_period2.persist()\n",
    "    \n",
    "    logging.debug(f\"Computing: difference in results for {calc_func} over the \" + \n",
    "                  \"given periods.\")\n",
    "    ds_diff = ds_period2 - ds_period1\n",
    "    \n",
    "    # Treat hour_max and hour_min stats separately since the difference in these\n",
    "    # should be between -12 hours (12 hours behind) and +12 hours (12 hours ahead).\n",
    "    \n",
    "    if calc_func_name == \"calc_era5_mdp_clim_stats_given_var_or_dvar\":\n",
    "        logging.debug(\"Converting: difference in hour_max and hour_min values to be \" + \n",
    "                      \"between -12 and +12 hours.\")\n",
    "        ds_diff[\"hour_max\"] = (ds_diff[\"hour_max\"] + 12) % 24 - 12\n",
    "        ds_diff[\"hour_min\"] = (ds_diff[\"hour_min\"] + 12) % 24 - 12\n",
    "    \n",
    "    # Add attributes to each DataArray within Dataset.\n",
    "    \n",
    "    logging.info(\"Adding: attributes for each DataArray within output \"+\n",
    "                 f\"Dataset from {func_cur}.\")\n",
    "    for da_name in [*ds_diff.keys()]:\n",
    "        # The subject over which the difference is being computed for appears right\n",
    "        # before the opening bracket ( for statistics abbreviations, and at the end\n",
    "        # of the abbreviation for variables. The following line accounts for both\n",
    "        # in selecting the subject, then appends a \"diff\" superscript to the subject.\n",
    "        ds_diff[da_name].attrs = copy.deepcopy(ds_period1[da_name].attrs)\n",
    "        subject = ds_diff[da_name].attrs[\"abbreviation\"].split(\"(\")[0]\n",
    "        ds_diff[da_name].attrs[\"abbreviation\"] = (ds_diff[da_name].attrs[\"abbreviation\"]\n",
    "                                                  .replace(subject, subject + \"$^{diff}$\"))\n",
    "        ds_diff[da_name].attrs[\"full_name\"] = (\"Difference in \" + \n",
    "                                               ds_diff[da_name].attrs[\"full_name\"])\n",
    "        if (da_name == \"hour_max\") | (da_name == \"hour_min\"):\n",
    "            ds_diff[da_name].attrs[\"units\"] = \"$h$\"\n",
    "        if calc_func_name == \"calc_glass_mean_clim\":\n",
    "            ds_diff[da_name].attrs[\"source\"] = path_output_diff[-8:-3]\n",
    "    \n",
    "    # Add attributes to Dataset.\n",
    "    \n",
    "    add_ds_attrs(ds_diff, time_exec, func_cur, func_1up, args_cur, args_cur_values)\n",
    "    \n",
    "    # Create output file in data_processed folder.\n",
    "    \n",
    "    create_output_file(ds_diff, path_output_diff, func_1up)\n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447b420-f32a-4efc-b048-68969cf24c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_era5_orog():\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the elevation and slope of sub-gridscale orography for the global\n",
    "    land surface using ERA5 data.\n",
    "                        \n",
    "    Returns:\n",
    "        ../data_processed/era5_orog_slope/{calc_funcs_ver}_calc_\n",
    "        global_static_orog.nc:\n",
    "            Output netcdf4 file in data_processed folder containing the elevation and \n",
    "            slope of sub-gridscale orography for the global land surface. \n",
    "            {calc_funcs_ver} is the version of the calc_funcs script being used.\n",
    "    \n",
    "    For each grid cell, calculate the global land surface elevation (m above mean sea \n",
    "    level) using ERA5 geopotential data, obtain the global slope of sub-gridscale \n",
    "    orography directly from ERA5 data, apply a mask to both datasets, then change the \n",
    "    datasets' attributes. ERA5 land-sea mask data containing the fraction of each grid \n",
    "    cell which is land is then used to mask values above sea cover (by selecting only \n",
    "    the values where this fraction was greater than 0.5). The calculations use static \n",
    "    reanalysis netcdf4 data from the data_raw folder as input, then outputs the result \n",
    "    (static data) as a netcdf4 file into the data_processed folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Executing: {func_cur} to obtain global orographic variables.\")\n",
    "    else:\n",
    "        logging.info(f\"Executing: {func_cur} to obtain global orographic variables \" +\n",
    "                     f\"for use in {func_1up}.\")\n",
    "    \n",
    "    # Create paths, open raw datasets, calculate the land surface elevation,\n",
    "    # then mask values and change dataset attributes\n",
    "    \n",
    "    path_output_orog = get_path_for_era5_orog()\n",
    "    terminate_if_file_exists(path_output_orog, func_cur, func_1up)\n",
    "    \n",
    "    path_static = \"../data_raw/global_era5-slv_static/global_era5-slv_static_all.nc\"\n",
    "    if Path(path_static).exists():\n",
    "        msg_exist = f\"Opening: existing file for use in {func_cur}: {path_static}.\"\n",
    "        logging.info(msg_exist)\n",
    "        print(msg_exist)\n",
    "        ds_static = regrid_era5(xr.open_dataset(path_static, engine = \"netcdf4\"))\n",
    "    else:\n",
    "        msg_miss = (f\"TERMINATED: file could not be found: {path_static}. This could \" +\n",
    "                    \"be because the data_download.ipynb notebook was not run properly. \" +\n",
    "                    \"Alternatively, the user may have changed some files in this folder.\")\n",
    "        logging.error(msg_miss)\n",
    "        print(msg_miss)\n",
    "        remove_handlers_if_directly_executed(func_1up)\n",
    "        return None\n",
    "    \n",
    "    da_geop = ds_static[\"z\"]\n",
    "    da_ssgo_raw = ds_static[\"slor\"]\n",
    "    da_lsm = ds_static[\"lsm\"]\n",
    "    \n",
    "    if priority == \"speed\":\n",
    "        da_geop = da_geop.persist()\n",
    "        da_ssgo_raw = da_ssgo_raw.persist()\n",
    "        da_lsm = da_lsm.persist()\n",
    "    \n",
    "    logging.debug(\"Computing: land surface elevation.\")\n",
    "    da_era5_orog_eleva = (mpcalc.geopotential_to_height(da_geop)\n",
    "                          .where(da_lsm > 0.5)\n",
    "                          .where(da_geop >= 0)\n",
    "                          .squeeze(\"time\", drop=True)\n",
    "                          .metpy.dequantify()\n",
    "                          .rename(\"lse\")\n",
    "                         )\n",
    "    \n",
    "    logging.debug(\"Computing: slope of sub-gridscale orography.\")\n",
    "    da_era5_orog_slope = (da_ssgo_raw\n",
    "                          .where(da_lsm > 0.5)\n",
    "                          .where(da_ssgo_raw >= 0)\n",
    "                          .squeeze(\"time\", drop=True)\n",
    "                          .rename(\"ssgo\")\n",
    "                         )\n",
    "    \n",
    "    ds_era5_orog = xr.merge([da_era5_orog_eleva, da_era5_orog_slope])\n",
    "    \n",
    "    # Add attributes to each DataArray within Dataset.\n",
    "    \n",
    "    logging.info(\"Adding: attributes for each DataArray within output \"+\n",
    "                 f\"Dataset from {func_cur}.\")\n",
    "    for da_name in [*ds_era5_orog.keys()]:\n",
    "        ds_era5_orog[da_name].attrs = copy.deepcopy(attrs_da[da_name])\n",
    "    \n",
    "    # Add attributes to Dataset.\n",
    "    \n",
    "    add_ds_attrs(ds_era5_orog, time_exec, func_cur, func_1up, args_cur, args_cur_values)\n",
    "    \n",
    "    # Create output file in data_processed folder.\n",
    "    \n",
    "    create_output_file(ds_era5_orog, path_output_orog, func_1up)\n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e7ba3-7219-46b6-bc53-77893280073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_glass_rolling_avg_of_annual_diff(region, year_start, year_end, months_subset,\n",
    "                                          window_size, glass_source_pref):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the rolling average of the annual difference in mean leaf area index \n",
    "    (MLAI) and mean fraction of absorbed photosynthetically active radiation (MFAPAR)\n",
    "    using GLASS data.\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "        year_start (int): Earliest year to compute the rolling average for.\n",
    "        year_end (int): Latest year to compute the rolling average for.\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "        window_size (int): Rolling window size (in years) to compute average for.\n",
    "            Must be an odd number and greater than or equal to 3.\n",
    "        glass_source_pref (str): Preferred glass data source to use when analysis is \n",
    "            over a period which is completely contained within both the available\n",
    "            AVHRR and MODIS datasets. Must be one of: [\"avhrr\", \"modis\"].\n",
    "                        \n",
    "    Returns:\n",
    "        ../data_processed/glass_rolling_avg_of_annual_diff/{calc_funcs_ver}_calc_\n",
    "        {region}_{year_start}_{year_end}_{months_subset_str}_{window_size}-year_\n",
    "        glass-rolling-diff_{glass_source_pref}.nc:\n",
    "            Output netcdf4 file in data_processed folder containing the rolling average\n",
    "            of the annual difference in MLAI and MFAPAR. {calc_funcs_ver} is the version \n",
    "            of the calc_funcs script being used. {months_subset_str} is a string \n",
    "            representing the list of selected months to use as a subset.\n",
    "    \n",
    "    For each grid cell, calculate the rolling average of the annual difference in \n",
    "    MLAI and MFAPAR, and only using a subset of data within this period (if a \n",
    "    months_subset not \"all\" is specified). These rolling averages are computed for each \n",
    "    year between year_start and year_end (inclusive). For example, the 3-year rolling \n",
    "    average of MLAI for the year 1992 would be the average of MLAI(1993)-MLAI(1992) and\n",
    "    MLAI(1992)-MLAI(1991), which uses 2 annual differences across 3 years of data.\n",
    "    The 5-year rolling average for the year 2002 would be the average of \n",
    "    MLAI(2004)-MLAI(2003), MLAI(2003)-MLAI(2002), MLAI(2002)-MLAI(2001) and\n",
    "    MLAI(2001)-MLAI(2000), which uses 4 annual differences across 5 years of data.\n",
    "    Thus, window_size must be odd for the rolling average of a year to equally\n",
    "    weight years before and after it, and window_size must be greater than or equal to 3 \n",
    "    for the rolling average to be well defined.\n",
    "    \n",
    "    This functions first runs calc_diff with calc_func = calc_glass_mean_clim for each \n",
    "    year between year_start - (window_size-1)/2 and year_end + (window_size-1)/2 \n",
    "    (inclusive) which has not already been run (this is to capture all necessary years of \n",
    "    data). Then the rolling average of these annual differences is calculated for each\n",
    "    year between year_start and year_end (inclusive). The calculations use 8-day satellite \n",
    "    HDF data from the data_raw folder as input, then outputs the result as a netcdf4 file \n",
    "    into the data_processed folder.\n",
    "    \n",
    "    Where an annual difference is completely contained within the time ranges of both AVHRR\n",
    "    and MODIS data, glass_source_pref is selected as the data source for use. Otherwise, \n",
    "    AVHRR data is used where the annual difference is completely contained only within the \n",
    "    time range of AVHRR data, and conversely for MODIS data. Annual differences which \n",
    "    simultaneously cover both an AVHRR-only period (i.e. before Mar-2000) and a MODIS-only \n",
    "    period (i.e. after Dec-2018) use both AVHRR and MODIS data (\"mixed\").\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    # Assert that input arguments are valid.\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(region=region, year_start=year_start, year_end=year_end, \n",
    "               months_subset=months_subset, window_size=window_size, \n",
    "               glass_source_pref=glass_source_pref)\n",
    "    \n",
    "    months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Executing: {func_cur} to obtain the {months_subset_str} rolling \" +\n",
    "                     f\"average of the annual difference in MLAI AND MFAPAR for years \" +\n",
    "                     f\"{year_start} to {year_end}.\")\n",
    "    else:\n",
    "        logging.info(f\"Executing: {func_cur} to obtain the {months_subset_str} rolling \" +\n",
    "                     f\"average of the annual difference in MLAI AND MFAPAR for years \" +\n",
    "                     f\"{year_start} to {year_end} for use in {func_1up}.\")\n",
    "    \n",
    "    # Define the output path.\n",
    "    \n",
    "    path_output_glass_roll = get_path_for_calc_glass_rolling(\n",
    "        region=region, year_start=year_start, year_end=year_end, \n",
    "        months_subset=months_subset, window_size=window_size, \n",
    "        glass_source_pref=glass_source_pref)\n",
    "    terminate_if_file_exists(path_output_glass_roll, func_cur, func_1up)\n",
    "    \n",
    "    # Years in which the annual difference MFAPAR DataArray is filled with NaNs.\n",
    "    years_diff_nan = (set(range(avhrr_earliest_year + 1, fapar_earliest_year + 1))\n",
    "                          .union(set(range(fapar_latest_year + 1, modis_latest_year + 1)))\n",
    "                     )\n",
    "    \n",
    "    # Create intermediate output files for each annual difference if they don't already\n",
    "    # exist, then read in these files, merge, and compute rolling average.\n",
    "    \n",
    "    datasets = []\n",
    "    \n",
    "    # This is a dictionary where elements will be appended onto in the following for loop.\n",
    "    # It gives the glass source (\"avhrr\", \"modis\", or \"mixed\") for each annual difference.\n",
    "    glass_source_diff = {}\n",
    "    \n",
    "    for year in range(int(year_start - (window_size-1)/2 + 1), \n",
    "                      int(year_end + (window_size-1)/2 + 1)\n",
    "                     ):\n",
    "        path_diff = get_path_for_calc_diff(\n",
    "            calc_func_name=\"calc_glass_mean_clim\", region=region, \n",
    "            period1_start=\"Jan-\"+str(year-1), period1_end=\"Dec-\"+str(year-1), \n",
    "            period2_start=\"Jan-\"+str(year), period2_end=\"Dec-\"+str(year), \n",
    "            months_subset=months_subset, glass_source_pref=glass_source_pref)\n",
    "        \n",
    "        glass_source_diff[str(year)] = path_diff[-8:-3]\n",
    "        \n",
    "        if Path(path_diff).exists():\n",
    "            msg_open = f\"Opening: existing file for use in {func_cur}: {path_diff}.\"\n",
    "            logging.info(msg_open)\n",
    "            print(msg_open)\n",
    "            ds_diff = (xr.open_dataset(path_diff, engine = \"netcdf4\")\n",
    "                       .expand_dims({\"year\": [year]})\n",
    "                      )\n",
    "            datasets.append(ds_diff)\n",
    "        else:\n",
    "            calc_diff(calc_func=calc_glass_mean_clim, region=region, \n",
    "                      period1_start=\"Jan-\"+str(year-1), period1_end=\"Dec-\"+str(year-1), \n",
    "                      period2_start=\"Jan-\"+str(year), period2_end=\"Dec-\"+str(year), \n",
    "                      months_subset=months_subset, glass_source_pref=glass_source_pref)\n",
    "            ds_diff = (xr.open_dataset(path_diff, engine = \"netcdf4\")\n",
    "                       .expand_dims({\"year\": [year]})\n",
    "                      )\n",
    "            datasets.append(ds_diff)\n",
    "        \n",
    "        if year in years_diff_nan:\n",
    "            msg_avail = (\"WARNING: A DataArray with NaN's was returned for the annual \" +\n",
    "                         f\"difference from {year-1}-{year} because GLASS FAPAR data \" +\n",
    "                         f\"is not available before {fapar_earliest_year} or after \" +\n",
    "                         f\"{fapar_latest_year}.\")\n",
    "            logging.warning(msg_avail)\n",
    "            print(msg_avail)\n",
    "            \n",
    "        if path_diff[-8:-3] == \"mixed\":\n",
    "            msg_mixed_diff = (f\"WARNING: Annual difference in mean from {year-1} to \" +\n",
    "                              f\"{year} uses both AVHRR and MODIS data (mixed). Years \" +\n",
    "                              f\"equal to or before {year-1} use AVHRR data while years \" + \n",
    "                              f\"equal to or after {year} use MODIS data.\")\n",
    "            logging.warning(msg_mixed_diff)\n",
    "            print(msg_mixed_diff)\n",
    "            year_mixed = year\n",
    "        else:\n",
    "            year_mixed = None\n",
    "    \n",
    "    logging.debug(\"Merging: datasets for annual difference in glass mean.\")\n",
    "    \n",
    "    if priority == \"speed\":\n",
    "        ds_diff_merged = xr.merge(datasets)\n",
    "        ds_diff_merged = ds_diff_merged.persist()\n",
    "        \n",
    "    elif priority == \"memory\":\n",
    "        ds_diff_merged = datasets[0]\n",
    "        for i in range(1, len(datasets)):\n",
    "            ds_diff_merged = xr.merge([ds_diff_merged, datasets[i]])\n",
    "    \n",
    "    # The code below computes the rolling avg by using xarray's rolling window but a more\n",
    "    # efficient way would have been to recognise that the average of consecutive annual\n",
    "    # differences actually produces a telescoping sum in the numerator, so that the \n",
    "    # rolling avg is in effect glass_mean(year_end) - glass_mean(year_start) divided\n",
    "    # by (window_size - 1).\n",
    "    \n",
    "    logging.debug(\"Computing: rolling avg of annual difference in mean glass datasets.\")\n",
    "    ds_roll_diff = (ds_diff_merged\n",
    "                    # xarray's rolling avg by default is assigned to coords at end of\n",
    "                    # window. This line centres it on each year coord for ds_roll_diff.\n",
    "                    .assign_coords({\"year\": ds_diff_merged.year - int((window_size-1)/2)})\n",
    "                    .rolling(year = window_size - 1, min_periods = math.ceil(\n",
    "                        (1-per_diff_nan_max/100) * (window_size-1)))\n",
    "                    .mean(skipna = True)\n",
    "                    .sel(year = slice(year_start, None))\n",
    "                   )\n",
    "    \n",
    "    # A previous line of code found the annual difference DataArray's (for year minus \n",
    "    # year-1) which are completely filled with NaNs (i.e. the years for which year or \n",
    "    # year-1 includes data from a year for which there is no FAPAR data). The following \n",
    "    # code then computes the intersection of this set with the set of annual difference \n",
    "    # DataArray's used in calculating the rolling average centred upon each year between \n",
    "    # year_start and year_end (inclusive). This gives the number and hence percentage of\n",
    "    # NaN DataArray's used in the computation of each year's rolling average.\n",
    "    \n",
    "    # This is a dictionary where elements will be appended onto in the following for loop.\n",
    "    # It gives the glass source (\"avhrr\", \"modis\", or \"mixed\") for each rolling avg.\n",
    "    glass_source_roll = {}\n",
    "    \n",
    "    for year in ds_roll_diff.year:\n",
    "        year = int(year)\n",
    "        # Years of annual difference DataArray's used in computing rolling avg for year.\n",
    "        years_diff_used = set(range(year - int((window_size-1)/2) + 1, \n",
    "                                    year + int((window_size-1)/2) + 1)\n",
    "                             )\n",
    "        # Number of NaN annual difference DataArray's used.\n",
    "        num_diff_nan = len(years_diff_nan\n",
    "                           .intersection(years_diff_used)\n",
    "                          )\n",
    "        # Percentage of annual difference DataArray's used which were NaN DataArray's.\n",
    "        per_diff_nan = round(num_diff_nan / (window_size - 1) * 100)\n",
    "        \n",
    "        if per_diff_nan > per_diff_nan_max:\n",
    "            msg_nan = (f\"WARNING: A DataArray with NaN's was returned for {year}'s \" +\n",
    "                       f\"rolling avg MFAPAR since {per_diff_nan}% of necessary annual \" +\n",
    "                       f\"difference DataArray's were NaN's (max is {per_diff_nan_max})%.\")\n",
    "            logging.warning(msg_nan)\n",
    "            print(msg_nan)\n",
    "        elif per_diff_nan > 0:\n",
    "            msg_nan = (f\"WARNING: {per_diff_nan}% of the annual difference DataArray's \" +\n",
    "                       f\"used in computing {year}'s rolling avg MFAPAR were NaN's and \" +\n",
    "                       \"ignored.\")\n",
    "            logging.warning(msg_nan)\n",
    "            print(msg_nan)\n",
    "            \n",
    "        if year_mixed in years_diff_used:\n",
    "            msg_mixed_roll = (f\"WARNING: Rolling avg for year {year} uses both AVHRR \" +\n",
    "                              \"and MODIS data (mixed).\")\n",
    "            logging.warning(msg_mixed_roll)\n",
    "            print(msg_mixed_roll)\n",
    "            \n",
    "        if all(glass_source_diff[str(year_diff)] == \"avhrr\" \n",
    "               for year_diff in years_diff_used):\n",
    "            glass_source_roll[str(year)] = \"avhrr\"\n",
    "        elif all(glass_source_diff[str(year_diff)] == \"modis\" \n",
    "               for year_diff in years_diff_used):\n",
    "            glass_source_roll[str(year)] = \"modis\"\n",
    "        else:\n",
    "            glass_source_roll[str(year)] = \"mixed\"\n",
    "    \n",
    "    # Add attributes to each DataArray within Dataset.\n",
    "    \n",
    "    logging.info(\"Adding: attributes for each DataArray within output \"+\n",
    "                 f\"Dataset from {func_cur}.\")\n",
    "    for da_name in [*ds_roll_diff.keys()]:\n",
    "        ds_roll_diff[da_name].attrs = copy.deepcopy(attrs_da[da_name])\n",
    "        ds_roll_diff[da_name].attrs[\"abbreviation\"] = (\n",
    "            \"$annual \\ difference _{{{} \\ year}} ^{{roll \\ avg}}$({})\"\n",
    "            .format(window_size, ds_roll_diff[da_name].attrs[\"abbreviation\"])\n",
    "        )\n",
    "        ds_roll_diff[da_name].attrs[\"full_name\"] = (\n",
    "            f\"{window_size}-Year Rolling Average of Annual Difference in \" + \n",
    "            ds_roll_diff[da_name].attrs[\"full_name\"]\n",
    "        )\n",
    "        ds_roll_diff[da_name].attrs.update(glass_source_roll)\n",
    "    \n",
    "    # Add attributes to Dataset.\n",
    "    \n",
    "    add_ds_attrs(ds_roll_diff, time_exec, func_cur, func_1up, args_cur, args_cur_values)\n",
    "    \n",
    "    # Create output file in data_processed folder.\n",
    "    \n",
    "    create_output_file(ds_roll_diff, path_output_glass_roll, func_1up)\n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e15b0-10c0-40b6-9251-4c81635b07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## High level calculation functions to create all possible data files.\n",
    "\n",
    "def create_all_possible_calc_data_files(region, period_start, period_end, months_subset):\n",
    "    \n",
    "    \"\"\"\n",
    "    For the given inputs, run all possible calculation functions. For calculation\n",
    "    functions which require a var_or_dvar input, the function is run for every\n",
    "    var_or_dvar possible (i.e. all items in the vars_and_dvars_era5_all list\n",
    "    in the global settings).\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(region=region, period_start=period_start, period_end=period_end,\n",
    "               months_subset=months_subset)\n",
    "    \n",
    "    months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Executing: {func_cur} to create all possible calc data files \" +\n",
    "                     f\"in {region} over {months_subset_str} months between \" + \n",
    "                     f\"{period_start} and {period_end}.\")\n",
    "    else:\n",
    "        logging.info(f\"Executing: {func_cur} to create all possible calc data files \" +\n",
    "                     f\"in {region} over {months_subset_str} months between \" + \n",
    "                     f\"{period_start} and {period_end} for use in {func_1up}.\")\n",
    "    \n",
    "    for calc_func_name in calc_func_names:\n",
    "        calc_func = globals()[calc_func_name]\n",
    "        \n",
    "        if calc_func_name == \"calc_era5_wsd_clim\":\n",
    "            path = get_path_for_calc_func(\n",
    "                calc_func_name=calc_func_name, region=region, period_start=period_start, \n",
    "                period_end=period_end, months_subset=months_subset\n",
    "            )\n",
    "            if Path(path).exists():\n",
    "                msg_exists = f\"Skipped: file already exists: {path}.\"\n",
    "                logging.info(msg_exists)\n",
    "                print(msg_exists)\n",
    "            else:\n",
    "                calc_func(\n",
    "                    region=region, period_start=period_start, period_end=period_end,\n",
    "                    months_subset=months_subset\n",
    "                )\n",
    "        elif calc_func_name == \"calc_glass_mean_clim\":\n",
    "            for glass_source in glass_sources_all:\n",
    "                path = get_path_for_calc_func(\n",
    "                    calc_func_name=calc_func_name, region=region, \n",
    "                    period_start=period_start, period_end=period_end, \n",
    "                    months_subset=months_subset, glass_source_pref=glass_source\n",
    "                )                \n",
    "                if Path(path).exists():\n",
    "                    msg_exists = f\"Skipped: file already exists: {path}.\"\n",
    "                    logging.info(msg_exists)\n",
    "                    print(msg_exists)\n",
    "                else:\n",
    "                    calc_func(\n",
    "                        region=region, period_start=period_start, period_end=period_end,\n",
    "                        months_subset=months_subset, glass_source_pref=glass_source\n",
    "                    )\n",
    "        else:\n",
    "            for var_or_dvar in vars_and_dvars_era5_all:\n",
    "                path = get_path_for_calc_func(\n",
    "                    calc_func_name=calc_func_name, region=region, \n",
    "                    period_start=period_start, period_end=period_end, \n",
    "                    months_subset=months_subset, var_or_dvar=var_or_dvar\n",
    "                )                \n",
    "                if Path(path).exists():\n",
    "                    msg_exists = f\"Skipped: file already exists: {path}.\"\n",
    "                    logging.info(msg_exists)\n",
    "                    print(msg_exists)\n",
    "                else:\n",
    "                    calc_func(\n",
    "                        region=region, period_start=period_start, period_end=period_end,\n",
    "                        months_subset=months_subset, var_or_dvar=var_or_dvar\n",
    "                    )\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b91b6-9fd3-47b5-a69c-f532b7874d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_possible_diff_data_files(region, period1_start, period1_end,\n",
    "                                        period2_start, period2_end, months_subset):\n",
    "    \n",
    "    \"\"\"\n",
    "    For the given inputs, run calc_diff over all possible calculation functions. \n",
    "    For calculation functions which require a var_or_dvar input, the function \n",
    "    is run for every var_or_dvar possible (i.e. all items in the vars_and_dvars_era5_all \n",
    "    list in the global settings).\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of: [\"ca\", \"sa\", \"wa\"].\n",
    "        period1_start (str): Start of first period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period1_end (str): End of first period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period2_start (str): Start of second period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period2_end (str): End of second period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        months_subset (str or list): Subset of period to perform calculation over.\n",
    "            Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "            list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_exec = datetime.today()\n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    frame_cur = inspect.currentframe()\n",
    "    args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "    create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "                                    args_cur, args_cur_values)\n",
    "    \n",
    "    check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "    check_args(region=region, period_start=period1_start, period_end=period1_end, \n",
    "               months_subset=months_subset)\n",
    "    check_args(period_start=period2_start, period_end=period2_end, \n",
    "               months_subset=months_subset)\n",
    "    \n",
    "    months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "    if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "        logging.info(f\"Executing: {func_cur} to create all possible {months_subset_str} \" +\n",
    "                     f\"difference data files in {region} over {period1_start} to \" +\n",
    "                     f\"{period1_end} and {period2_start} to {period2_end}.\")\n",
    "    else:\n",
    "        logging.info(f\"Executing: {func_cur} to create all possible {months_subset_str} \" +\n",
    "                     f\"difference data files in {region} over {period1_start} to \" +\n",
    "                     f\"{period1_end} and {period2_start} to {period2_end} \" +\n",
    "                     f\"for use in {func_1up}.\")\n",
    "    \n",
    "    for calc_func_name in calc_func_names:\n",
    "        calc_func = globals()[calc_func_name]\n",
    "        \n",
    "        if calc_func_name == \"calc_era5_wsd_clim\":\n",
    "            path = get_path_for_calc_diff(\n",
    "                calc_func_name=calc_func_name, region=region, \n",
    "                period1_start=period1_start, period1_end=period1_end, \n",
    "                period2_start=period2_start, period2_end=period2_end, \n",
    "                months_subset=months_subset\n",
    "            )\n",
    "            if Path(path).exists():\n",
    "                msg_exists = f\"Skipped: file already exists: {path}.\"\n",
    "                logging.info(msg_exists)\n",
    "                print(msg_exists)\n",
    "            else:\n",
    "                calc_diff(\n",
    "                    calc_func=calc_func, region=region, \n",
    "                    period1_start=period1_start, period1_end=period1_end, \n",
    "                    period2_start=period2_start, period2_end=period2_end, \n",
    "                    months_subset=months_subset\n",
    "                )\n",
    "        elif calc_func_name == \"calc_glass_mean_clim\":\n",
    "            for glass_source in glass_sources_all:       \n",
    "                path = get_path_for_calc_diff(\n",
    "                    calc_func_name=calc_func_name, region=region, \n",
    "                    period1_start=period1_start, period1_end=period1_end, \n",
    "                    period2_start=period2_start, period2_end=period2_end, \n",
    "                    months_subset=months_subset, glass_source_pref=glass_source\n",
    "                )\n",
    "                if Path(path).exists():\n",
    "                    msg_exists = f\"Skipped: file already exists: {path}.\"\n",
    "                    logging.info(msg_exists)\n",
    "                    print(msg_exists)\n",
    "                else:\n",
    "                    calc_diff(\n",
    "                        calc_func=calc_func, region=region, \n",
    "                        period1_start=period1_start, period1_end=period1_end, \n",
    "                        period2_start=period2_start, period2_end=period2_end, \n",
    "                        months_subset=months_subset, glass_source_pref=glass_source\n",
    "                    )\n",
    "        else:\n",
    "            for var_or_dvar in vars_and_dvars_era5_all:       \n",
    "                path = get_path_for_calc_diff(\n",
    "                    calc_func_name=calc_func_name, region=region, \n",
    "                    period1_start=period1_start, period1_end=period1_end, \n",
    "                    period2_start=period2_start, period2_end=period2_end, \n",
    "                    months_subset=months_subset, var_or_dvar=var_or_dvar\n",
    "                )\n",
    "                if Path(path).exists():\n",
    "                    msg_exists = f\"Skipped: file already exists: {path}.\"\n",
    "                    logging.info(msg_exists)\n",
    "                    print(msg_exists)\n",
    "                else:\n",
    "                    calc_diff(\n",
    "                        calc_func=calc_func, region=region, \n",
    "                        period1_start=period1_start, period1_end=period1_end, \n",
    "                        period2_start=period2_start, period2_end=period2_end, \n",
    "                        months_subset=months_subset, var_or_dvar=var_or_dvar\n",
    "                    )\n",
    "    \n",
    "    remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338c14a-f021-47d4-8aa8-1c3fef78f208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd6564-617d-48c6-8f23-11cc1370d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "# client = Client()\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e6c99-165d-41e2-a70b-d485f812254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbe3d9-d31a-4bad-9692-2d49273aed35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d2aa4-54fc-4f03-b720-ae972e785f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as ipw\n",
    "import hvplot.xarray # noqa\n",
    "import hvplot.pandas # noqa\n",
    "import panel as pn\n",
    "import pandas as pd\n",
    "import panel.widgets as pnw\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea63a2b-01db-4e49-af79-b28b448e328a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b0e6d-017b-409e-ab79-4c243781629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_glass_mean_clim(\"wa\", \"Jun-2000\", \"Aug-2005\", [8, 6,7], \"modis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77b866-4711-4d7c-8354-9c63932bfc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_era5_mdp_clim_given_var_or_dvar(\"sa\", \"Dec-1994\", \"Feb-2000\", \"djf\", \"wv10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026a476-fd9a-47a8-a2ee-8874caa4f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_era5_mdp_clim_stats_given_var_or_dvar(\"sa\", \"Dec-1994\", \"Feb-2000\", \"jja\", \"dwv100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f459ee-dc9a-487f-b64c-6d93f55d9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_era5_wsd_clim(\"wa\", \"Jun-2000\", \"Aug-2005\", [1,3,5,7,9,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a787a65-f6a2-4bb7-917d-dc21684d9f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_diff(calc_era5_mdp_clim_given_var_or_dvar, \"ca\", \"Jan-1985\", \"Dec-1994\", \"Jan-1995\", \"Jan-2004\", \"all\", var_or_dvar=\"dnac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d53130-ee5b-44f2-92a0-b0ebdee3cd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebebe984-2aed-461d-9bde-7fd0a6931129",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = xr.open_dataset(\"../data_processed/glass_mean_clim/cfv00_calc_wa_Jun-2000_Aug-2005_6-7-8_glass-mean_modis.nc\")\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57091f5c-bc05-48bc-b44d-9ad5892fc25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[\"mlai\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9d69b-05e4-4097-835d-8ea036a9d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[\"mfapar\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71482c39-6104-4bc5-80fd-253b56449c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3141d8d-5f4d-4add-b119-355243ecf1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = xr.open_dataset(\"../data_processed/era5_mdp_clim_given_var_or_dvar/cfv00_calc_sa_Dec-1994_Feb-2000_djf_era5-mdp_wv10.nc\")\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b592be9-05f4-4d1d-a4ba-a1115acdde34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2[\"u10\"].sel(hour=21).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a6407-0aaf-4f88-ba3d-d7d0257f32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2[\"v10\"].sel(hour=21).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5164b8cf-38e6-4e2d-b87b-24889694cf0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310a40d-2cd7-4c71-9f74-454133810524",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = xr.open_dataset(\"../data_processed/era5_mdp_clim_given_var_or_dvar/cfv00_diff_ca_Jan-1985_Dec-1994_Jan-1995_Jan-2004_all_era5-mdp_dnac.nc\")\n",
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e222fb-d81b-4f44-b4c1-20abf9cf56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3[\"dnse\"].sel(hour=21).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a2673-eada-4552-b536-01e2f9600c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3[\"dvidmf\"].sel(hour=21).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ec6f0-d32e-40d9-881a-f675fbc12e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3[\"dtcwv\"].sel(hour=21).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7553c-7273-40f8-bfa2-e25da5162c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3[\"dnac\"].sel(hour=21).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346fa51-29a1-4b11-877a-7561594f1b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e2901-c282-44d2-ae22-8c76babd59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4 = xr.open_dataset(\"../data_processed/era5_mdp_clim_stats_given_var_or_dvar/cfv00_calc_sa_Dec-1994_Feb-2000_jja_era5-mdp_dwv100_stats.nc\")\n",
    "test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca63b9c-ab3d-4f41-819e-6911f289e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4[\"hour_max\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1a306-8cd6-447c-af70-5f2830663e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4[\"hour_min\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff999fa-6c1d-4042-ba26-b482f5528799",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4[\"max_u\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f160e8c2-a469-4fdc-8aef-2f15d32db10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4[\"max_v\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df306ea7-42ba-4960-b0c2-d16bf999004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4[\"min_u\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d01f8-5c03-4826-91e6-06cfcc2e6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4[\"min_v\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f1e05-081c-4556-a128-9632fc43d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4[\"mean_u\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e707b5-89f0-4f27-b2c9-5c2559d36f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4[\"mean_v\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c44b5-93cd-4d89-b62d-961289f7e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test4[\"range\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e4d41-18b8-4c9c-b6a7-8c2772ff09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test4[\"max\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb201cb6-5f8a-4225-ad58-ea5d06aefb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test4[\"min\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b2442-39fe-4885-812d-1670c6301bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test4[\"mean\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d99f3c-84e9-4754-acdf-04708d5aec8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f3e83-0b32-4b5c-a0ec-e09a0dffdf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test5 = xr.open_dataset(\"../data_processed/era5_wsd_clim/cfv00_calc_wa_Jun-2000_Aug-2005_1-3-5-7-9-11_era5-wsd.nc\")\n",
    "test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e32c8-5f3a-47f0-a8ab-d06ac71d4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test5[\"ws100_mean\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c6aab-e89e-4dc2-9557-b8b07353dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test5[\"ws100_std\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aece03-3a75-4f63-a449-873e2452c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "test5[\"c100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76748738-3238-4d94-b5f6-ede59a00088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test5[\"k100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f496f8b-8305-485e-aa69-5b6761ff23dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test5[\"eroe100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55924ea6-0418-452a-b3a0-1f2a77f82d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test5[\"tgcf100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb571d2-bf2c-4959-b2df-886af0ac9800",
   "metadata": {},
   "outputs": [],
   "source": [
    "test5[\"eroe100\"].where(test5[\"eroe100\"]==test5[\"eroe100\"].max(), drop = True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd438a43-e098-4eb5-afd2-c101e4b9b573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66fad0-b385-429f-a83b-196a01915645",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_diff(calc_glass_mean_clim, \"wa\", \"Jan-1985\", \"Dec-1990\", \"Jan-2005\", \"Dec-2010\", \"all\", glass_source_pref=\"avhrr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97083901-4d5f-4936-8f1f-f0969f3453ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_diff(calc_era5_mdp_clim_given_var_or_dvar, \"wa\", \"Jan-1985\", \"Dec-1990\", \"Jan-2005\", \"Dec-2010\", \"all\", var_or_dvar=\"nac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4316c9-bd78-413f-9f96-8ec2a9f731ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_diff(calc_era5_mdp_clim_stats_given_var_or_dvar, \"wa\", \"Jan-1985\", \"Dec-1990\", \"Jan-2005\", \"Dec-2010\", \"all\", var_or_dvar=\"wv10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2644383-3505-4e62-841a-223e4f2f1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_diff(calc_era5_wsd_clim, \"wa\", \"Jan-1985\", \"Dec-1990\", \"Jan-2005\", \"Dec-2010\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45285294-cabc-41f8-a1b6-d7a40d2bca51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f57639-f3c8-4edd-b3f0-126e72faf50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test6 = xr.open_dataset(\"../data_processed/glass_mean_clim/cfv00_diff_wa_Jan-1985_Dec-1990_Jan-2005_Dec-2010_all_glass-mean_avhrr.nc\")\n",
    "test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe330c76-b68d-4c08-a41a-0c8f74988bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test6[\"mlai\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c84aaa9-825d-45c9-9b86-12c6de038119",
   "metadata": {},
   "outputs": [],
   "source": [
    "test6[\"mfapar\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c682304-57f3-42f7-a133-97ebd73c5993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4111ad93-7346-4c6b-8a8f-aeb4dd8960ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test7 = xr.open_dataset(\"../data_processed/era5_mdp_clim_given_var_or_dvar/cfv00_diff_wa_Jan-1985_Dec-1990_Jan-2005_Dec-2010_all_era5-mdp_nac.nc\")\n",
    "test7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefaa9b-4ec9-433f-8cf4-923275171eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test7[\"nse\"].sel(hour=21).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1691fd03-3d59-4231-b89c-ce70da34cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "test7[\"vidmf\"].sel(hour=21).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d99b0f-224d-4101-bf6b-616e0a2819f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test7[\"tcwv\"].sel(hour=21).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b45d15-4f11-4114-b4c1-6ea744ea0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test7[\"nac\"].sel(hour=21).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee57a38-dbd2-42d1-9cc9-e973a1a1d406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933bb519-72f7-4b6c-b257-afab0ccbc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test8 = xr.open_dataset(\"../data_processed/era5_mdp_clim_stats_given_var_or_dvar/cfv00_diff_wa_Jan-1985_Dec-1990_Jan-2005_Dec-2010_all_era5-mdp_wv10_stats.nc\")\n",
    "test8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f2ddf-46cc-4873-857e-668f64f35d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test8[\"hour_max\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d47d00-46d5-41e8-8613-4763e5f31bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test8[\"hour_min\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed2693-c74a-410a-b03c-2729faad5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test8[\"max_u\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131cae82-0c33-4e29-a3ea-4ed745f70f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test8[\"max_v\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9d571-b64f-428e-ad6e-86389df26374",
   "metadata": {},
   "outputs": [],
   "source": [
    "test8[\"min_u\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fecdea-8d3c-46f4-868f-2624940609ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test8[\"min_v\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbfcb85-0723-4525-83ac-611452fd654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test8[\"mean_u\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc3696a-c913-4003-bc86-ceffc9822be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test8[\"mean_v\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b5c30d-045a-42b8-b2a1-0725bdea4b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test8[\"range\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2eed3-50af-4c45-9aa1-caba4cb8c20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e045c86-f7d9-4044-903f-957483b3f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test9 = xr.open_dataset(\"../data_processed/era5_wsd_clim/cfv00_diff_wa_Jan-1985_Dec-1990_Jan-2005_Dec-2010_all_era5-wsd.nc\")\n",
    "test9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab93d0-e983-4e39-8869-56533fe934ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test9[\"ws100_mean\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e6691-ee8e-494b-88b5-4a01c46f09dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test9[\"ws100_std\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08194bea-627e-47bb-b7d1-f71417aacf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test9[\"c100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6c7b5-d9ad-413e-94dd-1e8907100587",
   "metadata": {},
   "outputs": [],
   "source": [
    "test9[\"k100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e49ee-839b-4873-b836-f7e9038516f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test9[\"eroe100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed90b3-1d43-4a84-a2a7-4e1b69a2511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test9[\"tgcf100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010eb5f-06fd-4a67-8517-a01506c4eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test9[\"eroe100\"].where(test9[\"eroe100\"]==test9[\"eroe100\"].max(), drop = True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f376d0-d48a-4014-832c-5377e915a082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57a8a1-bf42-4a53-89c6-5430b584dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_diff(calc_era5_mdp_clim_stats_given_var_or_dvar, \"wa\", \"Jan-1992\", \"Dec-1996\", \"Jan-2002\", \"Dec-2006\", \"all\", var_or_dvar=\"wv100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f7b11-08b9-4f4a-9383-392128733dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_diff(calc_era5_mdp_clim_stats_given_var_or_dvar, \"wa\", \"Jan-1992\", \"Dec-1996\", \"Jan-2002\", \"Dec-2006\", \"all\", var_or_dvar=\"ws100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba069c-c866-42ad-bfea-5f01f178a909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc0289-486d-4536-9d1b-9aa25eff1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "test10 = xr.open_dataset(\"../data_processed/era5_mdp_clim_stats_given_var_or_dvar/cfv00_diff_wa_Jan-1992_Dec-1996_Jan-2002_Dec-2006_all_era5-mdp_wv100_stats.nc\")\n",
    "test10[\"range\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e4465-2f77-4b79-a402-8bc5b7db64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test11 = xr.open_dataset(\"../data_processed/era5_mdp_clim_stats_given_var_or_dvar/cfv00_diff_wa_Jan-1992_Dec-1996_Jan-2002_Dec-2006_all_era5-mdp_ws100_stats.nc\")\n",
    "test11[\"range\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd37427-ba7c-4614-bcc4-6bdeef093ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a3b6b-3db3-4802-8b86-5fd53c82947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_era5_orog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c0b41-bae6-48d8-8308-81c4a271fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test12 = xr.open_dataset(\"../data_processed/era5_orog/cfv00_calc_global_era5-orog.nc\")\n",
    "test12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846202b0-0276-4ec1-8510-78366ce57a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test12[\"lse\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668370e-0a29-4e89-b421-d854a8e12ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test12[\"ssgo\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19b57c-153c-4e9c-89a3-8a0dc2a48ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162deec8-e74f-42be-a6b7-c099fb0fec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_glass_rolling_avg_of_annual_diff(\"wa\", 1984, 1987, \"all\", 7, \"avhrr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1fc8c3-38cf-4523-8b5e-445c8dc5d158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63754e1-5ebf-430f-ab3b-fad7fbbc4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "test13 = xr.open_dataset(\"../data_processed/glass_rolling_avg_of_annual_diff/cfv00_calc_wa_1984_1987_all_7-year_glass-rolling-diff_pref-avhrr.nc\")\n",
    "test13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e200530-9dda-444b-9e60-2065fc4a364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test13[\"mlai\"].isel(year=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152deec5-dfd9-4ee3-9183-ea97a2eed36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test13[\"mfapar\"].isel(year=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6864474-bd56-46a2-971b-194baa273141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d82c6-ef83-4c5a-9a72-3db1e28aa979",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_glass_rolling_avg_of_annual_diff(\"wa\", 1983, 2019, \"all\", 5, \"avhrr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174fa020-f26c-4e7b-876c-0d102a9a6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_glass_rolling_avg_of_annual_diff(\"wa\", 1984, 2018, \"all\", 7, \"avhrr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b7262-6a68-4746-8cce-3a91a58878ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d406daca-731c-4f71-b568-87a35dea1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test14 = xr.open_dataset(\"../data_processed/glass_rolling_avg_of_annual_diff/cfv00_calc_wa_1983_2019_all_5-year_glass-rolling-diff_pref-avhrr.nc\")\n",
    "test14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b2772-4b34-4666-b33f-35d2476d99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test14[\"mlai\"].interactive.sel(year=pnw.DiscreteSlider).plot(cmap = \"RdBu\", vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04862d65-bb11-4ca8-8b79-3cf1088a1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "test14[\"mfapar\"].interactive.sel(year=pnw.DiscreteSlider).plot(cmap = \"RdBu\", vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c404f1df-d425-4886-b0f6-2360c7192a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad5dc0-f66b-4f49-beb2-c7e23475a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test15 = xr.open_dataset(\"../data_processed/glass_rolling_avg_of_annual_diff/cfv00_calc_wa_1984_2018_all_7-year_glass-rolling-diff_pref-avhrr.nc\")\n",
    "test15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27632f0-06fe-4ef2-be55-1014dd00e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test15[\"mlai\"].interactive.sel(year=pnw.DiscreteSlider).plot(cmap = \"RdBu\", vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ec5b0-615d-4a91-bb26-bda1aa55c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test15[\"mfapar\"].interactive.sel(year=pnw.DiscreteSlider).plot(cmap = \"RdBu\", vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f2279-5c29-4669-ad44-a34193e9c300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d81c2c1-761b-49c2-aa18-3e8786353449",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "create_all_possible_calc_data_files(\"wa\", \"Jan-1992\", \"Dec-1996\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604289e-ae41-4a8e-91d9-5f0d189cd7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "create_all_possible_diff_data_files(\"wa\", \"Jan-1992\", \"Dec-1996\", \"Jan-2002\", \"Dec-2006\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06fbf4-4af7-46bd-a1eb-458d93bd4a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037cb9a-4bb1-492c-8806-b0dac033046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test16 = xr.open_dataset(\"../data_processed/glass_mean_clim/cfv00_diff_wa_Jan-1992_Dec-1996_Jan-2002_Dec-2006_all_glass-mean_avhrr.nc\")\n",
    "test16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e995407-681b-4245-904e-ab2c4b408a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test16[\"mlai\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766e342-9447-4cd2-9fee-2f412ab39301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694d3f9-4b3d-4af7-8b0f-6663db3eb83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test17 = xr.open_dataset(\"../data_processed/era5_wsd_clim/cfv00_diff_wa_Jan-1992_Dec-1996_Jan-2002_Dec-2006_all_era5-wsd.nc\")\n",
    "test17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40cfacd-6ac8-4deb-8669-5ef61585b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test17[\"ws10_mean\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76248ba9-2556-48b2-ac92-092cff674b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b7a17a-8f3d-4bc9-9469-e1fbe2a62013",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "create_all_possible_diff_data_files(\"wa\", \"Jan-1992\", \"Dec-1996\", \"Jan-2002\", \"Dec-2006\", \"jja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e219451c-43b7-47c7-a4c6-951651d2b20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686a1af-0e37-4f9a-8c0a-a925b21eee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Below was deprecated after correspondence with ECMWF\n",
    "## specialist support confirmed that the definition of\n",
    "## vidmf included water vapour only (i.e. does not include\n",
    "## cloud liquid or frozen water fluxes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17300ce9-7461-4ce7-9911-6679494b8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mapping from ERA5 dataset variable names to own desired names, while\n",
    "# # also accounting for any var_or_dvar variable dependencies\n",
    "# vars_deps_and_rename = {\"ws10\": {\"u10\": \"u10\", \"v10\": \"v10\"},\n",
    "#                         \"ws100\": {\"u100\": \"u100\", \"v100\": \"v100\"},\n",
    "#                         \"wv10\": {\"u10\": \"u10\", \"v10\": \"v10\"},\n",
    "#                         \"wv100\": {\"u100\": \"u100\", \"v100\": \"v100\"},\n",
    "#                         \"mslp\": {\"msl\": \"mslp\"},\n",
    "#                         \"t2\": {\"t2m\": \"t2\"},\n",
    "#                         \"slhf\": {\"slhf\": \"slhf\"},\n",
    "#                         \"sshf\": {\"sshf\": \"sshf\"},\n",
    "#                         \"viec\": {\"p64.162\": \"viec\"},\n",
    "#                         \"vipile\": {\"p62.162\": \"vipile\"},\n",
    "#                         \"vike\": {\"p59.162\": \"vike\"},\n",
    "#                         \"tcclw\": {\"tclw\": \"tcclw\"},\n",
    "#                         \"tcwv\": {\"tcwv\": \"tcwv\"},\n",
    "#                         \"nac\": {\"e\": \"nse\", \"p84.162\": \"vidmf\", \"p80.162\": \"vidcfwf\",\n",
    "#                                 \"p79.162\": \"vidclwf\", \"tcwv\": \"tcwv\"}\n",
    "#                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3886d1a9-3576-4488-97ca-a9edc8713a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_nac(da_nse, da_vidmf, da_vidcfwf, da_vidclwf, da_tcwv):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Calculate net atmospheric condensation from ERA5 atmospheric variables.\n",
    "    \n",
    "#     Arguments:\n",
    "#         da_nse (xarray.DataArray): Net surface evaporation [kg m-2 s-1].\n",
    "#         da_vidmf (xarray.DataArray): Vertical integral of\n",
    "#             divergence of moisture flux [kg m-2 s-1].\n",
    "#         da_vidcfwf (xarray.DataArray): Vertical integral of \n",
    "#             divergence of cloud frozen water flux [kg m-2 s-1].\n",
    "#         da_vidclwf (xarray.DataArray): Vertical integral of\n",
    "#             divergence of cloud liquid water flux [kg m-2 s-1].\n",
    "#         da_tcwv (xarray.DataArray): Total column water vapour [kg m-2].\n",
    "        \n",
    "#     Returns:\n",
    "#         da_nac (xarray.DataArray): Net atmospheric condensation [kg m-2 s-1].\n",
    "        \n",
    "#     Performs a vectorised computation on data arrays containing ERA5 atmospheric\n",
    "#     variables and returns the net atmospheric condensation. Dask is allowed.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     time_exec = datetime.today()\n",
    "#     func_cur = inspect.stack()[0][3]\n",
    "#     func_1up = inspect.stack()[1][3]\n",
    "#     frame_cur = inspect.currentframe()\n",
    "#     args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "#     create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "#                                     args_cur, args_cur_values)\n",
    "    \n",
    "#     assert str(type(da_nse)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "#         \"da_nse must be an xarray.DataArray\"\n",
    "#     assert str(type(da_vidmf)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "#         \"da_vidmf must be an xarray.DataArray\"\n",
    "#     assert str(type(da_vidcfwf)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "#         \"da_vidcfwf must be an xarray.DataArray\"\n",
    "#     assert str(type(da_vidclwf)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "#         \"da_vidclwf must be an xarray.DataArray\"\n",
    "#     assert str(type(da_tcwv)) == \"<class 'xarray.core.dataarray.DataArray'>\", \\\n",
    "#         \"da_tcwv must be an xarray.DataArray\"\n",
    "    \n",
    "#     if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "#         logging.debug(f\"Executing: {func_cur} to calculate net atmospheric condensation \" +\n",
    "#                       \"from ERA5 atmospheric variables.\")\n",
    "#     else:\n",
    "#         logging.debug(f\"Executing: {func_cur} to calculate net atmospheric condensation \" +\n",
    "#                       f\"from ERA5 atmospheric variables for use in {func_1up}.\")\n",
    "            \n",
    "#     logging.debug(\"Computing: average rate of change in tcwv over consecutive hours to \" +\n",
    "#                   \"estimate instantaneous rate of change at each hour for use in \" +\n",
    "#                   f\"{func_cur}.\")\n",
    "#     da_tcwv_for, da_tcwv_lag = get_da_mdp_for_and_lag(da_tcwv)\n",
    "#     # Estimate midpoint of rate of change using mean rate (result is in kg m-2 s-1).\n",
    "#     da_tcwv_change = (da_tcwv_for - da_tcwv_lag)/(2*3600)\n",
    "    \n",
    "#     def nac(nse, vidmf, vidcfwf, vidclwf, tcwv_change):\n",
    "#         return nse - (vidmf - vidcfwf - vidclwf) - tcwv_change\n",
    "#     da_nse = xr.apply_ufunc(nac, da_nse, da_vidmf, da_vidcfwf, da_vidclwf, \n",
    "#                             da_tcwv_change, dask = \"allowed\")\n",
    "    \n",
    "#     if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "#         logging.info(\"Obtained: net atmospheric condensation from ERA5 atmospheric \" +\n",
    "#                      \"variables.\")\n",
    "#     else:\n",
    "#         logging.info(\"Obtained: net atmospheric condensation from ERA5 atmospheric \" +\n",
    "#                      f\"variables for use in {func_1up}.\")\n",
    "    \n",
    "#     remove_handlers_if_directly_executed(func_1up)\n",
    "#     return da_nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407cc043-7e27-40dd-ae19-cb12735f8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_era5_mdp_clim_given_var_or_dvar(region, period_start, period_end, \n",
    "#                                          months_subset, var_or_dvar):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Calculate the mean diurnal profile (MDP) climatology for a particular\n",
    "#     variable or change in variable (compared to previous hour) using ERA5 data.\n",
    "    \n",
    "#     Arguments:\n",
    "#         region (str): Region to perform calculation over.\n",
    "#             Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "#         period_start (str): Start of period to perform calculation over.\n",
    "#             Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "#             Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "#         period_end (str): End of period to perform calculation over.\n",
    "#             Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "#             Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "#         months_subset (str or list): Subset of period to perform calculation over.\n",
    "#             Must be a str and one of: [\"all\", \"djf\", \"mam\", \"jja\", \"son\"], or a subset\n",
    "#             list of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] with at least one item.\n",
    "#         var_or_dvar (str): Variable or value of change in variable to perform\n",
    "#             calculation over. Must be one of: ['u10', 'v10', 'ws10', 'wv10', 'u100', \n",
    "#             'v100', 'ws100', 'wv100', 'mslp', 't2', 'slhf', 'sshf', 'nse', 'vidmf', \n",
    "#             'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac', 'blh', 'fa', 'cbh', 'tcc', \n",
    "#             'cape', 'ci', 'du10', 'dv10', 'dws10', 'dwv10', 'du100', 'dv100', 'dws100', \n",
    "#             'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dnse', 'dvidmf', 'dviec', \n",
    "#             'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac', 'dblh', 'dfa', 'dcbh', \n",
    "#             'dtcc', 'dcape', 'dci'].\n",
    "                        \n",
    "#     Returns:\n",
    "#         ../data_processed/era5_mdp_clim_given_var_or_dvar/{calc_funcs_ver}_calc_{region}_\n",
    "#         {period_start}_{period_end}_{months_subset_str}_era5-mdp_{var_or_dvar}.nc:\n",
    "#             Output netcdf4 file in data_processed folder containing the MDP for\n",
    "#             var_or_dvar. {calc_funcs_ver} is the version of the calc_funcs script\n",
    "#             being used. {months_subset_str} is a string representing the list of \n",
    "#             selected months to use as a subset.\n",
    "    \n",
    "#     For each grid cell, calculate the MDP for the selected var_or_dvar. The MDP\n",
    "#     values are computed over the period from period_start to period_end (inclusive),\n",
    "#     and only using a subset of data within this period (if months_subset not \"all\" is\n",
    "#     specified). The calculation uses monthly averaged reanalysis by hour of day netcdf4\n",
    "#     data from the data_raw folder as input, then outputs the result as a netcdf4 file\n",
    "#     into the data_processed folder.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     time_exec = datetime.today()\n",
    "#     func_cur = inspect.stack()[0][3]\n",
    "#     func_1up = inspect.stack()[1][3]\n",
    "#     frame_cur = inspect.currentframe()\n",
    "#     args_cur, _, _, args_cur_values = inspect.getargvalues(frame_cur)\n",
    "#     create_log_if_directly_executed(time_exec, func_cur, func_1up, \n",
    "#                                     args_cur, args_cur_values)\n",
    "    \n",
    "#     # Assert that input arguments are valid, and create path for months_subset.\n",
    "    \n",
    "#     check_args_for_none(func_cur, args_cur, args_cur_values)\n",
    "#     check_args(region=region, period_start=period_start, period_end=period_end,\n",
    "#                months_subset=months_subset, var_or_dvar=var_or_dvar)\n",
    "    \n",
    "#     months_subset_str = get_months_subset_str(months_subset=months_subset)\n",
    "    \n",
    "#     if (func_1up == \"<cell line: 1>\") | (func_1up == \"<module>\"):\n",
    "#         logging.info(f\"Executing: {func_cur} to obtain {months_subset_str} climatology \" +\n",
    "#                      f\"of {var_or_dvar} MDP between {period_start} and {period_end}.\")\n",
    "#     else:\n",
    "#         logging.info(f\"Executing: {func_cur} to obtain {months_subset_str} climatology \" +\n",
    "#                      f\"of {var_or_dvar} MDP between {period_start} and {period_end} \" +\n",
    "#                      f\"for use in {func_1up}.\")\n",
    "    \n",
    "#     # Define the output path, convert period_start and period_end to\n",
    "#     # datetime.datetime objects, and months_subset to list if a str was used as input.\n",
    "    \n",
    "#     path_output_mdp_clim = get_path_for_calc_func(\n",
    "#         calc_func_name=func_cur, region=region, period_start=period_start, \n",
    "#         period_end=period_end, months_subset=months_subset, var_or_dvar=var_or_dvar)\n",
    "#     terminate_if_file_exists(path_output_mdp_clim, func_cur, func_1up)\n",
    "    \n",
    "#     period_start, period_end, months_subset = convert_period_data_types(\n",
    "#         period_start=period_start, period_end=period_end, months_subset=months_subset)\n",
    "    \n",
    "#     # Obtain the var_or_dvar_layer and var_or_dvar_type classifications for the given \n",
    "#     # var_or_dvar. This is used later to identify which folder to open files from,\n",
    "#     # and whether to compute changes since the previous hour.\n",
    "    \n",
    "#     var_or_dvar_layer, var_or_dvar_type = get_var_or_dvar_layer_and_type(\n",
    "#         var_or_dvar=var_or_dvar)\n",
    "#     if var_or_dvar_type == \"vars\":\n",
    "#         var = var_or_dvar\n",
    "#     if var_or_dvar_type == \"dvars\":\n",
    "#         var = var_or_dvar[1:]\n",
    "    \n",
    "#     # The two functions below are used with xarray's open_mfdataset for parallel\n",
    "#     # computing using dask. Together they select out the relevant files to read\n",
    "#     # and persist in memory only the data which is necessary for the computation.\n",
    "    \n",
    "#     def filter_era5_month_hour_files(file_name):\n",
    "#         # This function is used as a mask in conjunction with the default python\n",
    "#         # filter function later, in order to select out the raw data files with\n",
    "#         # years within the input period. The following preprocess function also\n",
    "#         # selects out the relevant years (as well as months) but by applying a\n",
    "#         # filter on the list of file names first we can avoid preprocessing a \n",
    "#         # lot of files and hence save on memory.\n",
    "#         year = int(file_name[-7:-3])\n",
    "#         if period_start.year <= year <= period_end.year:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "    \n",
    "#     def preprocess_era5_month_hour(ds):\n",
    "#         # This function is used for the preprocess argument in open_mfdataset.\n",
    "#         # It selects out only the subset months for persist scalability,\n",
    "#         # renames variables and sorts data in time order.\n",
    "#         file_name = ds.encoding[\"source\"]\n",
    "#         logging.debug(f\"Preprocessing: file for use in {func_cur}: {file_name}.\")\n",
    "#         ds = (regrid_era5(ds=ds)[[*vars_deps_and_rename[var].keys()]]\n",
    "#               .rename(vars_deps_and_rename[var])\n",
    "#               .sel(time = ds.time.dt.month.isin(months_subset))\n",
    "#               # The downloaded ERA5 dataset is not sorted in time order (which\n",
    "#               # is a necessity for open_mfdataset, so we sort first over here.\n",
    "#               .sortby(\"time\")\n",
    "#              )\n",
    "#         return ds\n",
    "    \n",
    "#     # The following code loads in an existing MDP file for the var corresponding to\n",
    "#     # var_or_dvar, or creates one if it doesn't already exist. The True component of\n",
    "#     # the if statement will only ever be run for dvars since if it were a var then\n",
    "#     # path_output_var == path_output_mdp_clim and the code would have terminated earlier.\n",
    "    \n",
    "#     path_output_var = path_output_mdp_clim.replace(var_or_dvar, var)\n",
    "#     if Path(path_output_var).exists():\n",
    "#         msg_open = f\"Opening: existing file for use in {func_cur}: {path_output_var}.\"\n",
    "#         logging.info(msg_open)\n",
    "#         print(msg_open)\n",
    "#         ds_era5_mdp = xr.open_dataset(path_output_var, engine = \"netcdf4\")\n",
    "#     else:      \n",
    "#         # The following code opens the relevant monthy ERA5 files then computes\n",
    "#         # mean over each hour of the day.\n",
    "#         files_era5_month_hour = glob(\n",
    "#             f\"../data_raw/{region}_era5-slv-{var_or_dvar_layer}_month-hour/*.nc\")\n",
    "#         files_era5_month_hour.sort()\n",
    "#         if len(files_era5_month_hour) != number_of_era5_month_hour_files:\n",
    "#             msg_files = (\n",
    "#                 f\"WARNING: Expected {number_of_era5_month_hour_files} files in \" +\n",
    "#                 f\"../data_raw/{region}_era5-slv-{var_or_dvar_layer}_month-hour/ \" +\n",
    "#                 f\"but got {len(files_era5_month_hour)}. This could be because the \" + \n",
    "#                 \"data_download.ipynb notebook was not run properly. Or it could \" +\n",
    "#                 \"be that the user has selected a different number of years to \" +\n",
    "#                 \"retrieve data for in the data_download.ipynb notebook as \" +\n",
    "#                 \"compared with the original analysis. Or it may be that the \" +\n",
    "#                 \"user has changed some files in this folder.\"\n",
    "#             )\n",
    "#             logging.warning(msg_files)\n",
    "#             print(msg_files)\n",
    "            \n",
    "#         logging.debug(f\"Filtering: ERA5 {var_or_dvar_layer} files from data_raw \" +\n",
    "#                       f\"folder for use in {func_cur}.\")\n",
    "#         files_era5_month_hour_filtered = list(filter(filter_era5_month_hour_files, \n",
    "#                                                      files_era5_month_hour))\n",
    "#         files_era5_month_hour_filtered.sort()\n",
    "        \n",
    "#         logging.debug(f\"Opening: ERA5 {var_or_dvar_layer} files from data_raw \" +\n",
    "#                       f\"folder for use in {func_cur}.\")\n",
    "#         ds_era5_mdp = (xr.open_mfdataset(files_era5_month_hour_filtered,\n",
    "#                                          preprocess=preprocess_era5_month_hour,\n",
    "#                                          engine = \"netcdf4\", parallel = True)\n",
    "#                        # We add an extra month to period_end here because period_end was\n",
    "#                        # specified as a month, and conversion into a datetime object\n",
    "#                        # defaults to the first (rather than last) day of that month. The\n",
    "#                        # -1 hr is to avoid selecting first hour of the following month.\n",
    "#                        .sel(time = slice(period_start, period_end +\n",
    "#                                          relativedelta(months=1, hours = -1)))\n",
    "#                        # Rechunking after open_mfdataset here is actually bad practice\n",
    "#                        # since it requires extra computation, but the chunks argument\n",
    "#                        # for open_mfdataset doesn't seem to work here for some reason.\n",
    "#                        .chunk(chunks = {\"time\": chunksize})\n",
    "#                       )\n",
    "#         if priority == \"speed\":\n",
    "#             ds_era5_mdp = ds_era5_mdp.persist()\n",
    "        \n",
    "#         if var == \"ws10\":\n",
    "#             ds_era5_mdp = (get_magnitude(ds_era5_mdp[\"u10\"], ds_era5_mdp[\"v10\"])\n",
    "#                            .to_dataset(name = \"ws10\")\n",
    "#                           )\n",
    "            \n",
    "#         if var == \"ws100\":\n",
    "#             ds_era5_mdp = (get_magnitude(ds_era5_mdp[\"u100\"], ds_era5_mdp[\"v100\"])\n",
    "#                            .to_dataset(name = \"ws100\")\n",
    "#                           )\n",
    "        \n",
    "#         logging.debug(f\"Computing: MDPs of {[*ds_era5_mdp.keys()]} for use in {func_cur}.\")\n",
    "#         ds_era5_mdp = (ds_era5_mdp\n",
    "#                        # The time coordinates for the downloaded ERA5 dataset do not\n",
    "#                        # have perfect alignment across all variables, and sometimes\n",
    "#                        # the hour components for a particular month are distributed\n",
    "#                        # across different days (01 or 02) in that month. But this\n",
    "#                        # shouldn't affect the results of an hour-wise average.\n",
    "#                        .groupby(\"time.hour\")\n",
    "#                        .mean(\"time\")\n",
    "#                       )\n",
    "        \n",
    "#         # For slhf, sshf and nse: average values from hour before and hour after.\n",
    "#         # This is because these variables are hourly accumulations ending at each hour.\n",
    "#         # The average then provides an estimate of the instantaneous value at the \n",
    "#         # midpoint between these two accumulation periods. Afterwards, calculate net \n",
    "#         # atmospheric condensation from atmospheric variables.\n",
    "        \n",
    "#         if var == \"slhf\":\n",
    "#             logging.debug(f\"Computing: averages for consecutive {var} accumulation \" +\n",
    "#                           \"periods to estimate instantaneous hourly values for use \" +\n",
    "#                           f\"in {func_cur}.\")\n",
    "#             da_slhf_for, da_slhf_lag = get_da_mdp_for_and_lag(ds_era5_mdp[\"slhf\"])\n",
    "#             # Estimate midpoint and convert from J m-2 to W m-2.\n",
    "#             ds_era5_mdp[\"slhf\"] = (da_slhf_for + da_slhf_lag)/(2*3600)\n",
    "            \n",
    "#         if var == \"sshf\":\n",
    "#             logging.debug(f\"Computing: averages for consecutive {var} accumulation \" +\n",
    "#                           \"periods to estimate instantaneous hourly values for use \" +\n",
    "#                           f\"in {func_cur}.\")\n",
    "#             da_sshf_for, da_sshf_lag = get_da_mdp_for_and_lag(ds_era5_mdp[\"sshf\"])\n",
    "#             # Estimate midpoint and convert from J m-2 to W m-2.\n",
    "#             ds_era5_mdp[\"sshf\"] = (da_sshf_for + da_sshf_lag)/(2*3600)\n",
    "            \n",
    "#         if var == \"nac\":\n",
    "#             logging.debug(\"Computing: averages for consecutive nse accumulation \" +\n",
    "#                           f\"periods to estimate instantaneous {var} hourly values \" +\n",
    "#                           f\"for use in {func_cur}.\")\n",
    "#             da_nse_for, da_nse_lag = get_da_mdp_for_and_lag(ds_era5_mdp[\"nse\"])\n",
    "#             # Estimate midpoint and convert from m of water equivalent to kg m-2 s-1.\n",
    "#             ds_era5_mdp[\"nse\"] = (da_nse_for + da_nse_lag)/(2*3.6)\n",
    "#             ds_era5_mdp[\"nac\"] = get_nac(ds_era5_mdp[\"nse\"], ds_era5_mdp[\"vidmf\"], \n",
    "#                                      ds_era5_mdp[\"vidcfwf\"], ds_era5_mdp[\"vidclwf\"], \n",
    "#                                      ds_era5_mdp[\"tcwv\"])\n",
    "        \n",
    "#         # Add attributes to each DataArray within Dataset.\n",
    "        \n",
    "#         logging.info(\"Adding: attributes for each DataArray within output \"+\n",
    "#                      f\"Dataset from {func_cur}.\")\n",
    "#         for da_name in [*ds_era5_mdp.keys()]:\n",
    "#             ds_era5_mdp[da_name].attrs = copy.deepcopy(attrs_da[da_name])\n",
    "        \n",
    "#         # Add attributes to Dataset.\n",
    "    \n",
    "#         add_ds_attrs(ds_era5_mdp, time_exec, func_cur, func_1up, \n",
    "#                      args_cur, args_cur_values)\n",
    "        \n",
    "#         # Modify attributes in Dataset and output if var_or_dvar_type == \"dvars\" \n",
    "#         # (i.e. the MDP for var is being computed as an intermediate \n",
    "#         # output for the dvar MDP).\n",
    "        \n",
    "#         if var_or_dvar_type == \"dvars\":\n",
    "#             ds_era5_mdp.attrs[\"func_executed\"] = (\n",
    "#                 ds_era5_mdp.attrs[\"func_executed\"]\n",
    "#                 .replace(var_or_dvar, var)\n",
    "#             )\n",
    "#             create_output_file(ds_era5_mdp, path_output_var, func_1up)\n",
    "    \n",
    "#     # If a dvar was specified for var_or_dvar, calculate the change in the value\n",
    "#     # of the variable as compared with its value in the previous hour.\n",
    "    \n",
    "#     if var_or_dvar_type == \"dvars\":\n",
    "#         for da_name in [*ds_era5_mdp.keys()]:\n",
    "#             logging.info(f\"Obtaining d{da_name} MDP from {da_name} MDP for \" +\n",
    "#                          f\"use in {func_cur}.\")\n",
    "#             _, da_var_lag = get_da_mdp_for_and_lag(ds_era5_mdp[da_name])\n",
    "#             ds_era5_mdp[da_name] += - da_var_lag\n",
    "            \n",
    "#             # Add attributes to each DataArray within Dataset.\n",
    "            \n",
    "#             logging.info(\"Adding: attributes for each DataArray within output \"+\n",
    "#                          f\"Dataset from {func_cur}.\")\n",
    "#             ds_era5_mdp[da_name].attrs = copy.deepcopy(attrs_da[da_name])\n",
    "#             # Append entries to front of attributes if dvar is given.\n",
    "#             ds_era5_mdp[da_name].attrs[\"abbreviation\"] = (\n",
    "#                 \"d\" + ds_era5_mdp[da_name].attrs[\"abbreviation\"])\n",
    "#             ds_era5_mdp[da_name].attrs[\"full_name\"] = (\n",
    "#                 \"Hourly Change in \" + ds_era5_mdp[da_name].attrs[\"full_name\"])\n",
    "            \n",
    "#             # Rename DataArray names to include \"d\" in front.\n",
    "            \n",
    "#             ds_era5_mdp = ds_era5_mdp.rename({da_name: \"d\" + da_name})\n",
    "    \n",
    "#         # Add attributes to Dataset.\n",
    "    \n",
    "#         add_ds_attrs(ds_era5_mdp, time_exec, func_cur, func_1up, \n",
    "#                      args_cur, args_cur_values)\n",
    "    \n",
    "#     # Create output file in data_processed folder.\n",
    "    \n",
    "#     create_output_file(ds_era5_mdp, path_output_mdp_clim, func_1up)\n",
    "#     remove_handlers_if_directly_executed(func_1up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231e722-a073-4cd7-b126-1977fcc823db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
