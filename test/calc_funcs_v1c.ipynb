{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998f8680-5d1d-428f-8c44-d471c5ef256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries for calculation functions\n",
    "\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy.special import gamma\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59e3876d-1842-41ee-bc78-663c7762c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings for calculation functions\n",
    "\n",
    "# This is to get the version number of the calc_funcs script being used so that it\n",
    "# can be appended to the file name of any outputs. The reason this is done is because\n",
    "# the calculation functions below and the plot functions in the plot_funcs script both\n",
    "# output intermediate files one at a time from low level to high level, and that each\n",
    "# file name is used in recognising whether there is a need to re-run a script (if the\n",
    "# file already exists then the script is not run so as to save on computation).\n",
    "# However, this method can propagate errors from low level through to high level\n",
    "# if there has been a change to the code and/or output at the lower levels. By\n",
    "# appending the version number of the calc_funcs script being used, it forces all\n",
    "# intermediate files to be recreated from scratch rather than reuse intermediate files\n",
    "# which was outputted by outdated code. \"v00\" is used as a placeholder version number\n",
    "# if there is an error: it is used mostly for scripting purposes within an\n",
    "# interactive python notebook where the file name cannot be directly extracted\n",
    "# using the __file__ python variable.\n",
    "try:\n",
    "    calc_funcs_ver = Path(__file__).stem[-3:]\n",
    "except:\n",
    "    calc_funcs_ver = \"v00\"\n",
    "\n",
    "# Valid regions and their mapping to axis extents in [W, E, S, N] format \n",
    "# as well as timezones in hour +- GMT\n",
    "regions = {\n",
    "    # Central America (mostly Honduras-Nicaragua-Costa Rica)\n",
    "    \"ca\": {\"extent\": [-91, -81, 7, 17], \"tz\": -6},\n",
    "    # South America (mostly central and eastern Brazil)\n",
    "    \"sa\": {\"extent\": [-65, -30, -15, 0], \"tz\": -3},\n",
    "    # Western Australia (mostly near the west coast)\n",
    "    \"wa\": {\"extent\": [113, 123, -35, -30], \"tz\": +8}\n",
    "}\n",
    "\n",
    "# Earliest and latest entries in each GLASS dataset\n",
    "avhrr_earliest = \"Jan-1981\"\n",
    "modis_earliest = \"Mar-2000\"\n",
    "avhrr_latest = \"Dec-2018\"\n",
    "modis_latest = \"Dec-2021\"\n",
    "fapar_earliest = \"Jan-1982\"\n",
    "fapar_latest = \"Dec-2020\"\n",
    "\n",
    "# Size of chunks\n",
    "chunksize = \"500MB\"\n",
    "\n",
    "# Valid subsets to use as argument in climatologies and\n",
    "# their mapping to month numbers for use in xarray time slicing\n",
    "subsets = {\n",
    "    \"all\": [1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "    \"DJF\": [12,1,2], \"MAM\": [3,4,5], \"JJA\": [6,7,8], \"SON\": [9,10,11],\n",
    "    \"Jan\": [1], \"Feb\": [2], \"Mar\": [3], \"Apr\": [4], \"May\": [5], \"Jun\": [6],\n",
    "    \"Jul\": [7], \"Aug\": [8], \"Sep\": [9], \"Oct\": [10], \"Nov\": [11], \"Dec\": [12]\n",
    "}\n",
    "\n",
    "# Valid variables for use in analysis\n",
    "hours = list(range(0, 24))\n",
    "vars_glass = [\"lai\", \"fapar\"]\n",
    "vars_era5 = {\n",
    "    \"vars\": {\n",
    "        \"surface\": [\"wv10\", \"wv100\", \"mslp\", \"t2\", \"slhf\", \"sshf\"],\n",
    "        \"atmos\": [\"viec\", \"vipile\", \"vike\", \"tcclw\", \"tcwv\", \"nac\"]\n",
    "    },\n",
    "    \"dvars\": {\n",
    "        \"surface\": [\"dwv10\", \"dwv100\", \"dmslp\", \"dt2\", \"dslhf\", \"dsshf\"],\n",
    "        \"atmos\": [\"dviec\", \"dvipile\", \"dvike\", \"dtcclw\", \"dtcwv\", \"dnac\"]\n",
    "    }\n",
    "}\n",
    "vars_and_dvars_era5_all = (\n",
    "    vars_era5[\"vars\"][\"surface\"] + vars_era5[\"vars\"][\"atmos\"] +\n",
    "    vars_era5[\"dvars\"][\"surface\"] + vars_era5[\"dvars\"][\"atmos\"]\n",
    ")\n",
    "\n",
    "# File number check to make sure data_download notebook was run correctly\n",
    "number_of_glass_files = {\"lai\": {\"avhrr\": 1748, \"modis\": 1005},\n",
    "                         \"fapar\": {\"avhrr\": 1702, \"modis\": 960}\n",
    "                        }\n",
    "number_of_era5_month_hour_files = 42\n",
    "number_of_era5_hour_files = 42\n",
    "\n",
    "# Resolution of ERA5 dataset in degrees (used for regridding)\n",
    "res_era5 = 0.25\n",
    "\n",
    "# Speed (in m/s) for expected rate of exceedance analysis at 100 m\n",
    "speed_eroe = 42.5\n",
    "\n",
    "# Typical power curve for a 100 m turbine with 100 m rotor diameter and \n",
    "# a nameplate rating of around 2500 kW (used to compute gross capacity factor)\n",
    "# Speeds are in m/s, powers are in kW, data from https://www.thewindpower.net\n",
    "speeds_common = np.append(np.linspace(0, 25.5, 52), 999)\n",
    "power_nameplate = 2500\n",
    "# Vestas V100/2600\n",
    "powers_vestas = np.array([0, 0, 0, 0, 0, 0, 21, 63, 115, 172, 239, 318, 405, 550,\n",
    "                          706, 890, 1080, 1283, 1485, 1641, 1796, 1944, 2092, 2225,\n",
    "                          2351, 2440, 2502, 2560, 2584, 2597, 2600, 2600, 2600,\n",
    "                          2600, 2600, 2600, 2600, 2600, 2600, 2600, 2600, 2600,\n",
    "                          2600, 2600, 2600, 2600, 2600, 2600, 2600, 2600, 2600, 0, 0])\n",
    "# Goldwind GW100/2500\n",
    "powers_gw = np.array([0, 0, 0, 0, 0, 6, 34, 65, 101, 165, 235, 320, 409, 530, 655,\n",
    "                      826, 997, 1196, 1394, 1669, 1943, 2170, 2313, 2415, 2458,\n",
    "                      2485, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500,\n",
    "                      2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500,\n",
    "                      2500, 2500, 2500, 2500, 2500, 2500, 0, 0])\n",
    "# GE Energy 2.5-100\n",
    "powers_ge = np.array([0, 0, 0, 0, 0, 0, 10, 80, 160, 250, 340, 460, 590, 770, 952,\n",
    "                      1170, 1389, 1650, 1869, 2100, 2260, 2400, 2487, 2500, 2500,\n",
    "                      2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500,\n",
    "                      2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500, 2500,\n",
    "                      2500, 2500, 2500, 2500, 2500, 2500, 0, 0])\n",
    "# Average\n",
    "powers_avg = (powers_vestas/26*25 + powers_gw + powers_ge) / 3\n",
    "\n",
    "# Names of calculation functions\n",
    "calc_func_names = [\"calc_glass_mean_climatology\",\n",
    "                   \"calc_era5_mdp_climatology_given_var_or_dvar\",\n",
    "                   \"calc_era5_mdp_climatology_stats_given_var_or_dvar\",\n",
    "                   \"calc_era5_mdp_climatology_values_given_var_or_dvar_and_hour\",\n",
    "                   \"calc_era5_wsd_climatology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "500730ee-f637-47fb-861d-617517dbaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Supplementary functions for calculation functions\n",
    "\n",
    "def check_args(calc_func=None, region=None, period_start=None, period_end=None,\n",
    "               subset=None, var_or_dvar=None, hour=None,\n",
    "               vars_level=None, vars_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to check whether input arguments are valid.\n",
    "    \n",
    "    Arguments:\n",
    "        calc_func (function): Calculation function to compute difference in\n",
    "            results from. Must be one of: [\"calc_glass_mean_climatology\",\n",
    "            \"calc_era5_mdp_climatology_given_var_or_dvar\",\n",
    "            \"calc_era5_mdp_climatology_stats_given_var_or_dvar\",\n",
    "            \"calc_era5_mdp_climatology_values_given_var_or_dvar_and_hour\",\n",
    "            \"calc_era5_wsd_climatology\"].\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of: [\"ca\", \"sa\", \"wa\"].\n",
    "        period1_start (datetime.datetime): Start of first period to perform\n",
    "            calculation over. Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "            Note that this is a datetime.dateime object as opposed to str.\n",
    "        period1_end (datetime.datetime): End of first period to perform\n",
    "            calculation over. Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "            Note that this is a datetime.dateime object as opposed to str.\n",
    "        period2_start (datetime.datetime): Start of second period to perform\n",
    "            calculation over. Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "            Note that this is a datetime.dateime object as opposed to str.\n",
    "        period2_end (datetime.datetime): End of second period to perform\n",
    "            calculation over. Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "            Note that this is a datetime.dateime object as opposed to str.\n",
    "        subset (str): Subset of period to perform calculation over.\n",
    "            Must be one of: [\"all\", \"DJF\", \"MAM\", \"JJA\", \"SON\",\n",
    "            \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "            \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"].\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['wv10', 'wv100', 'mslp', 't2',\n",
    "            'slhf', 'sshf', 'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac',\n",
    "            'dwv10', 'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dviec',\n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac'].\n",
    "        hour (int): Hour of mean diurnal profile to compute value for.\n",
    "            Must be one of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "            13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23].\n",
    "        vars_level (str): Level from which to draw variables for analysis.\n",
    "            This is used for the plot_func script. Must be one of:\n",
    "            [\"surface\", \"atmos\"].\n",
    "        vars_type (str): Whether to analyse the variables themselves or the change\n",
    "            in their mean diurnal profile values as compared with their values\n",
    "            in the previous hour. This is used for the plot_func script.\n",
    "            Must be one of: [\"vars\", \"dvars\"].            \n",
    "    \n",
    "    Returns:\n",
    "        AssertionError if any of the input arguments are invalid.\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(f\"Executing: {func_cur} to check whether input arguments are valid.\")\n",
    "    else:\n",
    "        print(f\"Executing: {func_cur} to check whether input arguments into \" +\n",
    "              f\"{func_1up} are valid.\")\n",
    "    \n",
    "    if calc_func:\n",
    "        assert calc_func.__name__ in calc_func_names, \\\n",
    "            f\"calc_func must be one of: {calc_func_names}\"    \n",
    "    if region:\n",
    "        assert region in [*regions], \\\n",
    "            f\"region must be one of: {[*regions]}\"\n",
    "    if period_start:\n",
    "        assert period_start >= datetime.strptime(avhrr_earliest, \"%b-%Y\"), \\\n",
    "            f\"period_start must be equal to or later than {avhrr_earliest}\"        \n",
    "    if period_end:\n",
    "        assert period_end <= datetime.strptime(modis_latest, \"%b-%Y\"), \\\n",
    "            f\"period_end must be equal to or earlier than {modis_latest}\"\n",
    "    if (period_start is not None) & (period_end is not None):\n",
    "        assert period_end >= period_start, \\\n",
    "            \"period_end must be equal to or later than period_start\"        \n",
    "    if subset:\n",
    "        assert subset in [*subsets], \\\n",
    "            f\"subset must be one of: {[*subsets]}\"\n",
    "    if (period_start is not None) & (period_end is not None) & (subset is not None):\n",
    "        dates_in_period = pd.date_range(period_start, period_end, freq = \"MS\")\n",
    "        months_in_period = set(map(int, dates_in_period.strftime(\"%-m\")))\n",
    "        assert any(month in subsets[subset] for month in months_in_period), \\\n",
    "            \"period(s) must contain at least one month within the given subset\"\n",
    "    if var_or_dvar:\n",
    "        assert var_or_dvar in vars_and_dvars_era5_all, \\\n",
    "            f\"var_or_dvar must be one of: {vars_and_dvars_era5_all}\"\n",
    "    if hour:\n",
    "        assert hour in hours, \\\n",
    "            f\"hour must be one of: {hours}\"\n",
    "    if vars_level:\n",
    "        assert vars_level in [*[*vars_era5.values()][0].keys()], \\\n",
    "            f\"vars_level must be one of: {[*[*vars_era5.values()][0].keys()]}\"\n",
    "    if vars_type:\n",
    "        assert vars_type in [*vars_era5], \\\n",
    "            f\"vars_type must be one of: {[*vars_era5]}\"\n",
    "    \n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(\"Passed: validity check for input arguments.\")\n",
    "    else:\n",
    "        print(f\"Passed: validity check for input arguments into {func_1up}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc02f438-3c69-467c-83f7-cc3dcc22027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glass_data_source_to_use(period_start, period_end):\n",
    "    \n",
    "    \"\"\"\n",
    "    Select which GLASS data source (AVHRR or MODIS) to use.\n",
    "    \n",
    "    Arguments:\n",
    "        period_start (datetime.datetime): Start of period to perform calculation over.\n",
    "            Note that this is a datetime.dateime object as opposed to str.\n",
    "        period_end (datetime.datetime): End of period to perform calculation over.\n",
    "            Note that this is a datetime.dateime object as opposed to str.\n",
    "        \n",
    "    Returns:\n",
    "        glass_data_source (str): String indicating whether to use\n",
    "            \"avhrr\" or \"modis\" data for the given period.\n",
    "    \n",
    "    For the given period, select the most appropriate GLASS data source to use \n",
    "    (out of AVHRR and MODIS). MODIS is preferentially selected where the given \n",
    "    period is completely contained within the time range of MODIS data. \n",
    "    Otherwise, AVHRR data is used. Periods which simultaneously cover both an \n",
    "    AVHRR-only period (i.e. before Mar-2000) and a MODIS-only period \n",
    "    (i.e. after Dec-2018) are prevented from selection since summary statistics\n",
    "    over this range is subject to artefacts from the change in instruments.\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(f\"Executing: {func_cur} to select the appropriate \" +\n",
    "              \"glass data source for use between {} and {}.\"\n",
    "              .format(period_start.strftime(\"%b-%Y\"), period_end.strftime(\"%b-%Y\"))\n",
    "             )\n",
    "    else:\n",
    "        print(f\"Executing: {func_cur} to select the appropriate \" +\n",
    "              \"glass data source for use between {} and {} in {}.\"\n",
    "              .format(period_start.strftime(\"%b-%Y\"), period_end.strftime(\"%b-%Y\"),\n",
    "                      func_1up)\n",
    "             )\n",
    "    \n",
    "    check_args(period_start=period_start, period_end=period_end)\n",
    "    \n",
    "    if ((period_start >= datetime.strptime(avhrr_earliest, \"%b-%Y\")) & \n",
    "        (period_start < datetime.strptime(modis_earliest, \"%b-%Y\")) &\n",
    "        (period_end <= datetime.strptime(avhrr_latest, \"%b-%Y\"))\n",
    "       ):\n",
    "        glass_data_source = \"avhrr\"\n",
    "    elif ((period_start >= datetime.strptime(modis_earliest, \"%b-%Y\")) &\n",
    "          (period_end <= datetime.strptime(modis_latest, \"%b-%Y\"))\n",
    "         ):\n",
    "        glass_data_source = \"modis\"\n",
    "    else:\n",
    "        raise Exception(\"If period_start is before Mar-2000, \" +\n",
    "                        \"period_end cannot be after Dec-2018 \" +\n",
    "                        \"(since this would cover both an \" +\n",
    "                        \"AVHRR-only and a MODIS-only period)\")\n",
    "    \n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(\"Selected: {} glass data source for use between {} and {}.\"\n",
    "              .format(glass_data_source, period_start.strftime(\"%b-%Y\"),\n",
    "                      period_end.strftime(\"%b-%Y\"))\n",
    "             )\n",
    "    else:\n",
    "        print(\"Selected: {} glass data source for use between {} and {} in {}.\"\n",
    "              .format(glass_data_source, period_start.strftime(\"%b-%Y\"),\n",
    "                      period_end.strftime(\"%b-%Y\"), func_1up)\n",
    "             )\n",
    "        \n",
    "    return glass_data_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3644ec3-35e8-4f32-9450-f2fbfe8bb44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_era5(ds):\n",
    "    \n",
    "    \"\"\"\n",
    "    Regrid ERA5 xarray dataset.\n",
    "    \n",
    "    Arguments:\n",
    "        ds (xarray.Dataset): Dataset containing ERA5 data, loaded in\n",
    "            with xarray using the netcdf4 engine.\n",
    "                                \n",
    "    Returns:\n",
    "        ds_rg (xarray.Dataset): Dataset with regridded coordinates.\n",
    "        \n",
    "    Shifts each latitude coordinate south and longitude coordinate east by\n",
    "    half a grid cell. This reflects the fact that coordinates in the\n",
    "    original ERA5 dataset defines the north-western corner of each grid\n",
    "    cell, whereas xarray plots assuming the coordinates refer to the centre.\n",
    "    \"\"\"\n",
    "    \n",
    "    year_file = ds.encoding[\"source\"][-7:-3]\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(f\"Executing: {func_cur} on {year_file} file to make ERA5 \" +\n",
    "              \"coordinates consistent with xarray plotting.\")\n",
    "    else:\n",
    "        print(f\"Executing: {func_cur} on {year_file} file to make ERA5 \" +\n",
    "              f\"coordinates consistent with xarray plotting for use in {func_1up}.\")\n",
    "    \n",
    "    ds_rg = (ds\n",
    "            .assign_coords({\"latitude\": ds.latitude - res_era5/2,\n",
    "                            \"longitude\": (ds.longitude + 180 + res_era5/2) % 360 - 180})\n",
    "            # Redundant measure just in case longitudes exceed 180 degrees\n",
    "            .sortby(\"longitude\")\n",
    "            )\n",
    "    \n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(f\"Regridded: ERA5 coordinates in {year_file} file.\")\n",
    "    else:\n",
    "        print(f\"Regridded: ERA5 coordinates in {year_file} file for use in {func_1up}.\")\n",
    "    \n",
    "    return ds_rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f703f44e-a764-44ac-ab1b-3c548af6d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(da_x, da_y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate magnitude of 2D vectors given their components.\n",
    "    \n",
    "    Arguments:\n",
    "        da_x (xarray.DataArray): x-component of vectors.\n",
    "        da_y (xarray.DataArray): y-component of vectors.\n",
    "        \n",
    "    Returns:\n",
    "        da_r (xarray.DataArray); Magnitude of vectors.\n",
    "        \n",
    "    Performs a vectorised computation on two different data arrays\n",
    "    containing the x and y component of some vectors and returns\n",
    "    the magnitude of the vectors. Dask is allowed.\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(\"Executing: {} to calculate vector magnitudes from {} and {}.\"\n",
    "              .format(func_cur, da_x.name, da_y.name)\n",
    "             )\n",
    "    else:\n",
    "        print(\"Executing: {} to calculate vector magnitudes from {} and {} \"\n",
    "              .format(func_cur, da_x.name, da_y.name) + f\"for use in {func_1up}.\"\n",
    "             )\n",
    "    \n",
    "    r = lambda x, y: np.sqrt(x**2 + y**2)\n",
    "    da_r = xr.apply_ufunc(r, da_x, da_y, dask = \"allowed\")\n",
    "    \n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(\"Obtained: vector magnitudes from {} and {}.\".format(da_x.name, da_y.name))\n",
    "    else:\n",
    "        print(\"Obtained: vector magnitudes from {} and {} for use in {}.\"\n",
    "              .format(da_x.name, da_y.name, func_1up))\n",
    "    \n",
    "    return da_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d70f25-ec3c-4832-8aa6-b7f45e6498b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_params(da_mean, da_std):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain Weibull parameters for wind speed distribution from\n",
    "    mean and standard deviation.\n",
    "    \n",
    "    Arguments:\n",
    "        da_mean (xarray.DataArray): Mean wind speed.\n",
    "        da_std (xarray.DataArray): Standard deviation of wind speed.\n",
    "    \n",
    "    Returns:\n",
    "        da_c (xarray.DataArray): Scale parameter for empirical Weibull fit.\n",
    "        da_k (xarray.DataArray): Shape parameter for empirical Weibull fit.\n",
    "    \n",
    "    Performs a vectorised computation on two different data arrays\n",
    "    containing the mean and standard deviation of wind speed and returns\n",
    "    the Weibull scale and shape parameters for the fit. Dask is allowed.\n",
    "    This method uses equations (15) and (16) from an article by Justus et al.\n",
    "    (1977) titled \"Methods for Estimating Wind Speed Frequency Distributions\".\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(\"Executing: {} to obtain Weibull parameters from {} and {}.\"\n",
    "              .format(func_cur, da_mean.name, da_std.name)\n",
    "             )\n",
    "    else:\n",
    "        print(\"Executing: {} to obtain Weibull parameters from {} and {} \"\n",
    "              .format(func_cur, da_mean.name, da_std.name) + f\"for use in {func_1up}.\"\n",
    "             )\n",
    "    \n",
    "    k = lambda mean, std: (std / mean)**(-1.086)\n",
    "    da_k = xr.apply_ufunc(k, da_mean, da_std, dask = \"allowed\")\n",
    "    c = lambda mean, k: mean / gamma(1 + 1/k)\n",
    "    da_c = xr.apply_ufunc(c, da_mean, da_k, dask = \"allowed\")\n",
    "    \n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(\"Obtained: Weibull parameters from {} and {}.\"\n",
    "              .format(da_mean.name, da_std.name))\n",
    "    else:\n",
    "        print(\"Obtained: Weibull parameters from {} and {} for use in {}.\"\n",
    "              .format(da_mean.name, da_std.name, func_1up))\n",
    "    \n",
    "    return da_c, da_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9ce666-cc81-4e53-86ce-67e6ccb0a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_eroe(da_c, da_k, ws_exc):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain the expected rate of exceedance for a particular wind speed\n",
    "    from fitted Weibull parameters.\n",
    "    \n",
    "    Arguments:\n",
    "        da_c (xarray.DataArray): Scale parameter for empirical Weibull fit.\n",
    "        da_k (xarray.DataArray): Shape parameter for empirical Weibull fit.\n",
    "        ws_exc (float or int): Particular wind speed on which to conduct the\n",
    "            expected rate of exceedance analysis.\n",
    "        \n",
    "    Returns:\n",
    "        da_eroe (xarray.DataArray): Expected rate of exceedance from Weibull.\n",
    "        \n",
    "    For the given Weibull parameters, the expected rate of exceedance for a \n",
    "    particular wind speed is computed as 1 minus the cumulative probability\n",
    "    distribution for the Weibull fit.\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print((\"Executing: {} to obtain {} m/s expected rate of exceedance \" +\n",
    "               \"from {} and {}.\").format(func_cur, ws_exc, da_c.name, da_k.name)\n",
    "             )\n",
    "    else:\n",
    "        print((\"Executing: {} to obtain {} m/s expected rate of exceedance \" +\n",
    "               \"from {} and {} for use in {}.\")\n",
    "              .format(func_cur, ws_exc, da_c.name, da_k.name, func_1up)\n",
    "             )\n",
    "    \n",
    "    assert (isinstance(ws_exc, float) | isinstance(ws_exc, int)), \\\n",
    "        \"ws_exc must have data type float or int\"\n",
    "    \n",
    "    eroe = lambda c, k: np.exp(-(ws_exc / c)**k)\n",
    "    da_eroe = xr.apply_ufunc(eroe, da_c, da_k, dask = \"allowed\")\n",
    "    \n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(\"Obtained: {} m/s expected rate of exceedance from {} and {}.\"\n",
    "              .format(ws_exc, da_c.name, da_k.name)\n",
    "             )\n",
    "    else:\n",
    "        print(\"Obtained: {} m/s expected rate of exceedance from {} and {} for use in {}.\"\n",
    "              .format(ws_exc, da_c.name, da_k.name, func_1up)\n",
    "             )\n",
    "    \n",
    "    return da_eroe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08d0aff-6a42-4101-8ff3-1bab65c0e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcf(da_ws, speeds, powers, power_max):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the gross capacity factor for a typical wind turbine.\n",
    "    \n",
    "    Arguments:\n",
    "        da_ws (xarray.DataArray): Wind speed data over a period.\n",
    "        speeds (numpy.ndarray): Speed bins for the turbine's power curve.\n",
    "        powers (numpy.ndarray): Powers for each speed bin according to manufacturer\n",
    "            power curve data.\n",
    "        power_max (float or int): The maximum power which the turbine can produce.\n",
    "        \n",
    "    Returns:\n",
    "        da_gcf (xarray.DataArray): Gross capacity factor over the period.\n",
    "        \n",
    "    First uses the speeds and powers arguments to produce an interpolation\n",
    "    function for the power curve. Then this interpolation function is applied\n",
    "    to obtain the power at each wind speed data point in da_ws. Finally, this\n",
    "    is divided over the maximum power and averaged over the period to obtain\n",
    "    the gross capacity factor.\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(\"Executing: {} to obtain {} gross capacity factor.\"\n",
    "              .format(func_cur, da_ws.name)\n",
    "             )\n",
    "    else:\n",
    "        print(\"Executing: {} to obtain {} gross capacity factor for use in {}.\"\n",
    "              .format(func_cur, da_ws.name, func_1up)\n",
    "             )\n",
    "    \n",
    "    assert speeds.ndim == 1, \\\n",
    "        \"speeds must be a 1D numpy array with data type 'float64' or 'int64'\"\n",
    "    assert (speeds.dtype == \"float64\") | (speeds.dtype == \"int64\"), \\\n",
    "        \"speeds must be a 1D numpy array with data type 'float64' or 'int64'\"\n",
    "    assert powers.ndim == 1, \\\n",
    "        \"powers must be a 1D numpy array with data type 'float64' or 'int64'\"\n",
    "    assert (powers.dtype == \"float64\") | (powers.dtype == \"int64\"), \\\n",
    "        \"powers must be a 1D numpy array with data type 'float64' or 'int64'\"\n",
    "    assert isinstance(power_max, float) | isinstance(power_max, int), \\\n",
    "        \"power_max must have data type 'float' or 'int'\"\n",
    "    \n",
    "    power_curve = interp1d(speeds, powers, kind = \"nearest\")\n",
    "    gcf_instant = lambda ws: power_curve(ws) / power_max\n",
    "    da_gcf = (xr.apply_ufunc(gcf_instant, da_ws, dask = \"allowed\")\n",
    "              .mean(\"time\")\n",
    "             )\n",
    "    \n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(\"Obtained: {} gross capacity factor.\".format(da_ws.name))\n",
    "    else:\n",
    "        print(\"Obtained: {} gross capacity factor for use in {}.\"\n",
    "              .format(da_ws.name, func_1up)\n",
    "             )              \n",
    "    \n",
    "    return da_gcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d6c00ab-feb2-4125-89ff-a3084aab1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_for_calc_diff(calc_func, region, period1_start, period1_end, period2_start,\n",
    "                            period2_end, subset, var_or_dvar=None, hour=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain output path for calc_diff function, as well as paths for the calc_func\n",
    "    outputs from each given period.\n",
    "    \n",
    "    Arguments:\n",
    "        calc_func (function): Calculation function to compute difference in\n",
    "            results from. Must be one of: [\"calc_glass_mean_climatology\",\n",
    "            \"calc_era5_mdp_climatology_given_var_or_dvar\",\n",
    "            \"calc_era5_mdp_climatology_stats_given_var_or_dvar\",\n",
    "            \"calc_era5_mdp_climatology_values_given_var_or_dvar_and_hour\",\n",
    "            \"calc_era5_wsd_climatology\"].\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of: [\"ca\", \"sa\", \"wa\"].\n",
    "        period1_start (datetime.datetime): Start of first period to perform\n",
    "            calculation over. Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "            Note that this is a datetime.dateime object as opposed to str.\n",
    "        period1_end (datetime.datetime): End of first period to perform\n",
    "            calculation over. Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "            Note that this is a datetime.dateime object as opposed to str.\n",
    "        period2_start (datetime.datetime): Start of second period to perform\n",
    "            calculation over. Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "            Note that this is a datetime.dateime object as opposed to str.\n",
    "        period2_end (datetime.datetime): End of second period to perform\n",
    "            calculation over. Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "            Note that this is a datetime.dateime object as opposed to str.\n",
    "        subset (str): Subset of period to perform calculation over.\n",
    "            Must be one of: [\"all\", \"DJF\", \"MAM\", \"JJA\", \"SON\",\n",
    "            \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "            \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"].\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['wv10', 'wv100', 'mslp', 't2',\n",
    "            'slhf', 'sshf', 'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac',\n",
    "            'dwv10', 'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dviec',\n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac'].\n",
    "        hour (int): Hour of mean diurnal profile to compute value for.\n",
    "            Must be one of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "            13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23].\n",
    "            \n",
    "    Returns:\n",
    "        path_output (str): Output path for results from calc_diff.\n",
    "        path_period1 (str): Output path for results from calc_func applied\n",
    "            over the first period.\n",
    "        path_period2 (str): Output path for results from calc_func applied\n",
    "            over the second period.\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(f\"Executing: {func_cur} to obtain calc_diff output path and \" +\n",
    "              \"intermediate output paths from {}\".format(calc_func.__name__))\n",
    "    else:\n",
    "        print(f\"Executing: {func_cur} to obtain calc_diff output path and \" +\n",
    "              \"intermediate output paths from {} for use in {}.\"\n",
    "              .format(calc_func.__name__, func_1up))\n",
    "    \n",
    "    # Assert that there are no errors in input arguments\n",
    "    check_args(calc_func=calc_func, region=region, period_start=period1_start,\n",
    "               period_end=period1_end, subset=subset, var_or_dvar=var_or_dvar,\n",
    "               hour=hour)\n",
    "    check_args(period_start=period2_start, period_end=period2_end, subset=subset)\n",
    "    \n",
    "    # Define path stems\n",
    "    path_output = (\"../data_processed/{}_diff_{}_{}_{}_{}_{}_{}_\"\n",
    "                   .format(calc_funcs_ver, region, period1_start.strftime(\"%b-%Y\"),\n",
    "                           period1_end.strftime(\"%b-%Y\"), period2_start.strftime(\"%b-%Y\"),\n",
    "                           period2_end.strftime(\"%b-%Y\"), subset)\n",
    "                  )\n",
    "    path_period1 = (\"../data_processed/{}_{}_{}_{}_{}_\"\n",
    "                    .format(calc_funcs_ver, region, period1_start.strftime(\"%b-%Y\"),\n",
    "                            period1_end.strftime(\"%b-%Y\"), subset)\n",
    "                   )\n",
    "    path_period2 = (\"../data_processed/{}_{}_{}_{}_{}_\"\n",
    "                    .format(calc_funcs_ver, region, period2_start.strftime(\"%b-%Y\"),\n",
    "                            period2_end.strftime(\"%b-%Y\"), subset)\n",
    "                   )\n",
    "    # Define path endings (exception for calc_glass_mean_climatology)\n",
    "    if calc_func.__name__ == \"calc_glass_mean_climatology\":\n",
    "        glass_data_source_period1 = glass_data_source_to_use(period1_start, period1_end)\n",
    "        glass_data_source_period2 = glass_data_source_to_use(period2_start, period2_end)\n",
    "        if glass_data_source_period1 == glass_data_source_period2:\n",
    "            glass_data_source = glass_data_source_period1\n",
    "        else:\n",
    "            glass_data_source = \"mixed\"\n",
    "        path_output += f\"glass-mean_{glass_data_source}.nc\"\n",
    "        path_period1 += f\"glass-mean_{glass_data_source_period1}.nc\"\n",
    "        path_period2 += f\"glass-mean_{glass_data_source_period2}.nc\"\n",
    "        return path_output, path_period1, path_period2        \n",
    "    if calc_func.__name__ == \"calc_era5_mdp_climatology_given_var_or_dvar\":\n",
    "        path_ending = f\"era5-mdp_{var_or_dvar}.nc\"\n",
    "    if calc_func.__name__ == \"calc_era5_mdp_climatology_stats_given_var_or_dvar\":\n",
    "        path_ending = f\"era5-mdp_{var_or_dvar}_stats.nc\"        \n",
    "    if calc_func.__name__ == \"calc_era5_mdp_climatology_values_given_var_or_dvar_and_hour\":\n",
    "        path_ending = f\"era5-mdp_{var_or_dvar}_{hour}.nc\"        \n",
    "    if calc_func.__name__ == \"calc_era5_wsd_climatology\":\n",
    "        path_ending = \"era5-wsd.nc\"\n",
    "    \n",
    "    # Append path endings to stems to obtain the full paths\n",
    "    path_period1 += path_ending\n",
    "    path_period2 += path_ending\n",
    "    path_output += path_ending\n",
    "    \n",
    "    if func_1up == \"<cell line: 1>\":\n",
    "        print(\"Obtained: calc_diff output path and \" +\n",
    "              \"intermediate output paths from {}\".format(calc_func.__name__))\n",
    "    else:\n",
    "        print(\"Obtained: calc_diff output path and \" +\n",
    "              \"intermediate output paths from {} for use in {}.\"\n",
    "              .format(calc_func.__name__, func_1up))\n",
    "    \n",
    "    return path_output, path_period1, path_period2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37fd4993-a955-49fb-8d2c-7bea7b959fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Low-level calc functions\n",
    "\n",
    "def calc_glass_mean_climatology(region, period_start, period_end, subset,\n",
    "                                var_or_dvar=None, hour=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate mean leaf area index (MLAI) and mean fraction of absorbed\n",
    "    photosynthetically active radiation (MFAPAR) climatology using GLASS data.\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        subset (str): Subset of period to perform calculation over.\n",
    "            Must be one of [\"all\", \"DJF\", \"MAM\", \"JJA\", \"SON\",\n",
    "            \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "            \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"].\n",
    "        var_or_dvar (None): This argument is not used for this analysis. It is used \n",
    "            for applying the calc_diff function over an arbitrary calc_func.\n",
    "        hour (None): This argument is not used for this analysis. It is used \n",
    "            for applying the calc_diff function over an arbitrary calc_func.\n",
    "                        \n",
    "    Returns:\n",
    "        {calc_funcs_ver}_{region}_{period_start}_{period_end}_{subset}_\n",
    "        glass-mean_{glass_data_source}.nc:\n",
    "            Output netcdf4 file in data_processed folder containing both MLAI and\n",
    "            MFAPAR. {calc_funcs_ver} is the version of the calc_funcs script being\n",
    "            used and {glass_data_source} is automatically selected between\n",
    "            [\"avhrr\", \"modis\"] based on the selected period.\n",
    "    \n",
    "    For each grid cell, calculate the mean glass climatology (MLAI and MFAPAR). These\n",
    "    values are computed over the period from period_start to period_end (inclusive),\n",
    "    and only using a subset of data within this period (if a season or month is \n",
    "    specified). The calculation uses 8-day satellite HDF data from the data_raw\n",
    "    folder as input, then outputs the result as a netcdf4 file into the\n",
    "    data_processed folder. MODIS data is preferentially used where the given period\n",
    "    is completely contained within the time range of MODIS data (on and after \n",
    "    Mar-2000). Otherwise, AVHRR data is used.\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<module>\":\n",
    "        print(f\"Executing: {func_cur} to obtain {subset} climatology of MLAI \" +\n",
    "              f\"and MFAPAR between {period_start} and {period_end}.\")\n",
    "    else:\n",
    "        print(f\"Executing: {func_cur} to obtain {subset} climatology of MLAI \" +\n",
    "              f\"and MFAPAR between {period_start} and {period_end} \" +\n",
    "              f\"for use in {func_1up}.\")\n",
    "    \n",
    "    # Assert that there are no errors in input arguments, select the\n",
    "    # appropriate data source (AVHRR or MODIS) to use depending on period,\n",
    "    # then define the output path.\n",
    "    period_start = datetime.strptime(period_start, \"%b-%Y\")\n",
    "    period_end = datetime.strptime(period_end, \"%b-%Y\")\n",
    "    check_args(region=region, period_start=period_start, period_end=period_end,\n",
    "               subset=subset)\n",
    "    glass_data_source = glass_data_source_to_use(period_start, period_end)\n",
    "    path_output = (\"../data_processed/{}_{}_{}_{}_{}_glass-mean_{}.nc\"\n",
    "                   .format(calc_funcs_ver, region, period_start.strftime(\"%b-%Y\"),\n",
    "                           period_end.strftime(\"%b-%Y\"), subset, glass_data_source)\n",
    "                  )\n",
    "    if Path(path_output).exists():\n",
    "        print(\"TERMINATED: \" + inspect.stack()[0][3] +\n",
    "              \" because file already exists \" + path_output)\n",
    "        return None\n",
    "\n",
    "    # The two functions below are used with xarray's open_mfdataset for parallel\n",
    "    # computing using dask. The region and times (period and subset) are\n",
    "    # selected within separate functions and uses different logic as compared with\n",
    "    # filtering in the ERA5 datasets. This is because each GLASS file contains\n",
    "    # global data whereas the ERA5 datasets were downloaded for each local region.\n",
    "    \n",
    "    def filter_glass_files(file):\n",
    "        # This function is used as a mask in conjunction with the default python\n",
    "        # filter function later, in order to select out the raw data files within\n",
    "        # the input period and climatological subset within the original function \n",
    "        # arguments (by using dates contained within each file name). This is done \n",
    "        # (as opposed to using open_mfdataset then filtering) for scalability reasons \n",
    "        # since we may need to persist the data in RAM to speed up certain computations.\n",
    "        time = file[-12:-4]\n",
    "        time = datetime.strptime(time, \"%Y-%j\")\n",
    "        if ((time.month in subsets[subset]) &\n",
    "            # We add an extra month to period_end here because period_end was\n",
    "            # specified as a month, and conversion into a datetime object\n",
    "            # defaults to the first (rather than last) day of that month\n",
    "            (period_start <= time < period_end + relativedelta(months=1))\n",
    "           ):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def preprocess_glass(ds):\n",
    "        # This function is used for the preprocess argument in open_mfdataset.\n",
    "        # It uses the dates in each raw data file name to assign a time dimension\n",
    "        # and coordinate for the corresponding dataset. This then forms the\n",
    "        # dimension along which the files are combined into a single dataset\n",
    "        # and rechunked. This function also selects out the input region within\n",
    "        # the original function arguments before the files are concatenated using\n",
    "        # open_mfdataset (this is again done for persist scalability).\n",
    "        time = ds.encoding[\"source\"][-12:-4]\n",
    "        time = datetime.strptime(time, \"%Y-%j\")\n",
    "        ds = (ds\n",
    "              .expand_dims({\"time\": [time]})\n",
    "              # Redundant measure just in case longitudes exceed 180 degrees\n",
    "              .assign_coords({\"x\": (ds.x + 180) % 360 - 180})\n",
    "              .sortby(\"x\")\n",
    "              .rename({\"x\": \"longitude\", \"y\": \"latitude\"})\n",
    "              .drop_vars(\"spatial_ref\")\n",
    "              .squeeze(\"band\", drop=True)\n",
    "              )\n",
    "        ds = ds.sel(longitude=slice(regions[region][\"extent\"][0],\n",
    "                                    regions[region][\"extent\"][1]),\n",
    "                    latitude=slice(regions[region][\"extent\"][3],\n",
    "                                   regions[region][\"extent\"][2])\n",
    "                   )\n",
    "        return ds\n",
    "    \n",
    "    # The following code creates the mean climatology datasets for each GLASS\n",
    "    # variable, by using the previous functions along with open_mfdataset.\n",
    "    # An initally empty dataset is iteratively appended then merged so that\n",
    "    # future scalability is possible in case one wishes to add more GLASS\n",
    "    # variables to the vars_glass global python variable.\n",
    "    datasets = []    \n",
    "    for var in vars_glass:\n",
    "        files_glass_all = glob(f\"../data_raw/global_glass-{var}-{glass_data_source}\" +\n",
    "                               f\"_8-day/global_glass-{var}-{glass_data_source}*\")\n",
    "        if len(files_glass_all) != number_of_glass_files[var][glass_data_source]:\n",
    "            print(f\"WARNING: Expected {number_of_glass_files[var][glass_data_source]}\" +\n",
    "                  f\" files in ../data_raw/global_glass-{var}-{glass_data_source}\" +\n",
    "                  f\"_8-day/ but got {len(files_glass_all)}. This could be because the\" +\n",
    "                  \" data_download.ipynb notebook was not run properly. Or it could be\" +\n",
    "                  \" that the number of GLASS files on the server from which the data \" +\n",
    "                  \"was downloaded has changed. Or it may be that the user has changed\" +\n",
    "                  \" the period coverage from the original values in the data_download\" +\n",
    "                  \".ipynb notebook. Alternatively, the user may have changed some \" +\n",
    "                  \"files in this folder.\")\n",
    "        files_glass_filtered = list(filter(filter_glass_files, files_glass_all))\n",
    "        files_glass_filtered.sort()\n",
    "        # The if statement is to ensure an array full of NaNs is returned for MFAPAR\n",
    "        # when the input period includes 1981 or 2021. At the time of writing, GLASS\n",
    "        # FAPAR data is not available for these years.\n",
    "        if (var == \"fapar\") & (\n",
    "            (period_start < datetime.strptime(fapar_earliest, \"%b-%Y\")) |\n",
    "            (period_end > datetime.strptime(fapar_latest, \"%b-%Y\"))\n",
    "        ):\n",
    "            # This line exploits the fact that the for loop runs in sequence and \n",
    "            # will have computed MLAI before it attempts to compute MFAPAR. \n",
    "            # Therefore an MLAI array with appropriate coordinates already exists \n",
    "            # in the datasets list and can be used to create an array of NaNs.\n",
    "            ds_mean = (datasets[0]\n",
    "                       .where(np.isnan(datasets[0][\"mlai\"]))\n",
    "                       .rename({\"mlai\": \"mfapar\"})\n",
    "                      )\n",
    "            print(\"WARNING: GLASS FAPAR data is not available for the years \" +\n",
    "                  f\"{fapar_earliest[-4:]} and {fapar_latest[-4:]}. \" +\n",
    "                  \"A data array with NaNs was returned for MFAPAR instead.\")\n",
    "        else:\n",
    "            ds_mean = (xr.open_mfdataset(files_glass_filtered, engine = \"rasterio\",\n",
    "                                         preprocess=preprocess_glass, parallel = True)\n",
    "                       # Rechunking after open_mfdataset here is actually bad practice\n",
    "                       # since it requires extra computation, but the chunks argument\n",
    "                       # for open_mfdataset doesn't seem to work here for some reason.\n",
    "                       .chunk(chunks = {\"time\": chunksize})\n",
    "                       .persist()\n",
    "                       .mean(\"time\")\n",
    "                       .rename({\"band_data\": \"m\" + var})\n",
    "                      )\n",
    "        datasets.append(ds_mean)\n",
    "    ds_glass_mean = xr.merge(datasets)\n",
    "    \n",
    "    # Create output file in data_processed folder\n",
    "    ds_glass_mean.to_netcdf(path_output)\n",
    "    \n",
    "    if func_1up == \"<module>\":\n",
    "        print(f\"CREATED: file {path_output}.\")\n",
    "    else:\n",
    "        print(f\"CREATED: file for use in {func_1up} {path_output}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f5b0e6d-017b-409e-ab79-4c243781629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: calc_glass_mean_climatology to obtain JJA climatology of MLAI and MFAPAR between Jun-2001 and Aug-2003.\n",
      "Executing: check_args to check whether input arguments into calc_glass_mean_climatology are valid.\n",
      "Passed: validity check for input arguments into calc_glass_mean_climatology.\n",
      "Executing: glass_data_source_to_use to select the appropriate glass data source for use between Jun-2001 and Aug-2003 in calc_glass_mean_climatology.\n",
      "Executing: check_args to check whether input arguments into glass_data_source_to_use are valid.\n",
      "Passed: validity check for input arguments into glass_data_source_to_use.\n",
      "Selected: modis glass data source for use between Jun-2001 and Aug-2003 in calc_glass_mean_climatology.\n",
      "TERMINATED: calc_glass_mean_climatology because file already exists ../data_processed/v00_wa_Jun-2001_Aug-2003_JJA_glass-mean_modis.nc\n",
      "CPU times: user 160 ms, sys: 7.81 ms, total: 168 ms\n",
      "Wall time: 167 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "calc_glass_mean_climatology(\"wa\", \"Jun-2001\", \"Aug-2003\", \"JJA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be56ea3-f0ec-4abf-914b-81440dbb2825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_era5_mdp_climatology_given_var_or_dvar(region, period_start, period_end,\n",
    "                                                subset, var_or_dvar, hour=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the mean diurnal profile (MDP) climatology for a particular\n",
    "    variable or change in variable (compared to previous hour) using ERA5 data.\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        subset (str): Subset of period to perform calculation over.\n",
    "            Must be one of [\"all\", \"DJF\", \"MAM\", \"JJA\", \"SON\",\n",
    "            \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "            \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"].\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['wv10', 'wv100', 'mslp', 't2',\n",
    "            'slhf', 'sshf', 'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac',\n",
    "            'dwv10', 'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dviec',\n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac'].\n",
    "        hour (None): This argument is not used for this analysis. It is used \n",
    "            for applying the calc_diff function over an arbitrary calc_func.\n",
    "                        \n",
    "    Returns:\n",
    "        {calc_funcs_ver}_{region}_{period_start}_{period_end}_{subset}_\n",
    "        era5-mdp_{var_or_dvar}.nc:\n",
    "            Output netcdf4 file in data_processed folder containing the MDP for\n",
    "            var_or_dvar. {calc_funcs_ver} is the version of the calc_funcs script\n",
    "            being used.\n",
    "    \n",
    "    For each grid cell, calculate the MDP for the selected var_or_dvar. The MDP\n",
    "    values are computed over the period from period_start to period_end (inclusive),\n",
    "    and only using a subset of data within this period (if a season or month is \n",
    "    specified). The calculation uses monthyl averaged reanalysis by hour of day data\n",
    "    from the data_raw folder as input, then outputs the result as a netcdf4 file\n",
    "    into the data_processed folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<module>\":\n",
    "        print(f\"Executing: {func_cur} to obtain {subset} climatology of \" +\n",
    "              f\"{var_or_dvar} MDP between {period_start} and {period_end}.\")\n",
    "    else:\n",
    "        print(f\"Executing: {func_cur} to obtain {subset} climatology of \" +\n",
    "              f\"{var_or_dvar} MDP between {period_start} and {period_end} \" +\n",
    "              f\"for use in {func_1up}.\")\n",
    "    \n",
    "    # Assert that there are no errors in input arguments then define output path.\n",
    "    period_start = datetime.strptime(period_start, \"%b-%Y\")\n",
    "    period_end = datetime.strptime(period_end, \"%b-%Y\")\n",
    "    check_args(region=region, period_start=period_start, period_end=period_end,\n",
    "               subset=subset, var_or_dvar=var_or_dvar)\n",
    "    path_output = (\"../data_processed/{}_{}_{}_{}_{}_era5-mdp_{}.nc\"\n",
    "                   .format(calc_funcs_ver, region, period_start.strftime(\"%b-%Y\"),\n",
    "                           period_end.strftime(\"%b-%Y\"), subset, var_or_dvar)\n",
    "                  )\n",
    "    if Path(path_output).exists():\n",
    "        print(\"TERMINATED: \" + inspect.stack()[0][3] +\n",
    "              \" because file already exists \" + path_output)\n",
    "        return None\n",
    "    \n",
    "    # The two functions below are used with xarray's open_mfdataset for parallel\n",
    "    # computing using dask. Together they select out the relevant files to read\n",
    "    # and persist in memory only the data which is necessary for the computation.\n",
    "    \n",
    "    def filter_era5_month_hour_files(file):\n",
    "        # This function is used as a mask in conjunction with the default python\n",
    "        # filter function later, in order to select out the raw data files with\n",
    "        # years within the input period. The following preprocess function also\n",
    "        # selects out the relevant years (as well as months) but by applying a\n",
    "        # filter on the list of file names first we can avoid preprocessing a \n",
    "        # lot of files and hence save on memory.\n",
    "        year = int(file[-7:-3])\n",
    "        if period_start.year <= year <= period_end.year:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def preprocess_era5_month_hour(ds):\n",
    "        # This function is used for the preprocess argument in open_mfdataset.\n",
    "        # It selects out only the subset months for persist scalability.\n",
    "        ds = (regrid_era5(ds)\n",
    "              .sel(time = ds.time.dt.month.isin(subsets[subset]))\n",
    "             )\n",
    "        return ds\n",
    "    \n",
    "    # The following code opens the relevant hourly ERA5 files then uses the\n",
    "    # u and v components of wind velocity to compute the magnitude (wind speed)\n",
    "    files_era5_month_hour = glob(\n",
    "        f\"../data_raw/{region}_era5-slv-surface_month-hour/*.nc\")\n",
    "    files_era5_month_hour.sort()\n",
    "    if len(files_era5_month_hour) != number_of_era5_month_hour_files:\n",
    "        print(f\"WARNING: Expected {number_of_era5_month_hour_files} files in \" +\n",
    "              f\"../data_raw/{region}_era5-slv-surface_month-hour/ but got \" +\n",
    "              f\"{len(files_era5_month_hour)}. This could be because the \" + \n",
    "              \"data_download.ipynb notebook was not run properly. Or it could be \" +\n",
    "              \"that the user has selected a different number of years to retrieve \" +\n",
    "              \"data for in the data_download.ipynb notebook as compared with the \" +\n",
    "              \"original analysis. Or it may be that the user has changed some files \" +\n",
    "              \"in this folder.\")\n",
    "    files_era5_month_hour_filtered = list(filter(filter_era5_month_hour_files, \n",
    "                                                 files_era5_month_hour))\n",
    "    files_era5_month_hour_filtered.sort()\n",
    "    ds_era5_month_hour = (xr.open_mfdataset(files_era5_month_hour_filtered,\n",
    "                                            preprocess=preprocess_era5_month_hour,\n",
    "                                            engine = \"netcdf4\", parallel = True)\n",
    "                    # We add an extra month to period_end here because period_end was\n",
    "                    # specified as a month, and conversion into a datetime object\n",
    "                    # defaults to the first (rather than last) day of that month. The\n",
    "                    # -1 hr is to avoid selecting first hour of the following month.\n",
    "                    .sel(time = slice(period_start, period_end +\n",
    "                                relativedelta(months=1, hours = -1)))\n",
    "                    # Rechunking after open_mfdataset here is actually bad practice\n",
    "                    # since it requires extra computation, but the chunks argument\n",
    "                    # for open_mfdataset doesn't seem to work here for some reason.\n",
    "                    .chunk(chunks = {\"time\": chunksize})\n",
    "                    .persist()\n",
    "                   )\n",
    "    \n",
    "    # add hour dimension to above before persist\n",
    "    # find monthly averaged by hour of day values for default variables\n",
    "    # then depending on var_or_dvar, do manipulations accordingly\n",
    "    # create dictionary where key is \"wv10\" but value is list [\"u10\", \"v10\"]?\n",
    "    \n",
    "    da_ws10 = magnitude(ds_era5_hour[\"u10\"], ds_era5_hour[\"v10\"])\n",
    "    da_ws100 = magnitude(ds_era5_hour[\"u100\"], ds_era5_hour[\"v100\"])\n",
    "    da_ws10.name, da_ws100.name = \"ws10\", \"ws100\"\n",
    "    \n",
    "    # Compute the mean and standard deviation of wind speed, from these the \n",
    "    # Weibull scale and shape parameters, then the expected rate of exceedance\n",
    "    # and typical gross capacity factor, then combine into a single dataset.\n",
    "    da_ws10_mean = xr.DataArray(da_ws10.mean(\"time\"), name = \"ws10_mean\")\n",
    "    da_ws10_std = xr.DataArray(da_ws10.std(\"time\"), name = \"ws10_std\")\n",
    "    da_ws10_c, da_ws10_k = weibull_params(da_ws10_mean, da_ws10_std)\n",
    "    da_ws10_c.name, da_ws10_k.name = \"c10\", \"k10\"\n",
    "    da_ws100_mean = xr.DataArray(da_ws100.mean(\"time\"), name = \"ws100_mean\")\n",
    "    da_ws100_std = xr.DataArray(da_ws100.std(\"time\"), name = \"ws100_std\")\n",
    "    da_ws100_c, da_ws100_k = weibull_params(da_ws100_mean, da_ws100_std)\n",
    "    da_ws100_c.name, da_ws100_k.name = \"c100\", \"k100\"\n",
    "    da_ws100_eroe = weibull_eroe(da_ws100_c, da_ws100_k, speed_eroe)\n",
    "    da_ws100_gcf = gcf(da_ws100, speeds_common, powers_avg, power_nameplate)\n",
    "    da_ws100_eroe.name, da_ws100_gcf.name = \"eroe100\", \"gcf100\"\n",
    "    ds_era5_wsd = xr.merge([da_ws10_mean, da_ws10_std, da_ws10_c, da_ws10_k,\n",
    "                            da_ws100_mean, da_ws100_std, da_ws100_c,\n",
    "                            da_ws100_k, da_ws100_eroe, da_ws100_gcf])\n",
    "    \n",
    "    # Create output file in data_processed folder\n",
    "    ds_era5_wsd.to_netcdf(path_output)\n",
    "\n",
    "    if func_1up == \"<module>\":\n",
    "        print(f\"CREATED: file {path_output}.\")\n",
    "    else:\n",
    "        print(f\"CREATED: file for use in {func_1up} {path_output}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77b866-4711-4d7c-8354-9c63932bfc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calc_era5_mdp_climatology_given_var_or_dvar(\"wa\", \"Dec-1984\", \"Feb-1990\", \"DJF\", \"slhf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7ef3914-93ba-44d9-a571-c38f9b4a3b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (longitude: 41, latitude: 21, time: 372)\n",
       "Coordinates:\n",
       "  * longitude  (longitude) float32 113.0 113.2 113.5 113.8 ... 122.5 122.8 123.0\n",
       "  * latitude   (latitude) float32 -30.0 -30.25 -30.5 ... -34.5 -34.75 -35.0\n",
       "  * time       (time) datetime64[ns] 2021-01-01 ... 2021-12-01T23:00:00\n",
       "Data variables:\n",
       "    u100       (time, latitude, longitude) float32 ...\n",
       "    v100       (time, latitude, longitude) float32 ...\n",
       "    u10        (time, latitude, longitude) float32 ...\n",
       "    v10        (time, latitude, longitude) float32 ...\n",
       "    t2m        (time, latitude, longitude) float32 ...\n",
       "    msl        (time, latitude, longitude) float32 ...\n",
       "    slhf       (time, latitude, longitude) float32 ...\n",
       "    sshf       (time, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    Conventions:  CF-1.6\n",
       "    history:      2022-08-27 14:49:21 GMT by grib_to_netcdf-2.25.1: /opt/ecmw...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-b2fc62c3-1c8b-48c1-a01f-fdb94193a003' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-b2fc62c3-1c8b-48c1-a01f-fdb94193a003' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>longitude</span>: 41</li><li><span class='xr-has-index'>latitude</span>: 21</li><li><span class='xr-has-index'>time</span>: 372</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-dbaa90ed-ff0f-4431-873d-34aee3877b35' class='xr-section-summary-in' type='checkbox'  checked><label for='section-dbaa90ed-ff0f-4431-873d-34aee3877b35' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>113.0 113.2 113.5 ... 122.8 123.0</div><input id='attrs-e11a26dc-a1f2-4e83-809e-b4a6a23c8ce0' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e11a26dc-a1f2-4e83-809e-b4a6a23c8ce0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-aa234eec-b9e2-4460-ad5d-39e824537dc8' class='xr-var-data-in' type='checkbox'><label for='data-aa234eec-b9e2-4460-ad5d-39e824537dc8' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>long_name :</span></dt><dd>longitude</dd></dl></div><div class='xr-var-data'><pre>array([113.  , 113.25, 113.5 , 113.75, 114.  , 114.25, 114.5 , 114.75, 115.  ,\n",
       "       115.25, 115.5 , 115.75, 116.  , 116.25, 116.5 , 116.75, 117.  , 117.25,\n",
       "       117.5 , 117.75, 118.  , 118.25, 118.5 , 118.75, 119.  , 119.25, 119.5 ,\n",
       "       119.75, 120.  , 120.25, 120.5 , 120.75, 121.  , 121.25, 121.5 , 121.75,\n",
       "       122.  , 122.25, 122.5 , 122.75, 123.  ], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>-30.0 -30.25 -30.5 ... -34.75 -35.0</div><input id='attrs-6acec39a-01c4-4cf0-ba4f-d0e09961908e' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-6acec39a-01c4-4cf0-ba4f-d0e09961908e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1e56ee4b-6e66-4fed-894a-4578c734e99c' class='xr-var-data-in' type='checkbox'><label for='data-1e56ee4b-6e66-4fed-894a-4578c734e99c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>long_name :</span></dt><dd>latitude</dd></dl></div><div class='xr-var-data'><pre>array([-30.  , -30.25, -30.5 , -30.75, -31.  , -31.25, -31.5 , -31.75, -32.  ,\n",
       "       -32.25, -32.5 , -32.75, -33.  , -33.25, -33.5 , -33.75, -34.  , -34.25,\n",
       "       -34.5 , -34.75, -35.  ], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2021-01-01 ... 2021-12-01T23:00:00</div><input id='attrs-a9a800ba-9e0e-47fd-99b8-ea23164d306c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a9a800ba-9e0e-47fd-99b8-ea23164d306c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d7ee6622-9e40-4089-b1da-a49eda276033' class='xr-var-data-in' type='checkbox'><label for='data-d7ee6622-9e40-4089-b1da-a49eda276033' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>time</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;2021-01-01T00:00:00.000000000&#x27;, &#x27;2021-01-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-01-01T01:00:00.000000000&#x27;, ..., &#x27;2021-12-01T21:00:00.000000000&#x27;,\n",
       "       &#x27;2021-12-01T22:00:00.000000000&#x27;, &#x27;2021-12-01T23:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-9ad22c5b-cdac-4419-9ece-cf7394d6a15b' class='xr-section-summary-in' type='checkbox'  checked><label for='section-9ad22c5b-cdac-4419-9ece-cf7394d6a15b' class='xr-section-summary' >Data variables: <span>(8)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>u100</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-3578713f-90a3-4011-99a9-b4969d883622' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-3578713f-90a3-4011-99a9-b4969d883622' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f535b44e-e977-4a31-8dc2-ec6a8aea3c76' class='xr-var-data-in' type='checkbox'><label for='data-f535b44e-e977-4a31-8dc2-ec6a8aea3c76' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>m s**-1</dd><dt><span>long_name :</span></dt><dd>100 metre U wind component</dd></dl></div><div class='xr-var-data'><pre>[320292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>v100</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-ad65660e-5cfa-4455-946f-f2f532bef15a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-ad65660e-5cfa-4455-946f-f2f532bef15a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-07c87f1a-1953-4257-8ed7-0f96b722dedd' class='xr-var-data-in' type='checkbox'><label for='data-07c87f1a-1953-4257-8ed7-0f96b722dedd' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>m s**-1</dd><dt><span>long_name :</span></dt><dd>100 metre V wind component</dd></dl></div><div class='xr-var-data'><pre>[320292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>u10</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-2be04fd1-c032-40b5-9002-6c8cd9b9d915' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2be04fd1-c032-40b5-9002-6c8cd9b9d915' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d00ae560-69ed-49c5-b2a3-ab5966c66040' class='xr-var-data-in' type='checkbox'><label for='data-d00ae560-69ed-49c5-b2a3-ab5966c66040' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>m s**-1</dd><dt><span>long_name :</span></dt><dd>10 metre U wind component</dd></dl></div><div class='xr-var-data'><pre>[320292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>v10</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-4a8c4ef4-2a7a-4a55-a1a4-76eb19a149b7' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-4a8c4ef4-2a7a-4a55-a1a4-76eb19a149b7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b41bbf58-74be-43b6-9890-3e11f0f7c042' class='xr-var-data-in' type='checkbox'><label for='data-b41bbf58-74be-43b6-9890-3e11f0f7c042' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>m s**-1</dd><dt><span>long_name :</span></dt><dd>10 metre V wind component</dd></dl></div><div class='xr-var-data'><pre>[320292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>t2m</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-4b87be8a-1607-4abf-bfcd-d41a3e5fadec' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-4b87be8a-1607-4abf-bfcd-d41a3e5fadec' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9feac5ce-51b4-426b-8a7a-3eb4a904959e' class='xr-var-data-in' type='checkbox'><label for='data-9feac5ce-51b4-426b-8a7a-3eb4a904959e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>K</dd><dt><span>long_name :</span></dt><dd>2 metre temperature</dd></dl></div><div class='xr-var-data'><pre>[320292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>msl</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-e66a3847-ccd3-4e16-b917-9605ba5904e1' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e66a3847-ccd3-4e16-b917-9605ba5904e1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d1a2f249-0aa9-43b3-810d-778c8401ea9a' class='xr-var-data-in' type='checkbox'><label for='data-d1a2f249-0aa9-43b3-810d-778c8401ea9a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>Pa</dd><dt><span>long_name :</span></dt><dd>Mean sea level pressure</dd><dt><span>standard_name :</span></dt><dd>air_pressure_at_mean_sea_level</dd></dl></div><div class='xr-var-data'><pre>[320292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>slhf</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-63d78b45-d721-45f9-8a43-0c6186e614f1' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-63d78b45-d721-45f9-8a43-0c6186e614f1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-cf6b2591-ca29-48e8-a2dc-f6c9e59d0494' class='xr-var-data-in' type='checkbox'><label for='data-cf6b2591-ca29-48e8-a2dc-f6c9e59d0494' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>J m**-2</dd><dt><span>long_name :</span></dt><dd>Surface latent heat flux</dd><dt><span>standard_name :</span></dt><dd>surface_upward_latent_heat_flux</dd></dl></div><div class='xr-var-data'><pre>[320292 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sshf</span></div><div class='xr-var-dims'>(time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-d13f3788-7c89-4288-b848-cee9c4698d53' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d13f3788-7c89-4288-b848-cee9c4698d53' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b9c6174c-d75b-4290-a9b1-4634e0ea04f4' class='xr-var-data-in' type='checkbox'><label for='data-b9c6174c-d75b-4290-a9b1-4634e0ea04f4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>J m**-2</dd><dt><span>long_name :</span></dt><dd>Surface sensible heat flux</dd><dt><span>standard_name :</span></dt><dd>surface_upward_sensible_heat_flux</dd></dl></div><div class='xr-var-data'><pre>[320292 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-a1db8a68-afb5-43d8-a0c0-0375555beee5' class='xr-section-summary-in' type='checkbox'  checked><label for='section-a1db8a68-afb5-43d8-a0c0-0375555beee5' class='xr-section-summary' >Attributes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Conventions :</span></dt><dd>CF-1.6</dd><dt><span>history :</span></dt><dd>2022-08-27 14:49:21 GMT by grib_to_netcdf-2.25.1: /opt/ecmwf/mars-client/bin/grib_to_netcdf.bin -S param -o /cache/data4/adaptor.mars.internal-1661611756.9321146-6648-17-ac5482d4-05bd-4f56-8660-768613b3c585.nc /cache/tmp/ac5482d4-05bd-4f56-8660-768613b3c585-adaptor.mars.internal-1661611668.2346027-6648-30-tmp.grib</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (longitude: 41, latitude: 21, time: 372)\n",
       "Coordinates:\n",
       "  * longitude  (longitude) float32 113.0 113.2 113.5 113.8 ... 122.5 122.8 123.0\n",
       "  * latitude   (latitude) float32 -30.0 -30.25 -30.5 ... -34.5 -34.75 -35.0\n",
       "  * time       (time) datetime64[ns] 2021-01-01 ... 2021-12-01T23:00:00\n",
       "Data variables:\n",
       "    u100       (time, latitude, longitude) float32 ...\n",
       "    v100       (time, latitude, longitude) float32 ...\n",
       "    u10        (time, latitude, longitude) float32 ...\n",
       "    v10        (time, latitude, longitude) float32 ...\n",
       "    t2m        (time, latitude, longitude) float32 ...\n",
       "    msl        (time, latitude, longitude) float32 ...\n",
       "    slhf       (time, latitude, longitude) float32 ...\n",
       "    sshf       (time, latitude, longitude) float32 ...\n",
       "Attributes:\n",
       "    Conventions:  CF-1.6\n",
       "    history:      2022-08-27 14:49:21 GMT by grib_to_netcdf-2.25.1: /opt/ecmw..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = xr.open_dataset(\"../data_raw/wa_era5-slv-surface_month-hour/wa_era5-slv-surface_month-hour_2021.nc\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b25519-dcbf-4cf6-b19c-533b09e5f4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e222467-9793-4c83-ad28-eb4bc7c38f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0256283-9eb5-4e34-8bb1-47b716255ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3627d35-4d26-46c5-9898-1175cc9019b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a304c-5e70-465c-8fa1-0a766ad45b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c84eca-d587-4827-9b7d-15a25e5f1399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_era5_wsd_climatology(region, period_start, period_end, subset,\n",
    "                                  var_or_dvar=None, hour=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate climatology of wind speed distribution (WSD) properties using \n",
    "    ERA5 data for heights of 10 m and 100 m above surface.\n",
    "    \n",
    "    Arguments:\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of [\"ca\", \"sa\", \"wa\"].\n",
    "        period_start (str): Start of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period_end (str): End of period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        subset (str): Subset of period to perform calculation over.\n",
    "            Must be one of [\"all\", \"DJF\", \"MAM\", \"JJA\", \"SON\",\n",
    "            \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "            \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"].\n",
    "        var_or_dvar (None): This argument is not used for this analysis. It is used \n",
    "            for applying the calc_diff function over an arbitrary calc_func.\n",
    "        hour (None): This argument is not used for this analysis. It is used \n",
    "            for applying the calc_diff function over an arbitrary calc_func.\n",
    "                        \n",
    "    Returns:\n",
    "        {calc_funcs_ver}_{region}_{period_start}_{period_end}_{subset}_era5-wsd.nc:\n",
    "            Output netcdf4 file in data_processed folder containing Weibull shape and\n",
    "            scale parameters for wind speed at 10 m and 100 m above surface, expected\n",
    "            rate of exceedance for a particular wind speed at 100 m above surface,\n",
    "            and gross capacity factor for a typical turbine at 100 m above surface.\n",
    "            {calc_funcs_ver} is the version of the calc_funcs script being used.\n",
    "    \n",
    "    For each grid cell, calculate the Weibull scale and shape parameter for wind speed\n",
    "    at 10 m above surface (c10 and k10), the Weibull scale and shape parameter for\n",
    "    wind speed at 100 m above surface (c100 and k100), the expected rate of exceedance\n",
    "    for a particular wind speed at 100 m above surface (EROE100) and the gross\n",
    "    capacity factor for a typical wind turbine at 100 m above surface (GCF100). The\n",
    "    wind speed distributions (WSDs) are computed over the period between period_start\n",
    "    and period_end (inclusive), and only using a subset of data within this period\n",
    "    (if a season or month is specified). The calculation uses hourly ERA5 netcdf4 data\n",
    "    from the data_raw folder as input, then outputs the result as a netcdf4 file into\n",
    "    the data_processed folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<module>\":\n",
    "        print(f\"Executing: {func_cur} to obtain wind speed distribution parameters \" +\n",
    "              f\"over {subset} between {period_start} and {period_end}.\")\n",
    "    else:\n",
    "        print(f\"Executing: {func_cur} to obtain wind speed distribution parameters \" +\n",
    "              f\"over {subset} between {period_start} and {period_end}.\" +\n",
    "              f\"for use in {func_1up}.\")\n",
    "    \n",
    "    # Assert that there are no errors in input arguments then define output path.\n",
    "    period_start = datetime.strptime(period_start, \"%b-%Y\")\n",
    "    period_end = datetime.strptime(period_end, \"%b-%Y\")\n",
    "    check_args(region=region, period_start=period_start, period_end=period_end,\n",
    "               subset=subset)\n",
    "    path_output = (\"../data_processed/{}_{}_{}_{}_{}_era5-wsd.nc\"\n",
    "                   .format(calc_funcs_ver, region, period_start.strftime(\"%b-%Y\"),\n",
    "                           period_end.strftime(\"%b-%Y\"), subset)\n",
    "                  )\n",
    "    if Path(path_output).exists():\n",
    "        print(\"TERMINATED: \" + inspect.stack()[0][3] +\n",
    "              \" because file already exists \" + path_output)\n",
    "        return None\n",
    "    if period_start + relativedelta(years=5) > period_end:\n",
    "        print(\"WARNING: It is recommended to use at least 5 years of data \" +\n",
    "              \"for the wind speed distribution analysis.\")\n",
    "    \n",
    "    # The two functions below are used with xarray's open_mfdataset for parallel\n",
    "    # computing using dask. Together they select out the relevant files to read\n",
    "    # and persist in memory only the data which is necessary for the computation.\n",
    "    \n",
    "    def filter_era5_hour_files(file):\n",
    "        # This function is used as a mask in conjunction with the default python\n",
    "        # filter function later, in order to select out the raw data files with\n",
    "        # years within the input period. The following preprocess function also\n",
    "        # selects out the relevant years (as well as months) but by applying a\n",
    "        # filter on the list of file names first we can avoid preprocessing a \n",
    "        # lot of files and hence save on memory.\n",
    "        year = int(file[-7:-3])\n",
    "        if period_start.year <= year <= period_end.year:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def preprocess_era5_hour(ds):\n",
    "        # This function is used for the preprocess argument in open_mfdataset.\n",
    "        # It selects out only the wind speed data, and only for\n",
    "        # the subset months. This is done for persist scalability.\n",
    "        ds = (regrid_era5(ds)\n",
    "              .sel(time = ds.time.dt.month.isin(subsets[subset]))\n",
    "              .drop([\"t2m\", \"msl\", \"slhf\", \"sshf\"])\n",
    "             )\n",
    "        return ds\n",
    "    \n",
    "    # The following code opens the relevant hourly ERA5 files then uses the\n",
    "    # u and v components of wind velocity to compute the magnitude (wind speed)\n",
    "    files_era5_hour = glob(f\"../data_raw/{region}_era5-slv-surface_hour/*.nc\")\n",
    "    files_era5_hour.sort()\n",
    "    if len(files_era5_hour) != number_of_era5_hour_files:\n",
    "        print(f\"WARNING: Expected {number_of_era5_hour_files} files in \" +\n",
    "              f\"../data_raw/{region}_era5-slv-surface_hour/ but got \" +\n",
    "              f\"{len(files_era5_hour)}. This could be because the \" + \n",
    "              \"data_download.ipynb notebook was not run properly. Or it could be \" +\n",
    "              \"that the user has selected a different number of years to retrieve \" +\n",
    "              \"data for in the data_download.ipynb notebook as compared with the \" +\n",
    "              \"original analysis. Or it may be that the user has changed some files \" +\n",
    "              \"in this folder.\")\n",
    "    files_era5_hour_filtered = list(filter(filter_era5_hour_files, files_era5_hour))\n",
    "    files_era5_hour_filtered.sort()\n",
    "    ds_era5_hour = (xr.open_mfdataset(files_era5_hour_filtered, engine = \"netcdf4\",\n",
    "                                     preprocess=preprocess_era5_hour, parallel = True)\n",
    "                    # We add an extra month to period_end here because period_end was\n",
    "                    # specified as a month, and conversion into a datetime object\n",
    "                    # defaults to the first (rather than last) day of that month. The\n",
    "                    # -1 hr is to avoid selecting first hour of the following month.\n",
    "                    .sel(time = slice(period_start, period_end +\n",
    "                                relativedelta(months=1, hours = -1)))\n",
    "                    # Rechunking after open_mfdataset here is actually bad practice\n",
    "                    # since it requires extra computation, but the chunks argument\n",
    "                    # for open_mfdataset doesn't seem to work here for some reason.\n",
    "                    .chunk(chunks = {\"time\": chunksize})\n",
    "                    .persist()\n",
    "                   )\n",
    "    da_ws10 = magnitude(ds_era5_hour[\"u10\"], ds_era5_hour[\"v10\"])\n",
    "    da_ws100 = magnitude(ds_era5_hour[\"u100\"], ds_era5_hour[\"v100\"])\n",
    "    da_ws10.name, da_ws100.name = \"ws10\", \"ws100\"\n",
    "    \n",
    "    # Compute the mean and standard deviation of wind speed, from these the \n",
    "    # Weibull scale and shape parameters, then the expected rate of exceedance\n",
    "    # and typical gross capacity factor, then combine into a single dataset.\n",
    "    da_ws10_mean = xr.DataArray(da_ws10.mean(\"time\"), name = \"ws10_mean\")\n",
    "    da_ws10_std = xr.DataArray(da_ws10.std(\"time\"), name = \"ws10_std\")\n",
    "    da_ws10_c, da_ws10_k = weibull_params(da_ws10_mean, da_ws10_std)\n",
    "    da_ws10_c.name, da_ws10_k.name = \"c10\", \"k10\"\n",
    "    da_ws100_mean = xr.DataArray(da_ws100.mean(\"time\"), name = \"ws100_mean\")\n",
    "    da_ws100_std = xr.DataArray(da_ws100.std(\"time\"), name = \"ws100_std\")\n",
    "    da_ws100_c, da_ws100_k = weibull_params(da_ws100_mean, da_ws100_std)\n",
    "    da_ws100_c.name, da_ws100_k.name = \"c100\", \"k100\"\n",
    "    da_ws100_eroe = weibull_eroe(da_ws100_c, da_ws100_k, speed_eroe)\n",
    "    da_ws100_gcf = gcf(da_ws100, speeds_common, powers_avg, power_nameplate)\n",
    "    da_ws100_eroe.name, da_ws100_gcf.name = \"eroe100\", \"gcf100\"\n",
    "    ds_era5_wsd = xr.merge([da_ws10_mean, da_ws10_std, da_ws10_c, da_ws10_k,\n",
    "                            da_ws100_mean, da_ws100_std, da_ws100_c,\n",
    "                            da_ws100_k, da_ws100_eroe, da_ws100_gcf])\n",
    "    \n",
    "    # Create output file in data_processed folder\n",
    "    ds_era5_wsd.to_netcdf(path_output)\n",
    "\n",
    "    if func_1up == \"<module>\":\n",
    "        print(f\"CREATED: file {path_output}.\")\n",
    "    else:\n",
    "        print(f\"CREATED: file for use in {func_1up} {path_output}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95f459ee-dc9a-487f-b64c-6d93f55d9253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: calc_era5_wsd_climatology to obtain wind speed distribution parameters over DJF between Dec-1984 and Feb-1990.\n",
      "Executing: check_args to check whether input arguments into calc_era5_wsd_climatology are valid.\n",
      "Passed: validity check for input arguments into calc_era5_wsd_climatology.\n",
      "TERMINATED: calc_era5_wsd_climatology because file already exists ../data_processed/v00_wa_Dec-1984_Feb-1990_DJF_era5-wsd.nc\n",
      "CPU times: user 54 ms, sys: 321 µs, total: 54.3 ms\n",
      "Wall time: 52.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "calc_era5_wsd_climatology(\"wa\", \"Dec-1984\", \"Feb-1990\", \"DJF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58cb1180-723c-4cac-a827-39f3e178eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diff(calc_func, region, period1_start, period1_end,\n",
    "              period2_start, period2_end, subset, var_or_dvar=None, hour=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the difference in results for two separate periods which have\n",
    "    each been outputted by the same calculation function.\n",
    "    \n",
    "    Arguments:\n",
    "        calc_func (function): Calculation function to compute difference in\n",
    "            results from. Must be one of: [\"calc_glass_mean_climatology\",\n",
    "            \"calc_era5_mdp_climatology_given_var_or_dvar\",\n",
    "            \"calc_era5_mdp_climatology_stats_given_var_or_dvar\",\n",
    "            \"calc_era5_mdp_climatology_values_given_var_or_dvar_and_hour\",\n",
    "            \"calc_era5_wsd_climatology\"].\n",
    "        region (str): Region to perform calculation over.\n",
    "            Must be one of: [\"ca\", \"sa\", \"wa\"].\n",
    "        period1_start (str): Start of first period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period1_end (str): End of first period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period2_start (str): Start of second period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        period2_end (str): End of second period to perform calculation over.\n",
    "            Must be of form \"%b-%Y\" eg. \"Jul-1990\".\n",
    "            Must be between \"Jan-1981\" and \"Dec-2021\".\n",
    "        subset (str): Subset of period to perform calculation over.\n",
    "            Must be one of: [\"all\", \"DJF\", \"MAM\", \"JJA\", \"SON\",\n",
    "            \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "            \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"].\n",
    "        var_or_dvar (str): Variable or value of change in variable to perform\n",
    "            calculation over. Must be one of: ['wv10', 'wv100', 'mslp', 't2',\n",
    "            'slhf', 'sshf', 'viec', 'vipile', 'vike', 'tcclw', 'tcwv', 'nac',\n",
    "            'dwv10', 'dwv100', 'dmslp', 'dt2', 'dslhf', 'dsshf', 'dviec',\n",
    "            'dvipile', 'dvike', 'dtcclw', 'dtcwv', 'dnac'].\n",
    "        hour (int): Hour of mean diurnal profile to compute value for.\n",
    "            Must be one of: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "            13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23].\n",
    "    \n",
    "    Returns:\n",
    "        {calc_funcs_ver}_diff_{region}_{period1_start}_{period1_end}_{period2_start}_\n",
    "            {period2_end}_{subset}_glass-mean_{glass_data_source}.nc OR\n",
    "        {calc_funcs_ver}_diff_{region}_{period1_start}_{period1_end}_{period2_start}_\n",
    "            {period2_end}_{subset}_era5-mdp_{var_or_dvar}.nc OR\n",
    "        {calc_funcs_ver}_diff_{region}_{period1_start}_{period1_end}_{period2_start}_\n",
    "            {period2_end}_{subset}_era5-mdp_{var_or_dvar}_stats.nc OR\n",
    "        {calc_funcs_ver}_diff_{region}_{period1_start}_{period1_end}_{period2_start}_\n",
    "            {period2_end}_{subset}_era5-mdp_{var_or_dvar}_{hour}.nc OR\n",
    "        {calc_funcs_ver}_{region}_{period1_start}_{period1_end}_{period2_start}_\n",
    "            {period2_end}_{subset}_era5-wsd.nc:\n",
    "                Output netcdf4 file in data_processed folder containing the difference\n",
    "                in results, with name depending on calc_func being used.\n",
    "                {calc_funcs_ver} is the version of the calc_funcs script being\n",
    "                used and {glass_data_source} is automatically selected between\n",
    "                [\"avhrr\", \"modis\"] based on the selected period.\n",
    "    \n",
    "    First runs calc_func for each of the given periods if this has not already\n",
    "    been done. Then calculates the difference in results as period2 - period1.\n",
    "    For hour_max and hour_min stats, the result is expressed as a value between\n",
    "    -12 (hour_max or hour_min for period2 is 12 hours behind of that for period1) and\n",
    "    +12 (hour_max or hour_min for period2 is 12 hours ahead of that for period1).\n",
    "    \"\"\"\n",
    "    \n",
    "    func_cur = inspect.stack()[0][3]\n",
    "    func_1up = inspect.stack()[1][3]\n",
    "    if func_1up == \"<module>\":\n",
    "        print(\"Executing: {} to obtain difference in outputs from {} \"\n",
    "              .format(func_cur, calc_func.__name__) + \"over the given periods.\")\n",
    "    else:\n",
    "        print(\"Executing: {} to obtain difference in outputs from {} \"\n",
    "              .format(func_cur, calc_func.__name__) + \"over the given periods \" +\n",
    "              f\"for use in {func_1up}.\")\n",
    "    \n",
    "    # Assert that there are no errors in input arguments, and obtain the paths for\n",
    "    # the calc_diff output as well as intermediate calc_func outputs from each period\n",
    "    period1_start = datetime.strptime(period1_start, \"%b-%Y\")\n",
    "    period1_end = datetime.strptime(period1_end, \"%b-%Y\")\n",
    "    period2_start = datetime.strptime(period2_start, \"%b-%Y\")\n",
    "    period2_end = datetime.strptime(period2_end, \"%b-%Y\")\n",
    "    check_args(calc_func=calc_func, region=region, period_start=period1_start,\n",
    "               period_end=period1_end, subset=subset, var_or_dvar=var_or_dvar,\n",
    "               hour=hour)\n",
    "    check_args(period_start=period2_start, period_end=period2_end, subset=subset)\n",
    "    path_output, path_period1, path_period2 = get_paths_for_calc_diff(\n",
    "        calc_func=calc_func, region=region, period1_start=period1_start,\n",
    "        period1_end=period1_end, period2_start=period2_start, period2_end=period2_end,\n",
    "        subset=subset, var_or_dvar=var_or_dvar, hour=hour)\n",
    "    if Path(path_output).exists():\n",
    "        print(\"TERMINATED: \" + inspect.stack()[0][3] +\n",
    "              \" because file already exists \" + path_output)\n",
    "        return None\n",
    "    \n",
    "    # Create intermediate output files from each period if they don't already\n",
    "    # exist, then read in these files as xarray datasets and compute difference\n",
    "    if Path(path_period1).exists():\n",
    "        print(\"Using: existing file \" + path_period1)\n",
    "    else:\n",
    "        calc_func(region=region, period_start=period1_start.strftime(\"%b-%Y\"),\n",
    "                  period_end=period1_end.strftime(\"%b-%Y\"), subset=subset,\n",
    "                  var_or_dvar=var_or_dvar, hour=hour)\n",
    "    if Path(path_period2).exists():\n",
    "        print(\"Using: existing file \" + path_period2)\n",
    "    else:\n",
    "        calc_func(region=region, period_start=period2_start.strftime(\"%b-%Y\"),\n",
    "                  period_end=period2_end.strftime(\"%b-%Y\"), subset=subset,\n",
    "                  var_or_dvar=var_or_dvar, hour=hour)\n",
    "    ds_period1 = xr.open_dataset(path_period1, engine = \"netcdf4\")\n",
    "    ds_period2 = xr.open_dataset(path_period2, engine = \"netcdf4\")\n",
    "    ds_diff = ds_period2 - ds_period1\n",
    "    \n",
    "    # Treat hour_max and hour_min stats separately since the difference in these\n",
    "    # should be between -12 hours (12 hours behind) and +12 hours (12 hours ahead).\n",
    "    if calc_func.__name__ == \"calc_era5_mdp_climatology_stats_given_var_or_dvar\":\n",
    "        ds_diff[var_or_dvar + \"_hour_max\"] = (ds_diff[var_or_dvar + \"_hour_max\"] +\n",
    "                                              12) % 24 - 12\n",
    "        ds_diff[var_or_dvar + \"_hour_min\"] = (ds_diff[var_or_dvar + \"_hour_min\"] +\n",
    "                                              12) % 24 - 12\n",
    "    \n",
    "    # Create output file in data_processed folder\n",
    "    ds_diff.to_netcdf(path_output)\n",
    "\n",
    "    if func_1up == \"<module>\":\n",
    "        print(f\"CREATED: file {path_output}.\")\n",
    "    else:\n",
    "        print(f\"CREATED: file for use in {func_1up} {path_output}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a787a65-f6a2-4bb7-917d-dc21684d9f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: calc_diff to obtain difference in outputs from calc_era5_wsd_climatology over the given periods.\n",
      "Executing: check_args to check whether input arguments into calc_diff are valid.\n",
      "Passed: validity check for input arguments into calc_diff.\n",
      "Executing: check_args to check whether input arguments into calc_diff are valid.\n",
      "Passed: validity check for input arguments into calc_diff.\n",
      "Executing: get_paths_for_calc_diff to obtain calc_diff output path and intermediate output paths from calc_era5_wsd_climatology for use in calc_diff.\n",
      "Executing: check_args to check whether input arguments into get_paths_for_calc_diff are valid.\n",
      "Passed: validity check for input arguments into get_paths_for_calc_diff.\n",
      "Executing: check_args to check whether input arguments into get_paths_for_calc_diff are valid.\n",
      "Passed: validity check for input arguments into get_paths_for_calc_diff.\n",
      "Obtained: calc_diff output path and intermediate output paths from calc_era5_wsd_climatology for use in calc_diff.\n",
      "TERMINATED: calc_diff because file already exists ../data_processed/v00_diff_wa_Jan-1993_Jan-1993_Jan-2012_Jan-2012_all_era5-wsd.nc\n",
      "CPU times: user 129 ms, sys: 0 ns, total: 129 ms\n",
      "Wall time: 126 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "calc_diff(calc_era5_wsd_climatology, \"wa\", \"Jan-1993\", \"Jan-1993\", \"Jan-2012\", \"Jan-2012\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e9c6a-5d08-4160-90c9-276d1a0e66ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a9d15-b106-4b0a-a4b1-7a17d18656f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66fad0-b385-429f-a83b-196a01915645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97083901-4d5f-4936-8f1f-f0969f3453ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd6564-617d-48c6-8f23-11cc1370d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e6c99-165d-41e2-a70b-d485f812254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4316c9-bd78-413f-9f96-8ec2a9f731ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2644383-3505-4e62-841a-223e4f2f1d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f933f-ffb9-43d1-9638-11213ce57894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b4507-5027-402d-9bfa-7379e267e398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d53130-ee5b-44f2-92a0-b0ebdee3cd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f3e83-0b32-4b5c-a0ec-e09a0dffdf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.open_dataset(\"../data_processed/v00_diff_wa_Jan-1993_Jan-1993_Jan-2012_Jan-2012_all_era5-wsd.nc\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e32c8-5f3a-47f0-a8ab-d06ac71d4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"ws100_mean\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c6aab-e89e-4dc2-9557-b8b07353dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"ws100_std\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aece03-3a75-4f63-a449-873e2452c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"c100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76748738-3238-4d94-b5f6-ede59a00088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"k100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f496f8b-8305-485e-aa69-5b6761ff23dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"eroe100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55924ea6-0418-452a-b3a0-1f2a77f82d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"gcf100\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb571d2-bf2c-4959-b2df-886af0ac9800",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"eroe100\"].where(test[\"eroe100\"]==test[\"eroe100\"].max(), drop = True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57091f5c-bc05-48bc-b44d-9ad5892fc25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"mlai\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9d69b-05e4-4097-835d-8ea036a9d889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
